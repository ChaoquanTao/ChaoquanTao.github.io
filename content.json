{"meta":{"title":"Tau's Blog","subtitle":"","description":"大音希声 大象无形","author":"Tau","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2023-03-19T04:16:14.892Z","updated":"2023-03-19T04:16:14.873Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"202104 至今：美团点评"},{"title":"所有标签","date":"2023-03-05T10:10:06.298Z","updated":"2023-03-05T10:10:06.277Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2023-03-05T10:08:24.455Z","updated":"2023-03-05T10:08:24.435Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2017-05-27T05:47:40.000Z","updated":"2023-03-05T09:49:53.526Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"聊一聊linux中的tc命令","slug":"聊一聊linux中的tc命令","date":"2023-05-25T13:00:00.000Z","updated":"2023-05-29T14:17:39.326Z","comments":true,"path":"2023/05/25/聊一聊linux中的tc命令/","link":"","permalink":"http://example.com/2023/05/25/%E8%81%8A%E4%B8%80%E8%81%8Alinux%E4%B8%AD%E7%9A%84tc%E5%91%BD%E4%BB%A4/","excerpt":"","text":"最近杂事太多，又是组织架构调整，又是换工作，最近终于有空能写下这边文章了。 tc (Traffic Controll) 作为linux中的流量控制工具，功能非常强大，可以对网络流量的速率、延迟、带宽等进行控制。本文主要介绍tc命令的结构和使用，多数内容来自于对参考文章的翻译和整理，并增加了一些解释和说明，帮助大家在工作中能够快速理解和使用该命令。 什么是tc命令?一言以蔽之，tc是linux中的一个流量控制工具，它能够控制指定类型的网络包以指定的速率和指定的顺序从指定网卡进来或出去。 tc命令有什么用基于tc命令的强大能力，我们可以做很多有趣的事，比如我们可以对网络带宽按照流量类型进行限速，可以帮助我们限制特定应用程序或网络接口的带宽使用；在实际的开发过程中，可以使用tc命令去模拟一些网络延迟、网络丢包的故障，以此验证我们的系统能否应对网络抖动。 tc的原理 这部分的内容比较生硬，如果大家看着比较懵的话，可以先看下一节如何使用的部分，然后带着疑问来看这一节。 tc在逻辑上是一个树状结构，主要由以下队列(qdisc)，类别(class)，过滤器(filter)构成，其中队列和类别可以附着过滤器，用于对当前队列中的流量进行过滤和匹配，并将命中的流量发往下一级，大致结构如下： qdiscqdisc (queue discipline)即队列，linux网络中每个进入网卡的流量都会进入一个队列，队列分为有类别的队列 (classful qdiscs)和无类别的队列 (classless qdiscs)，有类别的队列下可以添加一个类别 (class)，这个类别上可以挂载过滤器 (filter)；无类别队列顾名思义，里面不能添加分类，是一种比较简单的队列。tc默认的队列的fifo (先进先出队列)。 我们在使用中会常看到root qdisc, 其指的是出站(egress)的根队列，tc的大多数配置也都是在出站队列里配的，而非入站(ingress)队列，这是因为入站队列能够配置的规则有限，不如出站队列的配置灵活。 qdisc分类qdisc分类如下，每种队列的适用场景不同，下面是这些队列一般性的定义： pfifo (Packet First-In, First-Out): 使用简单的FIFO排队算法进行数据包调度，按照先到先服务的原则进行处理。 bfifo (Byte First-In, First-Out): 类似于pfifo，但按照数据包的字节数进行调度和处理。 sfq (Stochastic Fairness Queueing): 使用随机公平队列调度算法，将数据包分配到多个小队列中，以实现公平的带宽共享。 tbf (Token Bucket Filter): 使用令牌桶算法对数据包进行调度和控制，限制传输速率和突发传输量。 htb (Hierarchical Token Bucket): 提供层次化的流量控制和优先级管理，可以创建多个子队列和子类别，并为每个子队列应用不同的流量控制策略。 prio (Priority Queueing): 允许用户为不同的数据流设置不同的优先级，数据包按照优先级进行排队和发送。 red (Random Early Detection): 使用随机早期检测算法对数据包进行调度，以避免网络拥塞和数据包丢失。 cbq (Class-Based Queueing): 提供基于类别的队列调度和流量管理，可以根据不同的类别设置不同的带宽限制和优先级。 classclass即类别，类别是以递归的结构依附于队列存在的，即队列下可以添加类别，而类别下又可以添加子类别或队列。每个类别会包含一个或多个过滤器 (filter)，这些过滤器可以用于筛选哪些流量可以进入哪些子类别或子队列。 filterfilter即过滤器，filter可以依附于class或qdisc，用以过滤哪些流量可以进入下一阶段。作为一个filter： 必须包含一个classifier 可以包含一个policer classifierclassifier即过滤器，用以确定要将数据包发往哪个类别。最常见的就是u32过滤器，可以认为classifier是filter的一部分，用来识别流量包的一些特征属性。 policer也是filter的一部分。可以限制网络包入队的速率，可以用于丢弃(drop)网络包。 handle用于标识class或classful qdisc, 由major number和minor number组成： major number: 可以随便命名 Minor numner: 如果为0，表示当前handle未qdisc，其他非0数字表示当前handle为class，同一父节点下的class的minor number相同。 ​ &gt; ffff:0表示入站队列 123456789root 1: | _1:1_ / | \\ / | \\ / | \\ 10: 11: 12: / \\ / \\10:1 10:2 12:1 12:2 对于上述结构，root 1: 表示根队列，根队列下有一个类别1:1，类别下有三个队列10:，11:, 12:，队列10:下有10:1和10:2两个类别，队列12:下有12:1和12:2两个类别。 如何使用经历上面这些生硬的概念后，下面我们从实战出发，看下tc命令的使用。 case 1: 添加一个队列12345tc qdisc add \\ ①&gt; dev eth0 \\ ②&gt; root \\ ③&gt; handle 1:0 \\ ④&gt; htb ⑤ tc qdisc add: 添加一个队列调度器规则。 dev eth0: 指定要应用该规则的网络接口，这里是以太网接口eth0。 root: 指定该规则为根（root）队列，即出站队列egress，表示它是队列调度器的顶层队列。 handle 1:0: 指定队列的处理标识符（handle），这里是1:0。该标识符用于唯一标识该队列，第一个数字可以随意指定，第二个数字为0表示队列，也可以简写为1:。 htb: 指定队列调度器的类型为”Hierarchical Token Bucket”（层次令牌桶）类型，它是一种流量调度算法。 case 2: 添加一个简单class1234567tc class add \\ ①&gt; dev eth0 \\ ②&gt; parent 1:1 \\ ③&gt; classid 1:6 \\ ④&gt; htb \\ ⑤&gt; rate 256kbit \\ ⑥&gt; ceil 512kbit :seven tc class add: 添加一个类别规则。 dev eth0: 指定要应用该规则的网络接口，这里是以太网接口eth0。 parent 1:1: 指定父类别的标识符，该类别是1:1，由于minor number非0，表示parent也是个class。 classid 1:6: 指定当前类别的标识符，该类别是1:6。 htb: 指定类别的类型为”Hierarchical Token Bucket”（层次令牌桶）类型，它是一种流量控制算法。 rate 256kbit: 设置类别的最大传输速率为256 kbit/s，表示流量在该类别中的传输速率不会超过该值。 ceil 512kbit: 设置类别的上限传输速率为512 kbit/s，表示流量在该类别中可以突发性地达到该值，但不会持续超过该值。 case 3: 添加一个优先级队列123456# tc qdisc add dev eth0 root handle 1: prio ## 创建优先级队列时会默认创建 1:1, 1:2, 1:3三个类别 # tc qdisc add dev eth0 parent 1:1 handle 10: sfq# tc qdisc add dev eth0 parent 1:2 handle 20: tbf rate 20kbit buffer 1600 limit 3000# tc qdisc add dev eth0 parent 1:3 handle 30: sfq 上面的命令创建的队列结构为: 1234567root 1: prio / | \\ 1:1 1:2 1:3 | | | 10: 20: 30: sfq tbf sfqband 0 1 2 对于上述配置，不免会有一个疑问，已经配置了优先级队列，但是当有网络包来临时，应当如何判断当前网络包的优先级呢？这里其实就涉及到filter了，需要为根队列配置filter，根据filter的过滤结果将数据包发往下一级队列或类别。 case 4: 为队列添加filter (classifier方式)123456# tc qdisc add dev eth0 root handle 10: prio （1）# tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \\ （2） ip dport 22 0xffff flowid 10:1 # tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \\ （3） ip sport 80 0xffff flowid 10:1# tc filter add dev eth0 protocol ip parent 10: prio 2 flowid 10:2 （4） 解释如下： （1）创建了一个根队列（root qdisc）并将其标识符设置为10: （2）添加了一个过滤器规则，该规则应用于根队列的子类别10:1。它使用prio优先级为1，并使用u32分类器来检查目标端口是否为22的IP数据包。如果匹配成功，该数据包将被发送到flowid为10:1的子类别进行进一步处理 (3) 添加了另一个过滤器规则，也应用于根队列的子类别10:1。它使用prio优先级为1，并使用u32分类器来检查源端口是否为80的IP数据包。如果匹配成功，该数据包将被发送到flowid为10:1的子类别进行进一步处理 （4）添加了第三个过滤器规则，应用于根队列的子类别10:2。它使用prio优先级为2，并将所有不符合第二条和第三条过滤器郭泽的数据包发送到flowid为10:2的子类别中进行处理。 上面的prio 1或prio 2决定了数据包被过滤器处理的顺序，因为prio 1的优先级高于prio 2, 所以当数据包来临时，prio 1的过滤器会先对数据包进行匹配，如果匹配不上，才会轮到prio 2所指的过滤器进行处理。 case 5: 为队列添加filter (policer方式)123456789101112131415# tc filter add \\ (1)&gt; dev eth0 \\ （2）&gt; parent 1:0 \\ (3)&gt; protocol ip \\ (4)&gt; prio 5 \\ (5)&gt; u32 \\ (6)&gt; match ip port 22 0xffff \\ (7)&gt; match ip tos 0x10 0xff \\ (8)&gt; flowid 1:6 \\ (9)&gt; police \\ (10)&gt; rate 32000bps \\ (11)&gt; burst 10240 \\ (12)&gt; mpu 0 \\ (13)&gt; action drop/continue (14) tc filter add: 添加一个过滤器规则。 dev eth0: 指定要应用该规则的网络接口，这里是以太网接口eth0。 parent 1:0: 指定父类别的标识符，该类别是1:0。这表示该过滤器规则将应用于标识符为1:0的父类别。 protocol ip: 指定过滤器规则的协议为IP协议，这意味着该规则将应用于IP数据包。 prio 5: 设置过滤器规则的优先级为5。优先级越高的规则将首先匹配和处理数据包。 u32: 指定过滤器匹配规则的类型为u32，表示使用32位的匹配规则。 match ip port 22 0xffff: 设置匹配规则，仅匹配目标端口号为22（SSH端口）的数据包。 match ip tos 0x10 0xff: 设置匹配规则，仅匹配TOS（Type of Service）字段为0x10的数据包。 flowid 1:6: 指定匹配的数据包将被发送到标识符为1:6的类别。 police: 启用流量控制（policing）机制，用于限制匹配的数据包的传输速率。 rate 32000bps: 设置流量控制的传输速率为32000 bps（比特每秒），即限制匹配的数据包的传输速率。 burst 10240: 设置允许的最大突发传输量为10240字节，表示数据包可以在短时间内突发性地达到该大小。 mpu 0: 设置最小传输单元（Minimum Packet Unit）为0，表示不进行进一步的分片处理。 action drop/continue: 指定匹配的数据包将被丢弃或继续处理，这取决于具体的配置需求。 写在最后tc命令强大，并且复杂， 光是其中的队列类型就有很多可以探究的地方，要以一篇文章总结tc的所有用法也不现实。本文旨在为读者提供一个tc的快速入门，帮助读者能够快速了解tc命令，希望对大家有用。 参考文章https://tldp.org/HOWTO/html_single/Traffic-Control-HOWTO/#software https://tldp.org/HOWTO/Adv-Routing-HOWTO/index.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"【基本功】如何理解Java线程中断","slug":"如何理解Java中断","date":"2023-03-12T01:00:00.000Z","updated":"2023-05-29T14:17:39.386Z","comments":true,"path":"2023/03/12/如何理解Java中断/","link":"","permalink":"http://example.com/2023/03/12/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3Java%E4%B8%AD%E6%96%AD/","excerpt":"","text":"什么是线程中断从广义上讲，就是中断一个正在工作或sleep的线程，从代码上讲， 所谓的线程中断，就是设置某个线程的中断标志位，当我想要中断某个线程的时候，就将这个线程的中断标志位设置为true, 但是至于是否响应中断，全凭JVM或这个线程自己决定。 为什么要有中断 一种常见的用途是用于线程池的shutdown方法, 如果你去查看ThreadPoolExecutor的shutdown方法方法，就会发现其底层就是通过线程中断来终止掉正在工作的线程的。🌰： 12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); //在这里中断线程 onShutdown(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); &#125; 123456789101112131415161718192021private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); //通过调用Thread.interrupt方法来中断正在工作的线程 &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#125; 如何中断和线程中断相关的一共有三个方法，分别是： 静态方法Thread.isInterrupted Thread.interrupt: 静态方法Thread.interrupted Thread.isInterrupted该方法是Thread类的一个静态方法，返回当前线程的中断标志位状态。 Thread.interrupt这个方法是Thread的一个成员方法，它会设置当前线程的中断标志位为true, 至于当前线程是否响应中断，和当前线程的执行内容有关。 所谓能够响应中断，是指: 如果在线程里调用了Object.wait()相关重载方法，Thread.join()相关重载方法，以及Thread.sleep()相关重载方法，则当前线程的中断标志位会被清空，并抛出一个InterruptedException异常 12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; while (!Thread.currentThread().isInterrupted())&#123; try &#123; System.out.println(&quot;in loop&quot;); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;after interrupted: &quot; + Thread.currentThread().isInterrupted()); &#125; &#125; &#125;); t.start(); Thread.sleep(1000); t.interrupt(); &#125; 对于上述代码，Thread.currentThread().isInterrupted()用于查看当前线程的中断标志位。初始时由于线程未被中断，Thread.currentThread().isInterrupted()返回false, 所以能够进入到while循环中，当执行t.interrupt()时，线程t会抛出InterruptedException并清空标志位，所以Thread.currentThread().isInterrupted()依然返回false, 从而while循环能够一直进行下去。 所以上述代码输出: 12345in loopafter interrupted: falsein loopin loop... 相反，如果我们只中断线程，但是不对中断标志位做任何响应的话，那么目标线程还是会正常运行: 123456789101112public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; while (true)&#123; boolean interrupted = Thread.currentThread().isInterrupted(); System.out.println(&quot;in loop, flag is: &quot;+ interrupted); &#125; &#125;); t.start(); Thread.sleep(1000L); t.interrupt(); &#125; 输出： 123456...in loop, flag is: falsein loop, flag is: falsein loop, flag is: truein loop, flag is: true... 如果当前线程阻塞在InterruptibleChannel类型的IO操作上，则会将当前线程中断标志位置为true并抛出一个ClosedByInterruptException 🌰： 1234567891011121314151617public static void main(String[] args) throws IOException, InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; try &#123; SocketChannel sc = SocketChannel.open(new InetSocketAddress(&quot;localhost&quot;, 8080)); sc.read(ByteBuffer.allocate(1)); &#125; catch (ClosedByInterruptException e) &#123; System.out.println(&quot;thread is interrupted, and the flag is:&quot; + Thread.currentThread().isInterrupted()); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;); t.start(); Thread.sleep(1000); t.interrupt(); &#125; 上述代码代码会打开一个SocketChannel并阻塞监听8080端口，如果此时中断当前线程，则会将线程中断标志位置为true并且抛出ClosedByInterruptException, 所以上述代码输出为： 1thread is interrupted, and the flag is:true 如果当前线程阻塞在NIO的Selector上，则会将线程中断标志位置为true并且立即从select动作中返回。🌰： 1234567891011121314151617181920public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; try &#123; Selector selector = Selector.open(); ServerSocketChannel sc = ServerSocketChannel.open(); sc.socket().bind(new InetSocketAddress(8080)); sc.configureBlocking(false); sc.register(selector, SelectionKey.OP_ACCEPT); selector.select(); //如果没有被中断且没有感兴趣的事件发生，则会一直阻塞在这里 System.out.println(&quot;如果走到了这里，说明线程被中断或者有感兴趣的事件发生&quot;); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;); t.start(); Thread.sleep(1000L); t.interrupt(); &#125; 上述代码中，我们使用NIO的方式开启了一个server, 并监听8080端口，由于没有感兴趣的事件发生，server的代码会一直阻塞在 selector.select()，此时如果中断当前线程，则select方法会立即返回，并打印下第11的输出。 ps: 可以看到第三点和第四点讲的都是NIO的中断响应，为什么没有讲到BIO呢，因为BIO是不会对中断抛出异常或立即返回的(虽然也会设置中断标志位为true, 但是在代码行为上不会有任何变化)，对于下述代码，服务端会阻塞在第12行serverSocket.accept上，当我们执行t.interrupt()后，虽然在主线程第23行的打印中可以看到线程t的标志位已经为true，但是ServerSocket依然阻塞，不会有任何改变。 123456789101112131415161718192021222324public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; ServerSocket serverSocket = null; try &#123; serverSocket = new ServerSocket(83); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; try &#123; while (true) &#123; Socket socket = serverSocket.accept(); &#125; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;); t.start(); Thread.sleep(1000L); t.interrupt(); System.out.println(t.isInterrupted()); &#125; 对于非上述几种类型，则只会将中断标志位设置为true. 小小总结一下，Thread.interrupt的本质是将线程中断标志位设置为true, 对于一些特殊的方法，如sleep,wait等，会抛出InterruptedException并清空中断标志位，对于其他操作，要么抛异常，要么立即返回，要么do nothing, 但是不会清空标志位。但无论如何，至于是否要响应中断，其实是目标线程自身决定的。 Thread.interruptedinterrupted是Thread类的一个静态方法，它会返回当前线程的中断标志位并清空，这意味着，如果连续两次调用该方法，第二次一定返回的是false. 举个例子： 1234567891011121314public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; while (!Thread.currentThread().isInterrupted())&#123; System.out.println(&quot;in loop, flag&quot;); &#125; System.out.println(&quot;thread is interrupted, before invoker Thread.interrupted(): &quot;+ Thread.currentThread().isInterrupted()); System.out.println(&quot;after invoker Thread.interrupted(): &quot;+Thread.interrupted()); System.out.println(&quot;after invoke Thread.interrupted() again: &quot;+Thread.interrupted()); &#125;); t.start(); Thread.sleep(1L); t.interrupt(); &#125; 输出： 12345...in loop, flagthread is interrupted, before invoker Thread.interrupted(): trueafter invoker Thread.interrupted(): trueafter invoke Thread.interrupted() again: false 当线程t被中断后，第一次调用Thread.interrupted(),返回true, 再次调用，返回false 写在最后Java的线程中断给我们提供了一种去改变目标线程状态的方式，和Thread.stop相比，中断更加温柔，它给目标线程提供了一个终止的机会，但是至于是否真的要终止，其实是由目标线程自身决定的，由目标线程自身决定是否对中断标志位的变更进行响应。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"中断","slug":"中断","permalink":"http://example.com/tags/%E4%B8%AD%E6%96%AD/"}]},{"title":"如何在Java中优雅地使用异常","slug":"如何在Java中优雅地使用异常","date":"2023-03-05T04:00:00.000Z","updated":"2023-05-29T14:17:39.381Z","comments":true,"path":"2023/03/05/如何在Java中优雅地使用异常/","link":"","permalink":"http://example.com/2023/03/05/%E5%A6%82%E4%BD%95%E5%9C%A8Java%E4%B8%AD%E4%BC%98%E9%9B%85%E5%9C%B0%E4%BD%BF%E7%94%A8%E5%BC%82%E5%B8%B8/","excerpt":"","text":"本文会简单介绍Java异常的分类， 以及在使用异常过程中的一些注意事项。 异常的分类Java异常是JVM应对错误的一种方式，无论是编译时错误、运行时错误、还是JVM内部错误，它的分类如下： Java的Exception和Error都继承自Throwable, Exeception包括CheckedExeception和UncheckedException，其中CheckedException是一些在编译期就能发现的异常，JVM要求开发者必须显式地捕获或抛出该异常, 如IOExcetion, FileNotFoundException, ClassNotFoundException。而UnCheckedException为运行时异常，在编译器无法发现，JVM也就不要求开发者必须做处理。 有两种比较容易混淆的异常和错误需要注意下：ClassNotFoundException, NoClassDefFoundError。如上文所说，ClassNotFoundException发生在编译期，通常是由于找不到该类文件导致，比如虽然在pom文件里引用了该jar包，编译器也确实没提示报错，但是由于当前的类加载器不加载这个jar包所在path的类文件，就会报这个错，比如调用Class.forName或Classloader.loadClass时，就可能会报这个异常。而NoClassDefFoundError发生在运行期，由于运行时找不到对应的类文件导致，比如你以provided方式引入某个jar包，编译时ok, 但运行时可能就会报错。 异常的使用由于Java异常有一定的性能损耗，在这里和大家分享几点异常的使用原则 1、应当捕获什么粒度的异常？ ​ 抛开场景谈这个问题毫无意义，看到网上有些文章说不应当捕获Throwable类，笔者不认同这种说法。在一些业务场景中，对于下游抛出的不同异常应当有不同的处理逻辑，这时捕获的异常应当越具体越好，比如： 1234567try&#123; //biz code&#125;catch(ExeptionA a)&#123; //do something&#125;catch(ExceptionB b)&#123; //do something else&#125; 也有些场景，比如你的代码相对于主逻辑是个旁路分支，这时你应当在自己代码的最外层一把梭捕获所有Exception和Error, 避免旁路逻辑抛出什么预期外的异常而影响主逻辑。，即你应当去捕获 Throwable: 12345try&#123; //旁路逻辑&#125;catch(Throwable t)&#123; //无论抛出什么异常，都不应当影响主流程&#125; 2、尽量使异常堆栈简短 ​ 异常堆栈的解析有一定的性能损耗，过长的异常栈也会给日志打印带来压力，所以，在明确知道你的异常会发生在什么位置时，应当使异常栈尽可能的浅，而对应的做法就是应当将捕获的异常重新定义再抛出： 12345678910111213//代码一，直接抛出原异常，会使异常栈比较深try&#123; //biz code&#125;catch(Exeception e)&#123; throw e;&#125;//代码二，捕获并重新定义异常，异常栈会从重新定义的地方开始计算try&#123; //biz code&#125;catch(Exception e)&#123; throw new RuntimeException(&quot;error msg here&quot;)&#125; 3、将异常定义为静态成员变量，避免重复创建对象 异常本身也是一个对象，既然是对象，那创建和回收就会有性能损耗，试想一下，在高并发情况下，刚好有一段代码有bug, 频繁地抛出异常，频繁地创建Exception新对象就有可能造成频繁地young GC. 12345try&#123; &#125;catch(Exception e)&#123; throw new Exception(); //在这里频繁地创建并抛出异常&#125; 所以，在明确知道当前逻辑会抛出或应当抛出什么异常的情况下，将异常定义为静态变量，可以帮助降低系统性能开销。举个🌰： 1234567if(/**不是会员**/)&#123; throw BizException.ExceptionA;&#125;public BizException&#123; public static BizException ExceptionA = new BizException(&quot;不是会员!&quot;);&#125; 写在最后开发不规范，上线两行泪。了解一下异常的使用技巧可以帮助我们规避一些开发风险 🫡","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"异常","slug":"异常","permalink":"http://example.com/tags/%E5%BC%82%E5%B8%B8/"}]},{"title":"一次由ip封禁引起的问题分析","slug":"一次iptables封禁引起的问题分析","date":"2023-02-10T14:00:00.000Z","updated":"2023-05-29T14:17:39.339Z","comments":true,"path":"2023/02/10/一次iptables封禁引起的问题分析/","link":"","permalink":"http://example.com/2023/02/10/%E4%B8%80%E6%AC%A1iptables%E5%B0%81%E7%A6%81%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/","excerpt":"","text":"问题背景​ 前两天有同事咨询：机器A上有个业务客户端，机器B上为服务端，服务端要定期探活客户端，当客户端访问不通时服务端应当摘除这个客户端节点。现在要验证下当客户端访问不通时服务端能否正常摘除节点，于是使用了iptables的ip封禁功能。在机器A上封禁机器B的ip后，在封禁期间服务B无法请求服务A，但是当取消机器A上的ip封禁后，服务B尽然收到了来自服务A的响应！ ​ 遇到这个问题我的第一反应是服务B是不是有什么重试机制，由于服务A访问不通所以多重试了几次，收到的响应其实是重试后的响应。在得到业务同学否定的回答后，我开始怀疑是否是tcp层做了重试。 问题复现先封禁，再建连准备两台机器A和B, ip分别为：10.48.22.221（对应下文dev01）和10.171.170.104(对应下文test02). 笔者当时使用的iptables命令如下，含义是拒绝来自ip的包和发向ip的包： 12iptables -I INPUT -s xxxx -j REJECTiptables -I OUTPUT -d xxx -j REJECT 第一步：添加规则 在dev01上添加上述两条规则 使用iptables -L查看，可以发现添加成功 第二步：dev01监听端口 使用nc -l 1234在dev01上监听1234端口 使用netstat -apn|grep 1234查看1234端口，发现已经处于监听状态 第三步骤：test02发起连接 在test02机器上使用nc 10.171.170.104 1234向dev01发起连接 在dev01上使用tcpdump host 10.48.22.221命令进行抓包 可以看到，dev01收到了test02的SYNC包（三次握手的第一次握手），但是由于dev01没有发送响应包，所以test01会进行重试，重试几次后，自动停止建连，在test02上使用netstat -apnc|grep 1234命令查看的结果也能验证这一点 至此，可以得到 结论一：在TCP建立连接阶段，使用 12iptables -I INPUT -s xxxx -j REJECTiptables -I OUTPUT -d xxx -j REJECT 是可以阻止TCP建立连接的。 先建连，再封禁既然先封禁、再建连是符合我们预期的，那本文开始提到的问题：封禁取消后发送端会收到响应包，有没有可能是基于已经建立好的TCP连接进行封禁的呢？ 先清除之前在dev01上建立的规则： 使用nc -l 1234在dev01上监听端口， 使用nc 10.171.170.104 1234在test02上发起连接： 可以看到TCP连接已经建立 在dev01上写入规则： 在test2上发送数据包 可以发现，由于没有收到ack, test2一直在尝试发送同一个数据包 此时，如果删除dev1上的规则，会怎样呢？ 果然，test2收到来自dev1的ack. 至此，我们得到 结论二：在已建立TCP连接后，使用 12iptables -I INPUT -s xxxx -j REJECTiptables -I OUTPUT -d xxx -j REJECT 不会断开已有连接，发送端会不断重试，如果通信恢复，发送端会收到之前的ack. 如何解决目前已经知道了问题所在，那如何解决呢？查看iptables相关命令可以发现，iptables命令可以指定协议，并且对于TCP命令可以指定参数，比如默认的--reject-with icmp-port-unreachable，也可以显式为TCP协议添加参数--reject-with tcp-reset. 从名字就可以看出，tcp-reset会使当前已建立的TCP连接立即重置，看起来应该可以解决建连后ip封禁不生效的问题，接下来就测试一下吧。 先封禁，再建连在dev01上使用命令 12iptables -I INPUT -p tcp -s 10.48.22.221 -j REJECT --reject-with tcp-resetiptables -I OUTPUT -p tcp -d 10.48.22.221 -j REJECT --reject-with tcp-reset dev01监听1234端口，test02发起连接，效果同上，test02会不断重试SYNC包。 看来该命令对于未建连的TCP是生效的。 先建连，再封禁建连后同样使用命令 12iptables -I INPUT -p tcp -s 10.48.22.221 -j REJECT --reject-with tcp-resetiptables -I OUTPUT -p tcp -d 10.48.22.221 -j REJECT --reject-with tcp-reset 在dev01上封禁test02,然后test02尝试发送数据包，诡异的事情出现了，test02并没有如我们所期望的那样收到dev01的RESET响应 难道说是iptables的OUTPUT策略吧reset包给拦截了？ 在建连之后只给dev01写入一条INPUT策略试下： 果然，这时候test发送数据包后立即收到了RESET包 至此，我们得到 结论三：对于已建连的TCP，使用命令 1iptables -I INPUT -p tcp -s 10.48.22.221 -j REJECT --reject-with tcp-reset 可以使TCP连接立即断开。 结论四：iptables OUTPUT策略和INPUT策略会互相影响，由INPUT导致的响应包会被OUTPUT策略给拦截。 总结一下本文主要介绍了使用iptables命令进行ip封禁的排查之路，之中会涉及到很多网络知识，希望对各位小伙伴有所帮助。","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"聊一聊限流之guava限流器","slug":"聊一聊限流之guava限流器","date":"2022-10-22T10:00:00.000Z","updated":"2023-05-29T14:17:37.600Z","comments":true,"path":"2022/10/22/聊一聊限流之guava限流器/","link":"","permalink":"http://example.com/2022/10/22/%E8%81%8A%E4%B8%80%E8%81%8A%E9%99%90%E6%B5%81%E4%B9%8Bguava%E9%99%90%E6%B5%81%E5%99%A8/","excerpt":"","text":"前言限流是微服务应用中一个老生常谈的话题，当A调B时，为了防止A的流量过大把B打垮，需要为B配置限流，限制上游应用对B的调用频率。关于限流算法，有漏桶算法、令牌桶算法、计数器算法、滑动窗口算法，本文不再赘述。本文主要讲解guava中的限流算法。 用法guava限流算法实现的是令牌桶算法，依赖于包 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;31.0-jre&lt;/version&gt;&lt;/dependency&gt; 赊账机制，将阻塞时间延后123456public static void main(String[] args) &#123; RateLimiter rateLimiter = RateLimiter.create(1); //创建一个限流器，每秒允许获取一个令牌 while (true)&#123; System.out.println(&quot;get token in &quot;+rateLimiter.acquire()+&quot;s&quot;); //rateLimiter.acquire返回距离上次获取限流器等待的时间 &#125;&#125; 输出： 12345get token in 0.0s //第一次获取令牌不用等待。get token in 0.997387sget token in 0.992418sget token in 0.996242sget token in 1.000031s 可以看到，在第一次获取令牌的时候，限流器并没有等待一秒，而是直接获取，反倒是从第二次获取令牌的时候才开始等待，这也是guava令牌桶算法的特点之一：赊账，将当前请求本应阻塞的时间顺延给下一个请求处理。这是一个很妙的设计，试想一下，如果面对下面的情况，第一个请求不用等100s，而是立即通过，反倒是第二个请求需要等100s后才能通过，很巧妙地将阻塞时间延后了，至于会不会有第二个请求、第二个请求要请求几个令牌，那都是100s后的事情了，这种赊账机制提升了限流器对于当前请求的处理速度。 123456public static void main(String[] args) &#123; RateLimiter rateLimiter = RateLimiter.create(1); while (true)&#123; System.out.println(&quot;get token in &quot;+rateLimiter.acquire(100)+&quot;s&quot;); &#125;&#125; 令牌累积，应对突发流量guava限流器会将当前没有用完的令牌囤积下来，以便应对未来的突发流量。默认会积攒一秒的令牌量，对于下述代码， 123456public static void main(String[] args) &#123; RateLimiter rateLimiter = RateLimiter.create(1); while (true)&#123; System.out.println(&quot;get token in &quot;+rateLimiter.acquire(1)+&quot;s&quot;); &#125;&#125; 输出 12345get token in 0.0sget token in 0.997302sget token in 0.993367sget token in 0.995367sget token in 0.995384s 即每隔一秒才能获取一个令牌，但是如果限流器启动后当前线程sleep一秒再获取令牌时，此时前六条请求（前五条用累积的令牌，第六条赊账）不用阻塞，能够立即获得令牌，原因就在于限流器积攒了这一秒的令牌。 即对于下述代码： 1234567public static void main(String[] args) throws InterruptedException &#123; RateLimiter rateLimiter = RateLimiter.create(5); Thread.sleep(1000); while (true)&#123; System.out.println(&quot;get token in &quot;+rateLimiter.acquire(1)+&quot;s&quot;); &#125; &#125; 输出： 1234567get token in 0.0sget token in 0.0sget token in 0.0sget token in 0.0sget token in 0.0sget token in 0.0sget token in 0.194899s 原理在了解guava令牌桶算法的原理之前，我们先来思考下，如果让我们来实现令牌桶算法，需要怎么写？ 所谓令牌桶算法，就是以固定的速率往一个桶里放令牌，当有请求来时，就从桶里取令牌，如果桶空了，就阻塞请求，直到桶里有令牌为止。按照令牌桶算法的思想，最直观的实现思路就是生产者消费者模型，专门起一个生产令牌的线程，以固定速率往集合（桶）里生产令牌。但如果这么做的话就会有些复杂，涉及到一些线程安全的操作。 guava令牌桶的实现就比较巧妙了，将多线程的令牌操作换算成单线程的时间操作。由于生产令牌的速率是固定的，所以只要知道生产令牌的起止时间，就能算出这段时间里生产了多少令牌，每次当有请求到来时，计算下迄今一共存了多少令牌，如果令牌够用，则通过请求，更新剩余令牌数，否则，先赊账让当前请求通过，然后计算下次请求应该阻塞的最早时间。 首先了解下ratelimiter里面几个很重要的变量 12345678910//SmoothRateLimiter.java//当前存储令牌数double storedPermits;//添加令牌时间间隔，如果qps是5，则时间间隔则为200ms，即每200ms获取一个令牌double stableIntervalMicros;//下一次请求可以获取令牌的起始时间//也就是上文提到的赊账机制，上次请求预消费令牌后//下次请求需要等待相应的时间到nextFreeTicketMicros时刻才可以获取令牌private long nextFreeTicketMicros = 0L; 先来看下acquire方法： 123456//RateLimiter.javapublic double acquire(int permits) &#123; long microsToWait = reserve(permits); //返回获取目标令牌数所需等待的时间 stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L);&#125; 其中reserve方法返回获取目标令牌数所需等待的时间： 1234567//RateLimiter.javafinal long reserve(int permits) &#123; checkPermits(permits); synchronized (mutex()) &#123; return reserveAndGetWaitLength(permits, stopwatch.readMicros()); &#125;&#125; 12345//RateLimiter.javafinal long reserveAndGetWaitLength(int permits, long nowMicros) &#123; long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0);&#125; 接下来就是核心部分了： 12345678910111213141516171819202122//SmoothRateLimiter.javafinal long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; //刷新截止目前的令牌数 storedPermits 和下次能获取令牌的时间 nextFreeTicketMicros resync(nowMicros); //下次允许获取令牌的时间点 long returnValue = nextFreeTicketMicros; //得出需要花费的令牌数，比如需要5个，当前一共存了3个，则返回3；如需求3个，但存了5个，仍返回3 double storedPermitsToSpend = min(requiredPermits, this.storedPermits); //除去已积攒的令牌，还需额外支付的令牌，比如需求5个，当前存了3个，则还需额外支付两个 double freshPermits = requiredPermits - storedPermitsToSpend; //把要额外支付的令牌数换算成时间，比如还需额外支付两个，如果设置的qps是5，即每200ms生产一个令牌，那2个令牌就需要等待400ms long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); //更新下次获取令牌的时间， //这里需要注意，这个方法的返回值是 returnValue，即更新前的 nextFreeTicketMicros， //也就是说当前请求需要阻塞的时间不变，而是将需要额外支付的时间交给下个请求，下个请求需要阻塞更久，也就是上文讲到的赊账机制 this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros); //更新已存储的令牌 this.storedPermits -= storedPermitsToSpend; return returnValue;&#125; 同步nextFreeTicket 12345678void resync(long nowMicros) &#123; // if nextFreeTicket is in the past, resync to now if (nowMicros &gt; nextFreeTicketMicros) &#123; double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros(); storedPermits = min(maxPermits, storedPermits + newPermits); nextFreeTicketMicros = nowMicros; &#125;&#125; 下面通过一个小🌰来解释一下，在下图中，假设限流器限流为5ps, 即每200ms一个请求，当第一个请求在限流器启动时（即0s）时到来，这时候会直接通过，并计算允许下次请求通过的时间，由于此时是请求两个令牌，所以nextFreeTicket为2*200ms=400ms，在0-400ms期间到来的请求都会阻塞到400ms才允许通过，并再次更新nextFreeTicket. 写在最后这篇文章主要介绍了guava令牌桶算法的用法以及原理，文章只挑选了最核心的部分进行了介绍，关于guava ratelimiter, 除了文中介绍的应对突发流量的限流器外，还有平滑预热（warmingUp）限流，感兴趣的读者可以自行了解。 从工程角度讲，上述限流器是一种单机限流，即只能针对单台机器生效，但真实环境中一个应用更多是集群部署，需要针对整个集群限流，比如让整个集群的qps小于某个阈值，这就需要用到集群限流，比如阿里巴巴开源的sentinel。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[]},{"title":"聊一聊DelayQueue","slug":"聊一聊DelayQueue","date":"2022-07-06T15:00:00.000Z","updated":"2023-05-29T14:17:37.602Z","comments":true,"path":"2022/07/06/聊一聊DelayQueue/","link":"","permalink":"http://example.com/2022/07/06/%E8%81%8A%E4%B8%80%E8%81%8ADelayQueue/","excerpt":"","text":"DelayQueue作为延时队列，有很多应用场景，今天主要来聊一下它的原理、优缺点以及应用场景。 基本用法DelayQueue的元素需要实现Delayed接口, 并覆盖getDelay方法和compareTo方法，其中getDelay方法会被轮询调用，以判断当前任务是否到达执行时间，comparedTo方法则是用来比较每个任务的先后关系。 基本用法如下： 123456789101112131415161718192021222324public class MyTask implements Delayed &#123; private long curTime = System.currentTimeMillis(); private long executeTime; private long delayTime; public MyTask(long time) &#123; this.delayTime = time; this.executeTime = curTime + time; &#125; public void execute() &#123; System.out.println(&quot;execute task with delay &quot; + delayTime); &#125; @Override public long getDelay(TimeUnit unit) &#123; return unit.convert(executeTime - System.currentTimeMillis(),TimeUnit.MILLISECONDS); &#125; @Override public int compareTo(Delayed o) &#123; return (int) (this.executeTime - ((MyTask) o).executeTime); &#125;&#125; 测试类 1234567891011121314151617181920212223public class DelayQueueApp &#123; public static void main(String[] args) &#123; DelayQueue&lt;MyTask&gt; queue = new DelayQueue&lt;&gt;(); queue.add(new MyTask(10_000)); queue.add(new MyTask(15_000)); queue.add(new MyTask(5_000)); new Thread(new Runnable() &#123; @Override public void run() &#123; while (true) &#123; try &#123; MyTask task = queue.take(); task.execute(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 我们给queue里添加三个元素，延迟分别是10ms, 15ms和5ms, 然后在子线程里从这个queue里取任务并执行，输出： 123execute task with delay 5000execute task with delay 10000execute task with delay 15000 可以看到任务是按照延迟时间排序出队的。 原理DelayQueue是基于优先级队列实现的，并且是线程安全的。先列出DelayQueue中几个比较重要的的概念： 优先级队列PriorityQueue:DelayQueue的底层是优先级队列 Thread类型的leader变量 可重入锁：用于控制入队和出队的线程安全 优先级队列和可重入锁这里不再赘述，关于leader变量需要着重说明下，**DelayQueue可能会有多个消费者线程**，然而一个任务节点最终只能被一个线程抢到，为了为了避免不必要的争抢，DelayQueue使用了“Leader-Follower”模式，说白了就是将消费者线程排队，每次只让leader线程去获取队首节点，这里就涉及到两个点： 当队首元素发生变化时（比如后入队的元素优先级更高，成了队首元素），leader线程也应当跟着刷新，即leader线程总是致力于获取队首元素。 当leader线程执行结束后，应当重新产生leader线程。 需要注意的是，Leader-Follower模式并不能减少awaitNanos的时间，它是用来避免不必要的线程状态切换的，如果不用Leader-Follower模式，也能实现该功能，但是会增加一些无意义的线程wakeup/sleep；如果使用Leader-Follower模式，只有leader线程会在指定时间后被唤醒，其他线程则是无限期等待，相比之下，后者更高效。 入队方法 123456789101112131415161718public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); //元素入队 /**如果当前是队首（有人会好奇为什么会有这个判断，这是因为当前是优先级队列，后入队的元素也可能是队首）， 如果队首元素有变化，那leader线程也应当跟着变化，所以这里将leader置为null, 等待出队时重新选择 **/ if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125; &#125; 这里首先会加个可重入锁，然后给q添加元素，查看q的定义，可以看到它就是一个优先级队列。 1private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;(); 这里有段代码需要注意下： 1234if (q.peek() == e) &#123; leader = null; available.signal();&#125; 出队方法 123456789101112131415161718192021222324252627282930313233343536public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); if (first == null) //如果队空，则当前线程进入等待队列 available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) //如果队首元素已到期，则直接出队 return q.poll(); /**否则，说明当前线程要排队等候，这时候就要决定当前线程是leader线程还是follow线程，如果已经有leader了，那当前线程就只 能是follower了，默默加入等待队列即可。如果当前还没有等待队列，那就把当前线程作为leader线程，并让当前线程等待到剩余 时间**/ first = null; // don&#x27;t retain ref while waiting if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 如果队列不为空，并且没有Leader则从等待队列拿出一个线程，进行take操作。 if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125; &#125; 应用看到网上有些文章讲DelayQueue可以用来做淘宝下单后的定时取消订单功能，对此笔者持保留态度。DelayQueue作为延迟队列，单从技术角度来看确实可以，但是从系统设计角度看则有待商榷。用DelayQueue做订单取消功能，意味着在内存中维护待取消的订单信息，说明你的服务是有状态的，而有状态意味着：1、无法水平扩展；2、增加开发成本。举个🌰，假如当前这台服务器突然宕机，那队列里的任务都不会被执行；又比如面临大促时，当前服务器系统负载飙升，但是由于任务都集中在当前机器的DelayQueue里，即使加机器也无法解决。所以，面临一些比较重的计算任务时，需要考虑系统的可扩展性和可用性，单单依赖DelayQueue是不行的，一般大型公司都会有专门做定时任务的中间件，可以依赖这些中间件去实现，并将delayqueu作为一种降级策略，如果是对时间精确度要求较低的场景，也可以考虑将这些任务持久化到数据库中，然后定时去扫库。 写在最后无论如何，没有最牛逼的架构，只有最合适的架构，选型之前除了组件本身功能之外，也要考虑到系统特点，需要在开发成本、系统可用性要求等诸多因素中做权衡。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[]},{"title":"从建造者模式看自限定泛型","slug":"Java泛型之自限定类型","date":"2022-05-22T13:00:00.000Z","updated":"2023-05-29T14:17:39.384Z","comments":true,"path":"2022/05/22/Java泛型之自限定类型/","link":"","permalink":"http://example.com/2022/05/22/Java%E6%B3%9B%E5%9E%8B%E4%B9%8B%E8%87%AA%E9%99%90%E5%AE%9A%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"基本用法Java提供了泛型，可以在编译期做一些类型检查。以集合类List为例，如果我们这样用： 123456789101112public class GenericApp &#123; public static void main(String[] args) &#123; List list = new ArrayList(); list.add(1); list.add(&quot;a&quot;); for (Object value : list) &#123; System.out.println((int)value); &#125; &#125;&#125; 虽然也不会报错，但是由于这个list什么类型都能添加，在运行期如果要获取其中元素并做一些强制类型转换的话，一定会报错。 有了泛型，可以帮助我们在编译器就发现程序的一些问题： 1234567public class GenericApp &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(1); list.add(&quot;a&quot;); &#125;&#125; 上述代码在编译器就会报错，因为泛型限制了当前list只能添加整型。 需要注意的是，泛型只存在于编译期，编译完成之后会进行类型擦除, 将上述代码编译后再反编译，你会看到list的元素类型其实是Object 当然了，如果使用的是有上限通配符的泛型，那反编译后泛型会被替换成上界的类型。 自限定类型在Java泛型中，有一种比较奇特的用法，叫自限定泛型（Self Bounded Generic）。写法是这样的: 1class SelfBounded&lt;T extends SelfBounded&lt;T&gt;&gt;&#123;&#125; 这种自限定泛型初次看起来可能会比较懵逼，SelfBounded接收的一个泛型参数，并且这个泛型的上界是它自己？看起来有点递归调用的意思？ 先说结论： 它的作用常常体现在继承中，用于限定子类中泛型的类型上界，当父类的某个方法想要返回的子类的类型，可以采用自限定类型这种方式 下面我们通过一个建造者模式的例子来加深对它的理解。 实现一个建造者模式有一个披萨类，是个抽象类，具体实现有芝士披萨和牛肉披萨，这两种披萨都有一些共有特征，比如都可以往上面加一些小料（topping），同时各自又有一些特性，比如芝士披萨需要指定尺寸，而牛肉披萨需要指定是否加酱料。 我们使用Builder模式来实现这个需求，首先将共有属性抽象到父Builder里 1234567891011public abstract class Pizza &#123; public static abstract class Builder &#123; abstract Pizza build(); public Builder addTopping(Topping topping)&#123; System.out.println(&quot;topping added&quot;); return this; &#125; &#125;&#125; 芝士披萨 1234567891011121314151617181920212223242526272829public class CheesePizza extends Pizza &#123; private String size; public CheesePizza()&#123;&#125; public CheesePizza(CheesePizzaBuilder builder)&#123; CheesePizza cheesePizza = new CheesePizza(); cheesePizza.size = builder.size; &#125; public static Builder builder()&#123; return new CheesePizzaBuilder(); &#125; public static class CheesePizzaBuilder extends Builder &#123; private String size; @Override Pizza build() &#123; return new CheesePizza(this); &#125; public CheesePizzaBuilder size(String size)&#123; this.size = size; return this; &#125; &#125;&#125; 测试类： 12345public class PizzaApp &#123; public static void main(String[] args) &#123; Pizza cheesePizza = CheesePizza.builder().size(&quot;small&quot;).addTopping(new Topping()).build(); &#125;&#125; 这时候问题就出现了，CheesePizza的builder()方法返回Builder类，Builder类是没有size方法的，因为size是子类CheesePizzaBuilder特有的。 这好办，我把CheesePizza的builder()方法返回具体子类不就好了？也不是不能用，但是不优雅，这个改动意味着每次build时必选先调用子类Builder中的特有方法，如size, 然后才能调用父Builder的addTopping方法，这样好吗？这样不好，很不优雅。 带泛型的建造者模式冷静分析上面的问题，你就会发现根因在于父Builder的addTopping方法返回的类型和子Builder的size方法返回的类型不一致。理论上，既然是子Builder进行build, 我们自然希望子Builder里的每个方法都能返回子Builder，这样既能调用子Builder自己的独有的方法，也能调用父Builder的方法。所以，我们可以这么改造: Pizza类 123456789101112131415public abstract class Pizza &#123; public static abstract class Builder&lt;T&gt; &#123; public Builder()&#123;&#125; abstract Pizza build(); public T addTopping(Topping topping)&#123; // 这里做了改变 System.out.println(&quot;topping added&quot;); return self(); &#125; protected abstract T self(); &#125;&#125; CheesePizza类 1234567891011121314151617181920212223public class CheesePizza extends Pizza &#123; ... public static class CheesePizzaBuilder extends Builder&lt;CheesePizzaBuilder&gt; &#123; private String size; public CheesePizzaBuilder()&#123;&#125; @Override Pizza build() &#123; return new CheesePizza(this); &#125; @Override protected CheesePizzaBuilder self() &#123; //这里做了改变 return this; &#125; public CheesePizzaBuilder size(String size)&#123; this.size = size; return this; &#125; &#125;&#125; 考虑到Builder中的每个具体的build方法（如size）都应该返回具体的Builder, 我们为父Builder加入了泛型，该泛型表示的是具体的Builder, 并在addTopping后返回该泛型。如此一来，我们就可以快乐的build了。 还能再优化吗从上面的讨论可以知道，我们引入的泛型其实是有上界的，泛型T一定是继承自Builder的，所以我们可以更精简一下： 123456789101112131415public abstract class Pizza &#123; public static abstract class Builder&lt;T extends Builder&lt;T&gt;&gt; &#123; //这里做了修改 public Builder()&#123;&#125; abstract Pizza build(); public T addTopping(Topping topping)&#123; System.out.println(&quot;topping added&quot;); return self(); &#125; protected abstract T self(); &#125;&#125; 子类中的写法保持不变： 1public static class CheesePizzaBuilder extends Builder&lt;CheesePizzaBuilder&gt; &#123;&#125; 那这时候就出现了我们前文提到的自限定泛型，它在这里的语义是：传给Builder的泛型一定是一个继承自Builder的类型。这么做有什么好处呢？它可以在编译器尽可能地帮我们检查出一些错误，如果这时候子类的Builder接收了一个非继承自Builder的类型，那么编译器就会直接报错。 总结一下这篇文章主要介绍了自限定泛型，并通过建造者模式加深了对它的理解。自限定泛型，常用于传入的类型参数需要和类本身继承自同一父类的场景，说白了，它的作用常常体现在继承中，用于限定子类中泛型的类型上界，当父类的某个方法想要返回的子类的类型，可以采用自限定类型这种方式，加强编译期校验。 如果你要问只用个泛型，不要自我限定行不行，答案是也行，只不过前者更“细”，前者会在编译器做更多的类型校验。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"泛型","slug":"泛型","permalink":"http://example.com/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"当ThreadLocal遇上线程池","slug":"当ThreadLocal遇上线程池","date":"2022-04-30T04:00:00.000Z","updated":"2023-05-29T14:17:39.329Z","comments":true,"path":"2022/04/30/当ThreadLocal遇上线程池/","link":"","permalink":"http://example.com/2022/04/30/%E5%BD%93ThreadLocal%E9%81%87%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"温馨提示: 本文需要垃圾回收、强弱引用、多线程等知识. ThreadLocal是什么ThreadLocal, 从名字大概可以知道，它是个线程本地变量，意味着只有当前线程可以使用，线程之间相互隔离。 举个🌰： 123456789101112131415161718192021222324public class ThreadLocalApp &#123; public static void main(String[] args) &#123; ThreadLocal&lt;String&gt; tl = new ThreadLocal&lt;&gt;(); tl.set(&quot;main&quot;); System.out.println(&quot;变更前, 主线程中的tl: &quot;+tl.get()); new Thread(new Runnable() &#123; @Override public void run() &#123; tl.set(&quot;sub thread&quot;); System.out.println(&quot;子线程中的tl: &quot;+tl.get()); &#125; &#125;).start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException ignore) &#123; &#125; System.out.println(&quot;变更后, 主线程中的tl: &quot;+tl.get()); &#125;&#125; 输出: 123变更前, 主线程中的tl: main子线程中的tl: sub thread变更后, 主线程中的tl: main 上面的代码中，我们先主线中设置了threadLocal为main，然后在子线程中将tl设置为sub thread，这时候再去打印主线程的tl, 发现还是main. 可以看到，在当前线程设置threadLocal变量后，不会影响其他线程中该变量的值。 有什么用ThreadLocal很适合在单一线程中传递一些上下文信息。比如在mvc模型中，在controller中获取了用户信息，现在service层中要用到，一种方法就是把用户信息放到方法参数中，一层一层传递下去，但这样很繁琐，另一种方法就是利用ThreadLocal,在controller中设置好，在service中读取即可。 实现原理从set方法浅看下threadLocal的实现原理: 可以看到，所谓的set就是把value放到ThreadLocalMap里： 这个map是Thread的一个静态成员变量: 1ThreadLocal.ThreadLocalMap threadLocals = null; 至此也就大概明了了：所谓ThreadLocal,也就是它维护了一个指向Thread对象的ThreadLocalMap类型的引用，其中Map的key为ThreadLocal类型，set和get的时候就是操作的都是Thread对象的map的set和get方法，说白了就是在操作线程的局部变量，自然不会受其他线程影响，也不会影响到其他线程。 在线程池中使用ThreadLocal在线程池中使用ThreadLocal时要记得用完之后要及时使用remove()回收,原因如下: 原因一: 线程池重复使用线程 来看一个🌰: 123456789101112131415161718192021222324252627public class ThreadLocalInPoolApp &#123; public static void main(String[] args) &#123; ThreadLocal&lt;String&gt; tl = new ThreadLocal(); ExecutorService executor = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; int finalI = i; executor.submit(new Runnable() &#123; @Override public void run() &#123; tl.set(String.valueOf(finalI)); System.out.println(&quot;set后,&quot;+Thread.currentThread().getName()+&quot; tl值:&quot;+tl.get()); &#125; &#125;); &#125; for (int i = 0; i &lt; 5; i++) &#123; int finalI = i; executor.submit(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;在新提交的任务里,&quot;+Thread.currentThread().getName()+&quot; tl值:&quot;+tl.get()); &#125; &#125;); &#125; &#125;&#125; 输出: 12345678910set后,pool-1-thread-2 tl值:1set后,pool-1-thread-4 tl值:3set后,pool-1-thread-1 tl值:0set后,pool-1-thread-3 tl值:2set后,pool-1-thread-5 tl值:4在新提交的任务里,pool-1-thread-4 tl值:3在新提交的任务里,pool-1-thread-5 tl值:4在新提交的任务里,pool-1-thread-3 tl值:2在新提交的任务里,pool-1-thread-1 tl值:0在新提交的任务里,pool-1-thread-2 tl值:1 在上面的例子里，笔者创建了一个大小为5的的线程池，在第一个循环里给线程池里面的五个线程设置了tl的值，当后续又用这个线程池的时候，会发现之前设置的tl的值还在，这是因为线程池是复用核心线程的，如果用完threadLocal后不及时回收，就会出现上述现象。 下面为正确使用姿势: 1234567891011121314151617181920212223242526272829public class ThreadLocalInPoolApp &#123; public static void main(String[] args) &#123; ThreadLocal&lt;String&gt; tl = new ThreadLocal(); ExecutorService executor = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; try&#123; tl.set(String.valueOf(finalI)); System.out.println(&quot;set后,&quot;+Thread.currentThread().getName()+&quot; tl值:&quot;+tl.get()); &#125;finally&#123; tl.remove(); //要及时remove &#125; &#125; &#125;); &#125; for (int i = 0; i &lt; 5; i++) &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;在新提交的任务里,&quot;+Thread.currentThread().getName()+&quot; tl值:&quot;+tl.get()); &#125; &#125;); &#125; &#125;&#125; 输出: 12345678910set后,pool-1-thread-1 tl值:0set后,pool-1-thread-5 tl值:4set后,pool-1-thread-4 tl值:3set后,pool-1-thread-3 tl值:2set后,pool-1-thread-2 tl值:1在新提交的任务里,pool-1-thread-5 tl值:null在新提交的任务里,pool-1-thread-2 tl值:null在新提交的任务里,pool-1-thread-3 tl值:null在新提交的任务里,pool-1-thread-4 tl值:null在新提交的任务里,pool-1-thread-1 tl值:null 原因二：降低内存泄露的可能再来看下ThreadLocal.ThreadLocalMap里面的entry. 可以看到，entry的key是个ThraedLocal，并且是个弱引用。 对于如下代码: 1234567891011121314151617181920212223public class ThreadLocalApp &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; //代码块① ThreadLocal&lt;String&gt; tl = new ThreadLocal&lt;&gt;(); tl.set(&quot;main&quot;); //代码块② tl = null; //查看Map Class&lt;?&gt; clazz = Thread.currentThread().getClass(); Field field = clazz.getDeclaredField(&quot;threadLocals&quot;); field.setAccessible(true); Object map = field.get(Thread.currentThread()); //代码块③ System.gc(); //gc后再次查看map map = field.get(Thread.currentThread()); System.out.println(map); &#125;&#125; 执行完代码块①后，ThreadLocal对象的引用关系如下，其中实线为强引用, 虚线为弱引用。 这时候通过debug查看threadLocalMap,还是可以看到ThreadLocal以及指向它的弱引用的: 执行完代码块②后，ThreadLocal对象就只有一个弱引用指向它 在进行一次gc后，ThreadLocal就彻底沦为“孤儿”了： 这时候再去看ThreadLocalMap： 这时候唯一存在的一条指向value的引用链为：Thread -&gt; ThreadLocalMap -&gt; Entry -&gt; value. value虽然一直存在（只要当前线程在，value就一直在)，但是外界却无法获取它。这时候，就发生了内存泄露。要避免这个问题,也很简单，每次用完记得remove就行。 上面说了这么多，再来思考一个问题：内存泄露和弱引用有没有关系？ 答案是没关系。即使不是弱引用，也会存在内存泄露，jdk使用弱引用只是为了让它能够被更好更快地回收，用文档原话说就是: 1To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys. 跨线程使用ThreadLocal更真实的情况是，有时候代码中会有异步操作，但我们又希望在异步线程里也能拿到父线程的ThreadLocal变量，针对这种情况，JDK提供了InheritableThreadLocal. InheritableThreadLocal下述代码在主线程里设置了InheritableThreadLocal变量，在子线程中仍然可以获取 1234567891011121314public class InheritableThreadLocalApp &#123; public static void main(String[] args) &#123; //代码块① InheritableThreadLocal&lt;String&gt; tl = new InheritableThreadLocal&lt;&gt;(); tl.set(&quot;main&quot;); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(tl.get()); &#125; &#125;).start(); &#125;&#125; 输出: 1main 实现原理Thread类的成员变量共有两个ThreadLocal.ThreadLocalMap类型的变量，一个是threadLocals,另一个是inheritableThreadLocals. 而InheriableThreadLocal继承自ThreadLocal, 重写了childValue，getMap,createMap三个方法。 那父线程的ThreadLocal变量的值是什么时候悄咪咪的传递到子线程的呢？答案是创建线程的时候: 123public Thread(Runnable target) &#123; init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0); &#125; init方法里有这么一行关键代码: 123if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); 相当于是把parent的inheritableThreadLocal给原样拷贝了一份。 线程池与InheritableThreadLocal从上面实现原理的分析可以知道，InheritableThreadLocal是在创建线程的时候传递inheritableThreadLocal的, 由于线程池是复用线程的，所以在线程池里使用InheritableThreadLocal同样是行不通的。 如何破局先来看症结在哪:InheritableThreadLocal是通过new Thread()时进行的传递，考虑到线程池是通过submit(Runnable)的方式来提交任务，那是否意味着我们可以将线程池或者Runnable包装一下，在submit或者run方法执行前将InheritableThreadLocal进行传递呢？ 阿里开源的TransmittableThreadLocal就基于上述的思想，分别通过 增强Runnable或Callable 使用TtlRunnable.get()或TtlCallable.get(), 提交线程池之后，在run()内取出变量 增强线程池 使用TtlExecutors.getTtlExecutor()或getTtlExecutorService()、getTtlScheduledExecutorService()获取装饰后的线程池使用线程池提交普通任务,在run()方法内取出变量（任务子线程） 两种方式解决了传统的InheritableThreadLocal的问题。 来看下效果: 123456789101112131415161718192021222324252627282930313233public class TransmittableThreadLocalApp &#123; private static TransmittableThreadLocal&lt;String&gt; context = new TransmittableThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5); context.set(&quot;value-set-in-parent&quot;); //空载，先将线程都创建起来 for (int i = 0; i &lt; 5; i++) &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; &#125; &#125;); &#125; // 第一次提交 Runnable task = new RunnableTask(); executor.submit(TtlRunnable.get(task)); context.set(&quot;value changed&quot;); executor.submit(TtlRunnable.get(task)); &#125; static class RunnableTask implements Runnable&#123; @Override public void run() &#123; System.out.println(context.get()); &#125; &#125;&#125; 输出: 12value changedvalue-set-in-parent 可以看到将值传到线程池的线程里。 总结本文介绍了ThreadLocal和InheritableThreadLocal,以及它们在线程池中使用时需要注意的问题以及一些扩展。","categories":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Netty学习笔记之服务端建立新连接","slug":"Netty学习笔记之服务端建立新连接","date":"2022-04-05T08:00:00.000Z","updated":"2023-05-29T14:17:39.336Z","comments":true,"path":"2022/04/05/Netty学习笔记之服务端建立新连接/","link":"","permalink":"http://example.com/2022/04/05/Netty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%BB%BA%E7%AB%8B%E6%96%B0%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"前情提要在Netty学习笔记之服务端启动一文中，我们了解了eventloop的基本功能，知道了它的一生其实就是个死循环，再循环里处理IO事件和taskQueue里面的任务；同时我们也了解到，在服务端启动之初(准确的来讲是在channel注册完成之后调用handlerAdded的时候)会给pipeline里添加一个特殊的handler：ServerBootstrapAcceptor，有了这两点之后，让我们看下Netty服务端启动后是如何利用reactor模型建立新连接的。 正文当客户端启动并给服务端发送消息后，服务端的eventloop就会监听到对应事件： NioEventLoop.run123456789101112131415161718192021222324252627282930313233343536373839404142protected void run() &#123; for (;;) &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; // fall through default: &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); //这里就会支棱起来 &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; // Always handle shutdown even if the loop processing threw an exception. ... &#125; &#125; NioEventLoop.processSelectedKey123456789101112131415private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); ... try &#123; .... // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); //调用了这里 &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125; &#125; NioMessageUnsafe.read123456789101112131415161718public void read() &#123; ... boolean closed = false; Throwable exception = null; try &#123; ... int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; readPending = false; pipeline.fireChannelRead(readBuf.get(i)); //这里 &#125; ... &#125; finally &#123; // Check if there is a readPending which was not processed yet. ... &#125; &#125; &#125; 最终调用了pipeline.fireChannelRead(readBuf.get(i)), 在服务端启动一文中我们也讲到了pipeline的传播，像这种firexxx的都是从head往后传播的，所以最终会传播到ServerBootstrapAcceptor里，调用ServerBootstrapAcceptor的channelRead,而这里，就是重头戏了。 ServerBootstrapAcceptor.channelRead 这里有几个点需要注意下： 代码①：这里的Channel是SockerChannel，而不是ServerSocketChannel，即是客户端的Channel. 代码②：childHandler就是我们在boostrap里配的ChannelInitializer，等到channel真正注册后回调initChannel方法，把MyServerHandler添加到pipeline，见下图，这里的处理和服务端启动一文中doResigter一节中的代码②是一个道理，归根到底就是因为我们想给pipeline添加handler，但是Channel还没注册好，所以采取的一种妥协的方式，即先给pipeline注册一个ChannelInitializer类型的Handler，等到Channel真正注册好之后，再去回调这个特殊Handler的initChannel方法。 这里也可以解释bootstrap的handler和childHanlder的区别：前者对应ServerSocketChannel，后者对应SockerChannel. ​ 代码③：这里就是将channel注册到eventloop上，和我们在服务端启动一文中看到的serversocketChannel的注册差不多，但是有细微区别，主要体现在 服务端启动时的注册是将serversocketChannel注册到bossGroup里的eventloop.而childChannel注册时是要注册到workerGroup里。 在注册环节，由于当前线程是bossGroup的线程，所以一定会走else的逻辑, 将注册的任务提交到childChannel自己的eventloop","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"http://example.com/tags/Netty/"}]},{"title":"Netty学习笔记之客户端启动","slug":"Netty学习笔记之客户端启动","date":"2022-04-04T02:00:00.000Z","updated":"2023-05-29T14:17:37.590Z","comments":true,"path":"2022/04/04/Netty学习笔记之客户端启动/","link":"","permalink":"http://example.com/2022/04/04/Netty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%AF%E5%8A%A8/","excerpt":"","text":"在上一篇文章中，讨论了netty服务端启动的大概流程，这篇文章将会继续看下客户端启动流程。 总览一般的客户端长这样，真正的入口要从bootstrap.connect看起。 分析进入connect方法的最终调用在这里： 如果已经看过服务端启动流程，会发现这里和服务端的代码神似，都是先initAndRegister,如果注册成功，则直接执行doResolveAndConnect0,否则就添加一个监听器，当监听器触发的时候执行doResolveAndConnect0. 事实上initAndRegister的逻辑都是一样的，因为都是走的都是Bootstrap.initAndRegister(). 我们只需要关注doResolveAndConnect0做了什么即可。 doResolveAndConnect0 这里熟悉的异步操作又又又又来了：首先异步执行resolver.resovle(),并返回一个future,后续会根据future来判断resolve动作是否完成。如果它完成了，则执行doConnect，否则给future注册一个listener,等到resovle完成的时候会触发这个listener，进而执行doConnect. 最终的connect走的是pipeline的connect方法 继续， 这个tail是个ChannelHandlerContext,也就是pipeline的主要内容，","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"http://example.com/tags/Netty/"}]},{"title":"Netty学习笔记之服务启动","slug":"Netty学习笔记之服务端启动","date":"2022-02-13T04:00:00.000Z","updated":"2022-02-13T04:00:00.000Z","comments":true,"path":"2022/02/13/Netty学习笔记之服务端启动/","link":"","permalink":"http://example.com/2022/02/13/Netty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%90%AF%E5%8A%A8/","excerpt":"","text":"前置知识学习之前需要理清这么几个关键概念： netty相关：EventLoop, EventLoopGroup, ChannelHandler, ChannelPipeline，ChannnelPromise, ChannelFuture nio相关：channel, selector. Channel与Selector谈到nio, 那么channel和selector就是绕不开的话题，他们的关系如下： 一个selector和一个线程对应，这也是nio的好处之一：用单线程处理多个客户端的连接；一个selector同时对应多个channel,每个channel将自己注册到selector上，注册的时候会携带自己感兴趣的事件。然后selector就去轮训这些事件，当有某个事件ready时，就去通知对应的channel. EventLoop翻译过来是事件循环器，其实就是用来处理各种io事件的，要具备这种能力，那么eventloop必须： 具有一个selector 具有自己的线程，在这个线程里可以对selector注册的事件进行遍历 所以,eventloop继承自了Executor,具有线程池的能力，同时含有一个selector. 每个channel都对应一个eventloop，在netty启动之时，会将channel注册到eventloop，然后eventloop就会开启死循环，去 遍历channel感兴趣的事件 作为executor去执行任务队列里的任务 上述两点便是eventloop的核心作用。我们已AbstractChannel.register来说明这个问题。 AbstractChannel.register1234567891011121314151617public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; ... if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; ... &#125; &#125;&#125; 在注册channel的时候，如果当前线程是eventloop线程，则直接注册，否则，将register0作为一个任务提交到eventloop的任务队列里，也就是execute方法。 SingleThreadEventExecutor.execute execute方法也是言简意赅，如果当前线程是eventloop线程，则直接addTask，否则先开启一个线程，然后addTask. SingleThreadEventExecutor.doStartThread1234567891011121314151617181920212223private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; boolean success = false; updateLastExecutionTime(); try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; finally &#123; ... &#125; &#125;); &#125; 这里利用Jdk的Executor.execute开启一个线程，并在这个线程里开始了它的死循环，即SingleThreadEventExecutor.this.run() NioEventloop.run1234567891011121314151617181920212223242526272829303132333435363738394041protected void run() &#123; for (;;) &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; // fall through default: &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; ... &#125; &#125; 这个run方法就是EventLoop的核心了，里面有两个比较关键的方法： processSelectedKeys:查询已经就绪的事件并处理，说白了就是处理io事件 runAllTasks:处理任务队列里的任务，比如我们通过eventloop.execute提交的任务 ​ 那么至此，eventloop的功能就大概清楚了，它就是在死循环里套死循环，去处理io事件和taskQueue. 当然了，里面还有一些小细节，比如： 为了分配好处理io事件的时间和处理taskQueue的事件，使用了ioratio作为两者的时间比例。 ChannelPipeline用张图来解释： 每个channel都会对应一个channel pipeline, 而这个pipeline就是一个链表，每个节点类型为ChannelHandlerContext,内部包了一个ChannelHandler. 而ChannelHandler又分为ChannelInboundHandler和ChannelOutboundHandler, 分别用来处理入站事件和出站事件，差不多像这样： 当有入站事件或者出站事件发生时，事件会以责任链模式经过handler. ChannelPromise和 ChannelFuturenetty扩展了jdk原生的future. 而promise则是对Netty future的进一步扩展。 jdk原生future: netty的future: 可以看到,netty扩展的future增加了一些监听器的add和remove的方法，以及一些同步方法，如await,sysnc. 再来看下promise： 多了一些设置状态的方法，如setSuccess,setFailure 这些扩展意味着什么netty的future可以addListener,removeLisener, promise可以setSuccess,setFailure,意味着异步操作时，如主线程调了eventloop的线程，只要将promise返回主线程，那么promise在eventloop线程里的任何动作都可以被主线程感知到，比jdk的futrue更加健壮了一些。 总览一般的启动代码长这样： 真正的入口在bind这里，进去看看： 首先，initAndRegister,意思是初始化并注册，初始化什么？注册什么？这里其实是初始化一个channel, 并把eventloop的selector注册到channel上，注意这个方法的返回值，是个future,也就是说initAndRegister这个动作是异步进行的，如果注册完成了，即regFuture.isDone(),则进行doBind0操作，否则，添加一个监听器，等initAndRegister完成了会出发它，然后进行doBind0。 OK，大致来看，启动分为两个步骤，首先initAndRegister,然后进行doBind0。 initAndRegister首先来看下这个initAndRegister究竟做了些啥。 这里init后面会讲。最终调用到的是**AbstractChannel$AbstractUnsage.register** AbstractChannel$AbstractUnsage.register 这个register方法有两个参数，eventloop是最初配置的bossGroup,ChannelPromise是对Channel的包装。这里要注意，注册的动作必须发生在eventloop的线程里，所以如果当前线程不是eventloop的线程的话，eventloop会起一个自己的线程去做这个事情。 继续看register0: register0 doResigter就是真正的注册过程，在死循环里将channel注册到eventloop的selector里。 doResigter 相比代码①，注册完成之后的②③④⑤更值得关注。 代码②回调添加handler时候的handlerAdded方法 ​ 这里是有细节的，回到我们最初的server端代码： ​ 执行完代码②后，应该输出“HandlerAdded”. 但是这个handler是什么时候添加进pipeline的呢？是serverBootStrap的handler()方法吗，不是。回到initAndRegister处， abc 看下这个init方法： 12345678910111213141516171819202122@Override void init(Channel channel) throws Exception &#123; ... //省略若干代码 p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;); &#125; 可以看到，在init的时候，pipeline就添加一个handler,即ChannelInitializer,并覆盖了initChannel方法,所以启动后pipelie里除了head和tail之外，还有一个叫做ChannelInitializer的handler,一共三个handler。再回到代码②，代码②的最终功能就是去调用ChannelInitializer的initChannel方法,而这个initChannle里面，才是把我们在serverbootstrap里定义的handler给加到pipeline里,并在添加之后回调handlerAdded方法。 当这个ChannelInitializer完成的它的任务后，就被remove掉了，此时pipeline里就只有head,tail以及我们自己定义的handler了。 代码③设置成功之后，我们上文里提到的doBind方法里的listener就会被出发，从而继续执行doBind0方法 代码④执行添加handler时候的channelRegistered回调 代码⑤首次注册的时候不是active,后面再讲 OK，至此，一个channel就初始化好了，并且注册了到了eventloop上 doBind0书接上回register0的代码③，设置成功后，doBind方法里的regFuture添加的listener就被触发了，来到了doBind0环节。 这里的channel.bind()也是比较有意思的，看似是channel的bind，其实最后调的是pipeline的bind.(插一嘴，pipieline在netty里相当核心，基于责任链模式，所有的事件都在pipeline里流动，后面会专门起一篇文章说这个事情。) AbstractChannel.bind() DefaultChannelPipeline.bind() ​ 可以看到，pipeline的bind是从tail开始的，也就是说，它是从尾部向头部传播的，也就是说，context的类型应该是outboundContenxt 总结一下服务端启动需要做这么几件事：初始化一个channel, 然后把这个channel注册到selector上，然后把在channel上绑定服务端地址。 整个过程中，pipeline贯穿全局，起着传递事件的作用。","categories":[{"name":"Netty","slug":"Netty","permalink":"http://example.com/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"http://example.com/tags/Netty/"}]},{"title":"一次由匿名内部类引发的问题","slug":"一次由匿名类引发的问题","date":"2022-02-12T03:00:00.000Z","updated":"2022-02-12T03:00:00.000Z","comments":true,"path":"2022/02/12/一次由匿名类引发的问题/","link":"","permalink":"http://example.com/2022/02/12/%E4%B8%80%E6%AC%A1%E7%94%B1%E5%8C%BF%E5%90%8D%E7%B1%BB%E5%BC%95%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"前菜众所周知，java的内部类是可以访问到外部类的field的，如： 12345678910111213141516public class Fruit &#123; private String name; public Origin origin()&#123; return new Origin(); &#125; class Origin&#123; String province; String county; public void info()&#123; System.out.println(&quot;fruit from &quot;+ province + &quot; &quot;+county+&quot; name:&quot;+name); //可以访问到外部类的name属性 &#125; &#125;&#125; 但是为什么呢？我们打印下origin对象的字段 12345678public static void main(String[] args) &#123; Fruit fruit = new Fruit(); Origin origin = fruit.origin(); for (Field field : origin.getClass().getDeclaredFields()) &#123; System.out.println(field); &#125; &#125; 输出： 123java.lang.String innerclass.Fruit$Origin.provincejava.lang.String innerclass.Fruit$Origin.countyfinal innerclass.Fruit innerclass.Fruit$Origin.this$0 可以看到，除了Origin类自有的province和county字段外，编译时会生成一个this$0字段，由final修饰，类型是Fruit. 所以，内部类之所以能够访问到外部类的field,是因为它持有了一个外部类的引用this$0 稍微复杂的情况当匿名类加上抽象类，会碰撞出怎样的火花呢？ 定义一个抽象类Parent，它含有一个抽象内部类Child，同时有一个child1方法，返回一个Child对象： 1234567public abstract class Parent &#123; protected abstract class Child&#123;&#125; protected Child child1()&#123; return new Child() &#123; &#125;; &#125;&#125; 再定义一个ParentImpl类，继承自Parent, 同时有一个child2方法，也返回一个Child对象 123456public class ParentImpl extends Parent&#123; public Parent.Child child2()&#123; return new Child() &#123; &#125;; &#125;&#125; 我们定义一个ParentImpl对象，那么这个对象应该有两个可操作的方法，child1()和child2(), child1()是来自父类的方法，child2()是实现类自己的方法，这两个方法都是Child类型，但是会不会有什么不同呢？答案就在this$0. 我们分别去打印这两个返回对象的this$0 12345678910public static void main(String[] args) throws IllegalAccessException &#123; ParentImpl parentImpl = new ParentImpl(); Parent.Child child2 = parentImpl.child2(); //实现自子类的child Field outField2 = getField(child2.getClass(),&quot;this$0&quot;); //子类内部类的this$0 System.out.println(&quot;子类new Child()的this$0:&quot;+outField2); Parent.Child child1 = parentImpl.child1(); //父类里实现的child Field outField1 = getField(child1.getClass(),&quot;this$0&quot;); //父类内部类的this$0 System.out.println(&quot;父类new Child()的this$0:&quot;+outField1);&#125; 输出： 12子类new Child()的this$0:final ParentImpl ParentImpl$1.this$0父类new Child()的this$0:final Parent Parent$1.this$0 可以看到，两个对象的this$0有所不同，子类new的Child的this$0是ParentImpl类型，父类new的Child的this$0是Parent类型，倒也合情合理。 那这个时候，假如说，我拿到了子类里的内部类对象，即child2, 同时我又有父类内部类的this$0,outField1, 我能否从child2利用反射拿到父对象呢？即 1outField1.get(child2); 抛异常了： 1234567Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Can not set final Parent field Parent$1.this$0 to ParentImpl$1 at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167) at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171) at sun.reflect.UnsafeFieldAccessorImpl.ensureObj(UnsafeFieldAccessorImpl.java:58) at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.get(UnsafeQualifiedObjectFieldAccessorImpl.java:38) at java.lang.reflect.Field.get(Field.java:393) at Main.main(Main.java:15) 那换一下呢？ 1outField2.get(child1); 也不行 1234567Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Can not set final ParentImpl field ParentImpl$1.this$0 to Parent$1 at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167) at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171) at sun.reflect.UnsafeFieldAccessorImpl.ensureObj(UnsafeFieldAccessorImpl.java:58) at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.get(UnsafeQualifiedObjectFieldAccessorImpl.java:38) at java.lang.reflect.Field.get(Field.java:393) at Main.main(Main.java:12) 说白了就是，child2里面没有final Parent Parent$1.this$0这个field,你想get,就会抛异常，同理child1里面也没有final ParentImpl ParentImpl$1.this$0这个field，你想get,也会抛异常。 总结一下上面说到的匿名内部类的问题，说白了是它的作用域的问题，父类里的抽象内部类，在父类里new,和在子类里new, this$0的指向是不同的。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Docker笔记","slug":"Docker学习","date":"2021-11-13T07:00:00.000Z","updated":"2023-05-29T14:17:39.325Z","comments":true,"path":"2021/11/13/Docker学习/","link":"","permalink":"http://example.com/2021/11/13/Docker%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"常见命令 docker image ls查看镜像列表 docker ps 查看正在运行的容器 docker run -p 8888:80 -tid blog-20220502 /bin/bash 启动容器 进入运行中的容器：docker exec -ti &#123;containerId&#125; /bin/bash -t 为docker分配一个伪终端并绑定到容器的标准输入上 -i 是让容器的标准输入保持打开状态 docker stop/start/restart constainerId 我在别人的容器里进行了修改，如何保存成新的镜像？先将之前的container停掉,然后docker commit oldContainerId newImage, 注意，是containerId","categories":[{"name":"容器","slug":"容器","permalink":"http://example.com/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[]},{"title":"Linux supervise","slug":"Linux Supervise","date":"2021-08-31T15:00:00.000Z","updated":"2023-05-29T14:17:39.312Z","comments":true,"path":"2021/08/31/Linux Supervise/","link":"","permalink":"http://example.com/2021/08/31/Linux%20Supervise/","excerpt":"","text":"今天工作中遇到一个命令svc，可以用于优雅杀死进程。本着啥都不会的精神，刨根问题一哈。 背景: 一般而言生产环境中的服务都是有守护进程的：当它挂掉后，会有另外一个进程把它立马拉起来。 在指导这个东西以前，我都是通过cron+脚本的方式来达到这一目的的，但是缺点就是cron只能精确到分钟，不够细。 正餐： linux中有个监控工具，叫supervise，它是daemontools里面的一个工具。 daemontools是什么？ 它是一个linux工具包，http://cr.yp.to/daemontools.html。 supervise是什么？ supervise用来监控一个服务，当服务死掉时，可以立马将其拉起。要实现这个操作，supervise命令需要创建一个run文件。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"Tomcat Session管理","slug":"关于Tomcat的Session管理","date":"2021-06-06T06:00:00.000Z","updated":"2023-05-29T14:17:39.310Z","comments":true,"path":"2021/06/06/关于Tomcat的Session管理/","link":"","permalink":"http://example.com/2021/06/06/%E5%85%B3%E4%BA%8ETomcat%E7%9A%84Session%E7%AE%A1%E7%90%86/","excerpt":"","text":"Hey what’s up guys. 有好长一段时间没写博客了，最近也是来上海一个多月难得的一个周末，所以写点东西吧。 关于session cookie相关的内容在校招时也被经常问到，但是最近感觉对这块的理解还是不够深入，所以再学习一下。 众所周知session用于会话管理，一般情况下，http request的header里的cookies字段里会带个sessionID, 服务端收到请求后，从cookie中拿出sessionID, 然后根据这个sessionID从服务端存储的session中拿出对应的session, 然后这个session里面一般会存储用户名、会话过期时间等。 流程是这么个流程，但是我之前一直忽略了一点，服务端的session是怎么存储的？因为考虑到服务端的扩展性，session有时候会被存储到redis或者mysql中，所以我一直以为session的管理需要开发者自己去做，后来发现，其实tomact有自己的会话管理功能。 而事实是，Tomcat内部有个Manager接口，这个接口的实现类负责管理session,具体来说，负责session的增删改查。Manager底下有StandarManager和PersistanceManagerBase两种实现，一种将session存在内存，一种则是持久化。当然StandardManager为了保证可靠性，也会将session存到文件中，只不过没有第二种存到数据库那么专业和高效罢了。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[]},{"title":"Springboot @Async探险","slug":"Springboot-@Async探险","date":"2020-12-02T09:30:00.000Z","updated":"2023-05-29T14:17:39.383Z","comments":true,"path":"2020/12/02/Springboot-@Async探险/","link":"","permalink":"http://example.com/2020/12/02/Springboot-@Async%E6%8E%A2%E9%99%A9/","excerpt":"","text":"从业务说起，用到了@Async在主线程中接收数据，进行数据拼接，然后存库，最后返回http 200, 由于客户端有失败重试机制，且失败次数多了之后会不再请求，所以为了避免由于存库导致的阻塞，项目中使用@async进行异步处理。 出现了意料之外的问题项目上线后发现，一段时间之后客户端停止请求服务端了（这里其实是客户端的自动推送功能被关了）查看日志发现是使用了@async的子线程抛了异常，导致没有正常返回http 200给客户端。 这就奇了怪了，@async是异步处理，理论上讲，在@async中出现异常不应该会影响到主线程返回http 200啊。因此笔者进行了进一步的验证。 @Async探秘是否是子线程的验证起初我的代码是这样写的（springboot下的test文件下的） 123456789101112131415161718192021@Slf4j@RunWith(SpringRunner.class)@SpringBootTestpublic class AsyncTest &#123; @Test public void test()&#123; log.info(&quot;before:&#123;&#125;&quot;,Thread.currentThread().getName()); asyncTest(); log.info(&quot;after&quot;); &#125; @Async(&quot;asyncTaskExecutor&quot;) public void asyncTest()&#123; log.info(&quot;sub:&#123;&#125;&quot;,Thread.currentThread().getName()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 但是输出就很奇怪了： 123before:&quot;main&quot;sub:&quot;main&quot;after 加了async注解，但是似乎并没有开启子线程？ 通过查找资料得知，原来使用async注解的方法不能和主线程的方法在一个类中，这里的原因笔者会稍后解释，于是修改代码： AsyncTest 1234567891011121314@Slf4j@RunWith(SpringRunner.class)@SpringBootTestpublic class AsyncTest &#123; @Autowired AnotherTest anotherTest; @Test public void test()&#123; log.info(&quot;before:&#123;&#125;&quot;,Thread.currentThread().getName()); anotherTest.asyncTest(); log.info(&quot;after&quot;); &#125;&#125; AnotherTest 12345678910111213@Slf4j@Servicepublic class AnotherTest &#123; @Async(&quot;asyncTaskExecutor&quot;) public void asyncTest()&#123; log.info(&quot;sub:&#123;&#125;&quot;,Thread.currentThread().getName()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 再次执行，一样的输出？？？小小的脑袋有大大的疑惑。后来找到原因，需要在SpringBootApplication所在类使用@EnableAsync开启async功能，像这样： 12345678@SpringBootApplication@EnableAsync@MapperScan(&quot;com.aier.camerawater.mapper&quot;)public class CamerawaterApplication &#123;public static void main(String[] args) &#123; SpringApplication.run(CamerawaterApplication.class, args); &#125;&#125; 再次运行，输出是对了： 123before:&quot;main&quot;aftersub:&quot;async-task-thread-pool-1&quot; 但是在输出的后面跟了个InterruptException: 123456789101112131415161718192020-12-02 19:10:33.960 INFO com.aier.camerawater.AsyncTest - before:&quot;main&quot;2020-12-02 19:10:33.971 INFO com.aier.camerawater.AsyncTest - after2020-12-02 19:10:33.980 INFO com.aier.camerawater.AnotherTest - sub:&quot;async-task-thread-pool-1&quot;2020-12-02 19:10:33.986 INFO org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService &#x27;asyncTaskExecutor&#x27;java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.aier.camerawater.AnotherTest.asyncTest(AnotherTest.java:14) at com.aier.camerawater.AnotherTest$$FastClassBySpringCGLIB$$437e206d.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Process finished with exit code 0 再次愣住，众所周知，出现InterruptException的原因之一就是当线程sleep的时候被中断就会抛出这个异常，具体可以参考笔者的这篇文章。那么问题来了，我们的代码中也没有interrupt的相关操作啊。但是冷静观察一下你就会发现，在抛出异常的上面，还有这么一行： 1org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService &#x27;asyncTaskExecutor&#x27;java.lang.InterruptedException: sleep interrupted 也就是说，是由于主线程先结束的，然后这时候线程池打算shutdown了，于是就interrupt了我们的子线程。换句话说就是，这个线程池是跟着主线程走的，主线程结束它就结束。 这似乎和我们平时用的线程池不太一样啊，平时使用也没见它这么猴急，还没等子线程结束就匆匆shutdown啊。在网上阅读了一些文章后发现，似乎问题不是出在线程池上，而是单元测试！还记得笔者在文章开始的时候说过这个测试代码是写在springboot的test文件夹下吗，也就是单元测试的位置，目测是在单元测试中，当主线程执行完之后，主线程所在bean就被回收了，不只是线程池，换成原生的线程创建方法都会有这么个问题。 那么怎么解决呢？严格来讲，这种情况只有在单元测试时才出现，所以不用太在意，但是如果非要解决，也是有办法的： 1asyncTaskExecutor.setWaitForTasksToCompleteOnShutdown(true); 加上这句，线程池就会等task都执行完才会shutdown了。 下面来讲上面的遗留问题：使用@async时，为什么异步方法不能和调用它的方法属于同一个类？ 其实要回答这个问题，最好的办法就是去理解和实现spring中的依赖注入，然后手写一个注解，下面给出参考自这篇文章的回答： spring 在扫描bean的时候会扫描方法上是否包含@Async注解，如果包含，spring会为这个bean动态地生成一个子类（即代理类，proxy），代理类是继承原来那个bean的。此时，当这个有注解的方法被调用的时候，实际上是由代理类来调用的，代理类在调用时增加异步作用。然而，如果这个有注解的方法是被同一个类中的其他方法调用的，那么该方法的调用并没有通过代理类，而是直接通过原来的那个 bean 也就是 this. method，所以就没有增加异步作用，我们看到的现象就是@Async注解无效。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"async","slug":"async","permalink":"http://example.com/tags/async/"}]},{"title":"容器学习笔记","slug":"容器学习笔记","date":"2020-09-15T02:00:00.000Z","updated":"2023-05-29T14:17:39.320Z","comments":true,"path":"2020/09/15/容器学习笔记/","link":"","permalink":"http://example.com/2020/09/15/%E5%AE%B9%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"docker本质是个进程，通过cgroup, namespace和rootfs实现的一个特殊的进程。 kubernetes凌驾于docker之上，docker只是它的运行时的一种实现方式，除了运行时，k8s还有许多其他的部分。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Java中的类卸载","slug":"Java中的类卸载","date":"2020-09-06T04:00:00.000Z","updated":"2023-05-29T14:17:37.584Z","comments":true,"path":"2020/09/06/Java中的类卸载/","link":"","permalink":"http://example.com/2020/09/06/Java%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%8D%B8%E8%BD%BD/","excerpt":"","text":"为什么会有类卸载一说在一些场景中，比如java agent技术，我们attach到目标jvm的agent中的类被加载并且使用完后，它的使命就完成了，留着占用jvm内存，这时候就需要卸载掉。 如何卸载在之前的文章中有分享过类加载，有类加载就有类卸载，当这个类的Class对象不再被引用时，那它的生命周期就结束了。我们需要理解这么几个概念： 类加载器 Class对象 类的实例。 我们知道，类是由类加载器加载进来的，即ClassLoader加载Class. 然后，需要注意的是这里JVM自带的ClassLoader和Class是互相引用的，比如，Class对象是有一个getClassLoader方法来获得它的类加载其的。 同时，类的实例持有Class对象的引用，这一点可以从Object类的getClass方法中得知。 正如前面所说，JVM自带的类加载器会一直持有它所加载的Class对象的引用，这就意味着由JVM自带的类加载器加载的类是无法被卸载的。所以我们如果想要被加载的类能够被卸载，就需要自定义类加载器，其具体做法就是继承ClassLoader类，然后复写findClass()方法。 会有什么问题","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"类卸载","slug":"类卸载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8D%B8%E8%BD%BD/"}]},{"title":"Java中的Instrumentation","slug":"Java中的Instrument","date":"2020-09-04T14:00:00.000Z","updated":"2023-05-29T14:17:39.331Z","comments":true,"path":"2020/09/04/Java中的Instrument/","link":"","permalink":"http://example.com/2020/09/04/Java%E4%B8%AD%E7%9A%84Instrument/","excerpt":"","text":"前言在之前的文章里我们介绍了ASM字节码框架，使用它可以动态的修改class文件。但是仔细一想，你会发现仅仅ASM并不能真正用于生产，为什么？假如你已经有一个在运行的系统了，现在想要做一些字节码修改的动作，难道我们要去修改源代码吗？麻烦不说，而且污染了本来的系统。 所以我们就考虑，有没有什么方法，可以实现动态的无污染的织入，这就要引入今天的主角，Instrument了。 正文Instrumentation是Javaagent的一种具体实现，那javaagent又是什么？如果你在终端里输入java(当然前提是你已经安装了jdk), 你会看到这么几个参数： 其中，-javaagent就是我们所说的，jdk提供的Instrument允许我们在jvm启动或者运行时，动态地拦截要加载的类，并对其进行修改。无论是启动时还是运行时，其大致原理都是把我们的修改代码封装成一个Jar包，然后想办法让目标jvm进程加载。 instrumentation介绍先上一张图： instrumentation是什么？jdk中的一个接口，我们看看这个接口提供了哪些方法： 这里我也框出来了常用的几个方法，可以看到这几个方法基本都和ClassFileTransformer这个接口有关，那我们继续看下ClassFileTransformer的介绍。 其实从名字可以大概看出，ClassFileTransformer是对class文件进行转换的，再通俗点，就是用来修改字节码的。ClassFileTransformer这个接口只有一个方法transform: 123456byte[] transform( ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) 其中loader参数是加载这个类的类加载器，classfileBuffer就是载入内存中的class文件。可以看到这个方法返回值是个字节数组，如果返回null, 则表示对class文件不做处理，否则就用返回的字节数组代替原来的类。 当我们使用addTransformer给instrumentation添加ClassFileTransformer后，后续所有JVM加载类的时候都会被ClassFileTransformer的transform方法拦截。 上面大概介绍了instrumentation和ClassFileTransformer，下面的部分会介绍这两个东西如何结合起来使用。如上文所说，instrumentation的原理大概是：把我们的修改代码封装成一个Jar包（即agent），然后想办法让目标jvm进程加载。那就涉及到一个问题：目标jvm何时加载？java agent提供了两种手段，分别是在jvm启动时加载和jvm运行时加载。 JVM启动时加载instrument agent主要用到了premain()方法， 从名字也可以看出，premain其实就是在main函数之前执行，所以也就是会在main函数执行之前拦截类的加载，并做一些改造，premain函数如下： 1public static void premain(String agentArgs, Instrumentation inst) 其中第一个参数agentArgs是agent启动时的参数，第二个参数就是我们的主角，instrumentation. 一般的一个操作流程是使用instrumentation的addTransformer方法添加一个ClassFileTransformer, 而这个ClassFileTransformer里面的transform方法一般就是我们施展拳脚的地方，在这里可以对字节码进行修改等操作。下面的代码实现了一个简单的Agent 123456789101112131415161718192021import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.lang.instrument.Instrumentation;import java.security.ProtectionDomain;public class PreMainAgent &#123; public static void premain(String agentArgs, Instrumentation inst)&#123; System.out.println(&quot;agent args: &quot;+agentArgs); inst.addTransformer(new MyTransformer(),true); &#125; static class MyTransformer implements ClassFileTransformer&#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; System.out.println(&quot;premain load class: &quot;+className); return classfileBuffer; &#125; &#125;&#125; 然后我们需要把这个agent打包成jar包，这里我使用maven打包，通过配置pom.xml文件，核心内容如下： 12345678910111213141516171819&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;!--自动添加META-INF/MANIFEST.MF --&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Premain-Class&gt;PreMainAgent&lt;/Premain-Class&gt; &lt;Agent-Class&gt;PreMainAgent&lt;/Agent-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; 使用mvn package打包成Jar包，打包后的文件在/target目录下。 完成上述操作后，我们再单独建一个项目，来测试我们的agent, 1234567891011public class Test &#123; public static void main(String[] args) &#123; System.out.println(&quot;main start&quot;); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;main end&quot;); &#125;&#125; 如果是在idea里运行的话，我们需要在add configuration里面配置一下： 主要就是关注下这个javaagent参数就行，然后运行，走起，输出如下： 123456789101112131415agent args: nullpremain load class: java/util/concurrent/ConcurrentHashMap$ForwardingNodepremain load class: java/util/jar/Attributespremain load class: java/util/jar/Manifest$FastInputStream...(此处省略若干)main startpremain load class: java/net/URI...（此处省略若干）premain load class: sun/nio/cs/US_ASCII$Decodermain endpremain load class: java/lang/Shutdownpremain load class: java/lang/Shutdown$LockProcess finished with exit code 0 至此，流程走通。 那么这种jvm启动时就加载agent的方式有没有什么问题呢？首先好处肯定是有的，因为此时agent加载的时候大部分类还没加载，这个时候可以实现对新加载的类的进行字节码修改。但是！如果premain方法执行失败或者抛异常，那么jvm进程会被终止，这就有点难以接受了。（这段话摘自占小狼的博客） 因此，在jdk1.6中，又提出了另一种方法。 JVM运行时加载instrument agent主要用到了agentmain()方法， instrument原理使用instrument有什么问题TODO: 类隔离 反射","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Instrument","slug":"Instrument","permalink":"http://example.com/tags/Instrument/"}]},{"title":"ASM字节码","slug":"ASM字节码注入","date":"2020-08-30T05:00:00.000Z","updated":"2023-05-29T14:17:39.391Z","comments":true,"path":"2020/08/30/ASM字节码注入/","link":"","permalink":"http://example.com/2020/08/30/ASM%E5%AD%97%E8%8A%82%E7%A0%81%E6%B3%A8%E5%85%A5/","excerpt":"","text":"写这篇文章是因为在开水团实习的时候的一个项目用到了这个技术，在这里重新做下总结和梳理。 什么是ASMASM是一个字节码操作框架，使用它可以动态地修改class文件，或者让类被加载到虚拟机之前修改一些行为。 ASM有什么用一言以蔽之，AOP. 说到AOP，可能会想到Spring的JDK动态代理Proxy或者CGLIB. 这里JDK动态代理底层使用反射实现，众所周知反射的性能比较差。而CGLIB, 其实ASM和CGLIB是有关系的。 怎么用ASM提供了两种API：基于事件触发的Core API和基于对象的Tree API, 其区别就在于解析class文件的方式不同。下面会主要介绍Core API. 先列出主要知识点： Core API有三个核心类：ClassReader,ClassWriter,ClassVisitor. 整体使用了Visitor模式。 首先, ClassReader, 听名字就知道是用来读取Class文件的，当然并不是简单的读文件操作啦，它还会分析class文件的结构之类的，给它分析的明明白白的放到内存里。 然后，这个ClassReader会作为Visitor模式中的被访问者，开辟一个accept接口，放进来一个ClassVisitor，进行一些visit操作。这里需要注意的一个点是，visit方法里面具体的visit顺序ASM已经固定好了，我们只需要按照自己的需求去覆盖一些visit方法即可。它的一个时序图如下： 而ClassWriter是ClassVisitor抽象类的一个实现类，剋把最终修改的字节码以byte数组的形式返回。 下面通过具体的例子来看下ASM是如何操作的。 先来一个测试类： 1234public class Test1 &#123; private int a; public void method()&#123;&#125;&#125; 再来一手javac Test1.java, 编译得到Test1.class. 现在开始ASM秀。 1. 访问类的方法和字段12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package asm;import jdk.internal.org.objectweb.asm.*;import java.io.*;import static jdk.internal.org.objectweb.asm.Opcodes.ASM5;public class Main1 &#123; public static void main(String[] args) &#123; try &#123; new Main1().visitMethodAndField(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void visitMethodAndField() throws IOException &#123; //先读class文件 byte[] classBytes = toByteArray(&quot;E:\\\\IntelliJidea\\\\workspace\\\\Test2\\\\src\\\\asm\\\\Test1.class&quot;); ClassReader cr = new ClassReader(classBytes); ClassWriter cw = new ClassWriter(0); ClassVisitor cv = new ClassVisitor(ASM5,cw) &#123; @Override public FieldVisitor visitField(int i, String s, String s1, String s2, Object o) &#123; System.out.println(&quot;field:&quot;+s); return super.visitField(i, s, s1, s2, o); &#125; @Override public MethodVisitor visitMethod(int i, String s, String s1, String s2, String[] strings) &#123; System.out.println(&quot;method:&quot;+s); return super.visitMethod(i, s, s1, s2, strings); &#125; &#125;; cr.accept(cv, ClassReader.SKIP_CODE | ClassReader.SKIP_DEBUG); &#125; public byte[] toByteArray(String filename) throws IOException &#123; File f = new File(filename); if (!f.exists()) &#123; throw new FileNotFoundException(filename); &#125; ByteArrayOutputStream bos = new ByteArrayOutputStream((int) f.length()); BufferedInputStream in = null; try &#123; in = new BufferedInputStream(new FileInputStream(f)); int buf_size = 1024; byte[] buffer = new byte[buf_size]; int len = 0; while (-1 != (len = in.read(buffer, 0, buf_size))) &#123; bos.write(buffer, 0, len); &#125; return bos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); throw e; &#125; finally &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; bos.close(); &#125; &#125;&#125; 输出： 123field:amethod:&lt;init&gt;method:method 几个需要注意的点： ClassWriter构造函数的参数，这里是一个标志位，可以用来标志是否修改这个类的默认行为，必须是0或者COMPUTE_MAXS或者COMPUTE_FRAMES: COMPUTE_MAXS: 一个标志位用来自动计算stack size的最大值和方法局部变量的最大值。如果这个标志位被设置，那么visitMethod()返回的对象MethodVisitor的方法visitMaxs的参数将会被忽略。 COMPUTE_FRAMES: 用来计算stack map frames的标志位。 ClassVisitor的第一个参数，表示ASM版本。 这个init是我们的构造方法。 上面的代码也实锤了这个ClassVisitor是一个抽象类，我们实现它的时候，需要复写的方法有： 2. 添加字段或方法12345678910111213141516171819202122232425262728293031323334353637383940package asm;import jdk.internal.org.objectweb.asm.*;import java.io.File;import java.io.IOException;import static jdk.internal.org.objectweb.asm.Opcodes.ASM5;public class Main2 &#123; public void addField() throws IOException &#123; byte[] classBytes = ByteUtil.toByteArray(&quot;E:\\\\IntelliJidea\\\\workspace\\\\Test2\\\\src\\\\asm\\\\Test1.class&quot;); ClassReader cr = new ClassReader(classBytes); ClassWriter cw = new ClassWriter(0); ClassVisitor cv = new ClassVisitor(ASM5,cw) &#123; @Override public void visitEnd() &#123; super.visitEnd(); FieldVisitor fv = cv.visitField(Opcodes.ACC_PUBLIC,&quot;str&quot;,&quot;Ljava/lang/String;&quot;,null,null); if(fv!=null) fv.visitEnd(); &#125; &#125;; cr.accept(cv, ClassReader.SKIP_CODE | ClassReader.SKIP_DEBUG); byte[] classModifyed = cw.toByteArray(); ByteUtil.byteArray2File(new File(&quot;E:\\\\IntelliJidea\\\\workspace\\\\Test2\\\\src\\\\asm\\\\ModifiedTest1.class&quot;),classModifyed); &#125; public static void main(String[] args) &#123; try &#123; new Main2().addField(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 最后javap ModifiedTest1.class: 123456public class asm.Test1 &#123; public java.lang.String str; public asm.Test1(); public void method();&#125; 几个需要注意的点： 这里我们添加方法是使用了visiteEnd()方法，从前面的时序图可以看出，它是最后一个visit方法，用以告诉ASM visit结束。 还需要注意的是这里使用了责任链模式。 新增方法操作类似，不再赘述。 3. 删除方法和字段删除操作比较简单，只需要在visiteMethod或者visiteField中返回null即可。 同样以Test1.class为例，我们删除方法method. 12345678910111213141516171819202122232425262728293031323334353637383940package asm;import jdk.internal.org.objectweb.asm.*;import java.io.File;import java.io.IOException;import static jdk.internal.org.objectweb.asm.Opcodes.ASM5;public class Main3 &#123; public void removeMethod() throws IOException &#123; byte[] classBytes = ByteUtil.toByteArray(&quot;E:\\\\IntelliJidea\\\\workspace\\\\Test2\\\\src\\\\asm\\\\Test1.class&quot;); ClassReader cr = new ClassReader(classBytes); ClassWriter cw = new ClassWriter(0); ClassVisitor cv = new ClassVisitor(ASM5,cw)&#123; @Override public MethodVisitor visitMethod(int i, String s, String s1, String s2, String[] strings) &#123; if(s.equals(&quot;method&quot;)) return null; return super.visitMethod(i, s, s1, s2, strings); &#125; &#125;; cr.accept(cv, ClassReader.SKIP_CODE | ClassReader.SKIP_DEBUG); byte[] classModifyed = cw.toByteArray(); ByteUtil.byteArray2File(new File(&quot;E:\\\\IntelliJidea\\\\workspace\\\\Test2\\\\src\\\\asm\\\\RemovedMethodTest1.class&quot;),classModifyed); &#125; public static void main(String[] args) &#123; try &#123; new Main3().removeMethod(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 通过javap查看，发现已删除。 4. 修改方法内容","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"ASM","slug":"ASM","permalink":"http://example.com/tags/ASM/"}]},{"title":"关于跨域","slug":"关于跨域","date":"2020-08-06T11:00:00.000Z","updated":"2023-05-29T14:17:39.317Z","comments":true,"path":"2020/08/06/关于跨域/","link":"","permalink":"http://example.com/2020/08/06/%E5%85%B3%E4%BA%8E%E8%B7%A8%E5%9F%9F/","excerpt":"","text":"什么是跨域往粗了说，就是一个站点的脚本或者文档企图访问另一个站点的资源，这是一种广义的定义。但通常我们说的是狭义的跨域，而狭义的跨域是和同源策略绑定在一起的。 什么是同源策略同源策略是浏览器的一种安全策略，是为了防止一个源下的资源去访问另一个源下的资源。所谓同源，是指协议+域名+端口相同。 为什么会有跨域跨域是实实在在存在的，往小了说，前端加载的静态资源可能来自其他域，比如加载css样式或者图片等，当然这种跨域是允许的。同源策略限制的跨域主要有： 一个域读取另一个域的LocalStorage或者Cookie. Dom和Js对象无法获得 Ajax请求不能发送。 如果这些行为被允许，这意味着我可以在一个恶意网站里去请求一些正常网站，比如银行，同时还能带上你刚刚在正常网站登录后留下的cookie, 这样我就可以登录了，然后我在恶意网站里对银行网站发起一些给自己转款的请求…… 怎么解决跨域解决方案比较多，作为后端，我用的比较多的有跨域资源共享（CORS）和Nginx反向代理。 Nginx反向代理因为同源策略是浏览器的操作，而在服务端跨域是可以正常请求的，反向代理原理也就在这里。以Nginx作为服务端，对于前端的跨域请求，以Nginx作为跳板，在Nginx服务端重新去请求，就可以解决跨域了。","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"跨域","slug":"跨域","permalink":"http://example.com/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"同源策略","slug":"同源策略","permalink":"http://example.com/tags/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5/"}]},{"title":"从集合类开始","slug":"从集合类谈起","date":"2020-07-26T10:00:00.000Z","updated":"2023-05-29T14:17:39.327Z","comments":true,"path":"2020/07/26/从集合类谈起/","link":"","permalink":"http://example.com/2020/07/26/%E4%BB%8E%E9%9B%86%E5%90%88%E7%B1%BB%E8%B0%88%E8%B5%B7/","excerpt":"","text":"此文为我在备战秋招过程中对Java基础知识的启发式总结。 Java集合类，有Set, List, Queue. List底下有Vector, ArrayList, LinkedList. Vecotr底下还有个Stack. 讲一讲区别？ 要说区别的话，Vector和ArrayList底层都是动态数组，不同的是Vector是线程安全的，因为它的方法有被**synchronized**关键字修饰， 还有就是扩容，ArrayList是1.5倍扩容，关于这点可参考这篇文章, 而Vector一般是两倍扩容（为什么说是一般呢，是不是两倍取决于我们new Vector的时候有没有传容量参数）。 然后Stack继承自Vector,所以它也是线程安全的。 讲一讲锁、Synchronized关键字？ 而LinkerList底层是链表，还有一点就是LinkedList实现了Queue接口，所以它可以当做队列来用(准确的来说，应该是个双端队列)。 而Set的实现主要有HashSet, TreeSet, 还有一个LinkedHashSet, 它继承自HashSet, 但是性质有所不同。 HashSet底层其实也是个HashMap, 只不过把HashMap的value变成一个静态对象了。 TreeSet底层是红黑树，目的就是可以实现排序。 LinkedHashSet继承自HashSet, 它俩的区别类似于HashMap和LinkedHashMap的区别（准确的说不是类似，是等同，因为它的），其区别就在于我们可以按照存入的顺序按序把元素取出。 LinkedHashSet或LinkedHashMap的这个特性是如何实现的呢？LinkedHashMap内部是有一个双向链表的（准确说是维护一个静态内部类Entry, 继承自Node），通过这个双向链表来维护顺序。具体体现在： 1234567891011// link at the end of list private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; &#125; 聊聊红黑树？ Map准确讲不能算在集合类里面，但是也很常用，Map接口底下主要有HashMap, TreeMap, HashTable, 以及继承自HashMap的LinkedHashMap. 谈谈区别 HashMap是数组+链表结构，用于存放键值对，HashTable也是，不同的是HashTable线程安全，因为它的put等方法是用synchronized关键字修饰的。TreeMap可以实现排序,之所以有这个功能是因为它的底层是红黑树，所以每次put都是相当于是按序插入。LinkedHashMap继承自HashMap, 上面在将LinkedHashSet的时候讲过，它可以按照插入顺序取出元素。 谈谈HashMap的扩容 HashMap是数组+链表的结构，它比较有趣的地方就在于它的put和扩容了。它的构造方法有以下几种： 123public HashMap(int initialCapacity, float loadFactor) public HashMap(int initialCapacity)public HashMap() 其中，initialCapacity是”初始容量“，loadFactor是负载因子。注意这里初始容量加了引号，意味着这并不一定是真的初始容量，它会根据传入的这个initialCapacity, 计算一个离它最近的比它的二的次幂作为真实容量。具体操作如下： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; （有一说一，这个写法有点灵性） 而负载因子的意思其实就是阈值，它表示当HashMap的容量达到多少时要进行一个扩容操作。 当我们使用无参的构造函数时，它俩默认值分别是16和0.75. 谈谈HashMap和ConcurrentHashMap? HashMap不是线程安全的，所以有了ConcurrentHashMap, 虽然HashTable也是线程安全的，但是两者实现略有不同，性能也有所差异。HashTable是通过synchronized关键字实现的，而ConcurrentHashMap在1.7和1.8中实现略有不同。1.7是通过分段锁实现的，1.8是通过CAS+synchronized实现的。 分段锁：首先是有一个Segment数组，这个数组的每一个元素指向的才是一个真正的HashMap, 这个Segment对象继承自ReentrantLock, 所以是有锁的功能的。基于分段锁的ConcurrentHashMap理论上最大可以达到Segment数组size的并发度。 1.8的ConcurrentHashMap放弃了分段锁的技术，使用CAS+synchronzied来保证线程安全。在插入的时候，先CAS插入，如果失败，则用synchronized加锁插入。 谈谈ReentrantLock?","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[]},{"title":"Spring源码学习之AOP","slug":"Spring源码学习之AOP","date":"2020-03-21T04:35:04.000Z","updated":"2020-03-21T05:00:00.000Z","comments":true,"path":"2020/03/21/Spring源码学习之AOP/","link":"","permalink":"http://example.com/2020/03/21/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8BAOP/","excerpt":"","text":"经过供应链大佬的预面试，觉得自己在Spring这一块掌握地还是有些浅，痛定思痛，再次阅读源码。 在上一篇文章中我们已经分析了Spring IOC的一个大概过程，那么AOP又是在什么时候发生的呢？（这篇文章不讲动态代理，不讲切面切点通知，只讲代码流程。） 缘起Spring AOP很关键的一步就是创建AOP 代理，那么这一动作是何时发生的呢？ 众所周知（不知道也没关系），创建代理对象有一种专门的类叫ProxyCreator, 那么如果是基于注解创建的话，这个类叫做AnnotationAwareAspectJAutoProxyCreator, 如果去看它的继承关系你会发现，它实现了BeanPostProcessor接口，这个接口我们在上篇文章中也提到了：Bean的实例化主要经过三个方法：createBeanInstance,populateBean,initializeBean.其中最后一个方法就是用来处理各种回调，其中就包括BeanPostProcessor,那我们就接着上一节讲的BeanPostProcessor的回调来继续讲。 开始先到BeanPostProcessor的后置处理这里， AbstractAutowireCapableBeanFactory 1633行 123if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; applyBeanPostProcessorsAfterInitialization: 123456789101112public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessAfterInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result; &#125; 进入到AbstactAutoProxyCreator,已经发现了ProxyCreator的影子了有木有？： 123456789public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125; wrapIfNecessary(): 我就只截取关键代码啦 这里的意思就是说，如果我们这个Bean有Advice或者Advisor的话，那么我们就开始创建代理，很容易理解有木有？ createProxy(): 这里代码略多，我就不贴了，它的核心逻辑就是先获取并设置一个代理工厂，然后从代理工厂里获取代理，方法的最后一句是这样的： 1return proxyFactory.getProxy(getProxyClassLoader()); 来到Class ProxyFactory: 123public Object getProxy(ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); &#125; 从名字就可以看出来，创建AopProxy createAopProxy(): 123456protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this); &#125; createAopProxy(): 从这里就可以看出，根据targetClass有没有接口之类的，决定用Jdk动态代理还是Cglib. 至此，createProxy()已经完成，我们再回到上面ProxyFactory的getProxy()方法： 123public Object getProxy(ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); &#125; 继续看下jdk代理的getProxy()做了什么： 来到了熟悉的jdk动态代理有木有。众所周知第三个参数是InvocationHandler接口的实现类，这里用了this, 说明这个类自己实现了InvocationHandler接口，我们来看下它复写的invoke()方法。这个方法就厉害了，它涉及到拦截器调用链的执行，我这里只截取了部分核心代码。 首先它会去获得当前方法的一个拦截器链，获得之后，如果这个chain不为空，我们就把这个拦截器链创建成一个method invocation，然后去执行。那么这个proceed()就是一个责任链模式的执行过程。 总结关于Spring的AOP, 我们要知道这么几个问题， 首先AOP从什么时候开始的，答案是BeanPostProcessor,也就是说，Spring AOP 会在 IOC 容器创建 bean 实例的最后对 bean 进行处理。其实就是在这一步进行代理增强。 AOP分为两步，createProxy和getProxy. 其中createProxy有jdk和cglib两种方法。而getProxy是我们最需要注意的。以jdk动态代理为例，它的invoke方法里包含了以责任链模式对拦截器的调用。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring思考与总结","slug":"Spring思考与总结","date":"2020-03-19T14:44:20.000Z","updated":"2023-05-29T14:17:37.599Z","comments":true,"path":"2020/03/19/Spring思考与总结/","link":"","permalink":"http://example.com/2020/03/19/Spring%E6%80%9D%E8%80%83%E4%B8%8E%E6%80%BB%E7%BB%93/","excerpt":"","text":"更新于2020-10-01 从IoC的角度来说，spring是个容器，这个容器就是BeanFactory, 当然你说它是ApplicationContext也没有问题。容器是用来装东西的，装的东西就是我们定义的bean, 不过spring对它进行了封装，叫做BeanDefinition. 所以spring初始化的过程中，首先会做这么几件事情： 创建容器 创建beandefinition 向容器里注册beandefinition Spring是容器，最基本的容器是BeanFactory, 然后ApplicationContext又继承自它，但其实不能认为ApplicationContext是BeanFactory的实现类，因为事实是ApplicationContext内部持有了一个实例化的BeanFactory(DefaultListableBeanFactory). refresh方法是整个容器启动的核心。方法主要有以下几个功能： obtainFreshBeanFactory(): 创建容器，加载注册Bean. prepareBeanFactory(): 设置类加载器，添加BeanPostProcessor finishBeanFactoryInitialization(beanFactory)：初始化所有的Singleton Beans createBeanInstance: 实例化bean populateBean: 属性设置，处理依赖 initializeBean: 处理各种回调 检查aware相关接口（aware接口是为了让bean可以获取到框架自身的一些对象） BeanPostProcessor前置处理 如果实现InitializeBean, 调用afterPropertiesSet() BeanPostProcessor后置处理‘ BeanDefinition是Bean装载进容器中的一种表示，里面具体有是否是单例，它的依赖，是否懒加载，类名称，等等。","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring源码学习","slug":"Spring源码学习之IOC","date":"2020-03-18T10:46:22.000Z","updated":"2023-05-29T14:17:37.595Z","comments":true,"path":"2020/03/18/Spring源码学习之IOC/","link":"","permalink":"http://example.com/2020/03/18/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8BIOC/","excerpt":"","text":"今天面试被问到了Spring, 被面试官吊捶，痛定思痛，决定重新开始学习源码！ 首先Spring容器的顶层容器接口是什么？BeanFactory和ApplicationContext, 其中ApplicationContext加了一些上下文的支持，更为高级一点。 以ClassPathXmlApplicationContext为例，容器初始化的入口方法在哪里呢？refresh()方法。 refresh()进来后有几处核心方法，我们来一一看下。 第一处 obtainFreshBeanFactory(): 这个方法又调用了refreshBeanFactory(),主要做了两件事情：创建容器，加载BeanDefinition，也就是我们常说的容器初始化三步走的第一步。 12DefaultListableBeanFactory beanFactory = createBeanFactory();loadBeanDefinitions(beanFactory); 继续看下这个loadBeanDefinition()： 可以看到里面的代码分为两部分，第一部分就是创建并设置一个读取器，用来读取资源文件，第二部分就是加载BeanDefinition,好，继续深入。 这里的代码也是很言简意赅，主要就是看我们的资源文件是以什么形式存在的，从而决定加载的是Resource还是String. 调试了一手发现我们这个走的是第一种类型，好，继续看： 代码依旧简单，我们来看最核心的这一行干了啥： 1234@Override public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(new EncodedResource(resource)); &#125; 继续深入loadBeanDefinitions()： 这个代码比较长，我就只截取最重要的部分进行说明了 这个代码主要做的工作就是负责从xml里面装载BeanDefinition. 继续看doLoadBeanDefinitions(): 这里把xml转化成document, 然后执行registerBeanDefinitions()方法。 继续看registerBeanDefinitions(): 代码依旧简单，主要分为两部分：首先创建一个Reader, 然后由reader进行注册。这两部分都很重要，我们一一来看： 创建Reader: 进行注册： 代码简单，继续深入： doRegisterBeanDefinitions(): 这里面最核心的一句： parseBeanDefinitions(root, this.delegate); 继续深入： parseDefaultElement(ele, delegate); 继续深入： 这里就厉害了，根据不同的节点名字进行不同的操作，那我们主要是加载bean, 那么节点名肯定就是BEAN_ELEMENT了，继续深入： 继续来看下是如何解析Element的： 解析的方法叫这个名字 public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) 可以看到它返回了一个BeanDefinitionHolder, BeanDefinitionHolder是对BeanDefinition的进一步封装，不信我们可以来看这个方法的返回值： return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); 可以看到里面封装了beanName,alias以及beanDefinition,那么beanDefinition又是在哪里定义的? 这个方法里有这么一句代码： 12AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean);","categories":[],"tags":[]},{"title":"Spring循环依赖","slug":"Spring循环依赖","date":"2020-02-18T05:13:01.000Z","updated":"2023-05-29T14:17:39.334Z","comments":true,"path":"2020/02/18/Spring循环依赖/","link":"","permalink":"http://example.com/2020/02/18/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/","excerpt":"","text":"要谈Spring循环依赖，首先要知道Spring何时进行依赖注入。在以前的文章中我们有提到，IoC容器初始化时，要经历BeanDefinition的Resource定位，BeanDefinition的载入解析以及BeanDefinition在IoC容器中的注册，经过上述过程后，IoC容器的初始化就完成了，里面的BeanDefinition也有了，然后才发生依赖注入。而循环依赖就是在依赖注入过程中发生的A依赖于B而B有依赖于A的现象。 接下来再说Spring中发生循环依赖会怎样。 spring中的循环依赖有三种情况： 构造器循环依赖：spring处理不了，抛出异常BeanCurrentlylnCreationException 单例模式下的setter循环依赖：通过三级缓存处理。 非单例循环依赖：无法处理。 构造器循环依赖： 将正在创建的bean记录在缓存中，如果一个bean在创建过程中发现自己已经被记录了，则抛出BeanCurrentlylnCreationException异常。 setter循环依赖： Spring为了解决单例的循环依赖问题，使用了三级缓存。 1234567/** Cache of singleton objects: bean name –&gt; bean instance */private final Map singletonObjects = new ConcurrentHashMap(256);/** Cache of singleton factories: bean name –&gt; ObjectFactory */private final Map&gt; singletonFactories = new HashMap&gt;(16);/** Cache of early singleton objects: bean name –&gt; bean instance */private final Map earlySingletonObjects = new HashMap(16);复制代码 这三级缓存的作用分别是： singletonFactories ： 进入实例化阶段的单例对象工厂的cache （三级缓存） earlySingletonObjects ：完成实例化但是尚未初始化的，提前暴光的单例对象的Cache （二级缓存） singletonObjects：完成初始化的单例对象的cache（一级缓存） 我们在创建bean的时候，会首先从cache中获取这个bean，这个缓存就是sigletonObjects。主要的调用方法是： 12345678910111213141516171819202122protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); //isSingletonCurrentlyInCreation()判断当前单例bean是否正在创建中 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); //allowEarlyReference 是否允许从singletonFactories中通过getObject拿到对象 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); //从singletonFactories中移除，并放入earlySingletonObjects中。 //其实也就是从三级缓存移动到了二级缓存 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125;复制代码 从上面三级缓存的分析，我们可以知道，Spring解决循环依赖的诀窍就在于singletonFactories这个三级cache。这个cache的类型是ObjectFactory，定义如下： 1234public interface ObjectFactory&lt;T&gt; &#123; T getObject() throws BeansException;&#125;复制代码 这个接口在AbstractBeanFactory里实现，并在核心方法doCreateBean（）引用下面的方法: 1234567891011protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125;&#125;复制代码 这段代码发生在createBeanInstance之后，populateBean（）之前，也就是说单例对象此时已经被创建出来(调用了构造器)。这个对象已经被生产出来了，此时将这个对象提前曝光出来，让大家使用。 这样做有什么好处呢？让我们来分析一下“A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了初始化的第一步，并且将自己提前曝光到singletonFactories中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，进去了一级缓存singletonObjects中，而且更加幸运的是，由于B拿到了A的对象引用，所以B现在hold住的A对象完成了初始化。 检测循环依赖的过程如下： A 创建过程中需要 B，于是 A 将自己放到三级缓里面 ，去实例化 B B 实例化的时候发现需要 A，于是 B 先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了！ 然后把三级缓存里面的这个 A 放到二级缓存里面，并删除三级缓存里面的 A B 顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态） 然后回来接着创建 A，此时 B 已经创建结束，直接从一级缓存里面拿到 B ，然后完成创建，并将自己放到一级缓存里面 如此一来便解决了循环依赖的问题 所以总结以下，解决setter循环依赖的方法就是在循环依赖之前给他设置了阶梯，或者说分了层，使得那种没有被完全初始化好的对象可以作为被依赖去完成依赖对象的初始化（也就是提前曝光）。 spring单例对象初始化经过以下过程： createBeanInstance: 调用构造方法对对象进行实例化。 populateBean: 属性填充 initializeBean: 调用xml中的init方法 所以循环依赖发生在第一二步。 参考：链接：https://juejin.im/post/5c98a7b4f265da60ee12e9b2","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Java中的动态代理","slug":"Java中的动态代理","date":"2020-02-16T09:41:44.000Z","updated":"2023-05-29T14:17:39.394Z","comments":true,"path":"2020/02/16/Java中的动态代理/","link":"","permalink":"http://example.com/2020/02/16/Java%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"最近在看Spring中的AOP, 其实现主要是靠动态代理，所以打算先了解一下动态代理。 要说动态代理，需要先知道什么是代理，既然是动态代理，那么有没有静态代理，区别又在哪里。 何为代理，最直观的，我们fq时会用到小飞机或者其他的正向代理，说白了就是让代理代替我们去做某件事，在设计模式中专门有一个代理模式，我们可以先来看下代理模式的类图。 其中ProxyImage就是代理对象，代理了RealImage, 它们实现了共同的接口，同时ProxyImage聚合了RealImage, 通过在ProxyImage的display方法中调用RealImage的display,达到代理的作用。 这样的代理我们也可以称之为静态代理，为什么这么说呢？因为这种代理关系是代码被编译成字节码时就存在的，而动态代理则不一样，它的代理关系是运行期动态创建的。说到运行期、动态，你想到了什么？反射。没错，其实动态代理就是用到了反射。 Java中常用的动态代理技术有JDK动态代理以及CGLIB动态代理。 基于JDK的动态代理核心有两个方法需要掌握： 首先要实现动态代理，代理需要继承InvacationHandler类，在代理类中实现代理对象和被代理对象的绑定，用的是Proxy.newProxyInstance()方法，然后需要重写一个invoke()方法，举一个廖雪峰大佬网站的例子 123456789101112131415161718192021222324public class Main &#123; public static void main(String[] args) &#123; InvocationHandler handler = new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method); if (method.getName().equals(&quot;morning&quot;)) &#123; System.out.println(&quot;Good morning, &quot; + args[0]); &#125; return null; &#125; &#125;;mornin Hello hello = (Hello) Proxy.newProxyInstance( Hello.class.getClassLoader(), // 传入ClassLoader new Class[] &#123; Hello.class &#125;, // 传入要实现的接口 handler); // 传入处理调用方法的InvocationHandler hello.morning(&quot;Bob&quot;); &#125;&#125;interface Hello &#123; void morning(String name);&#125; 代码中生成了代理hello, 可以看到它和被代理对象是同一类型的，当执行代理对象的morning()方法时，就会调用handler的invoke方法，当然了，在invoke方法里我们一方面调用了被代理对象的morning方法，一方面加入我们自己的逻辑。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"动态代理","slug":"动态代理","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"假如我是面试官","slug":"假如我是面试官","date":"2020-02-14T13:45:34.000Z","updated":"2023-05-29T14:17:39.333Z","comments":true,"path":"2020/02/14/假如我是面试官/","link":"","permalink":"http://example.com/2020/02/14/%E5%81%87%E5%A6%82%E6%88%91%E6%98%AF%E9%9D%A2%E8%AF%95%E5%AE%98/","excerpt":"","text":"最近阿里各部门已经陆续开始春招，自己也写完了项目最后的一部分，简历也刚刚完成了1.0版本，但是仍旧按捺不住躁动的内心。对于简历投递与面试，我是既期望又紧张，害怕它来又怕他不来。与其临渊羡鱼，不如退而结网，有躁动的功夫，不如温习一下知识点，正好最近一直在写项目, 知识点也快忘的差不多了。接下来打算结合自己的简历，从面试官的角度，对自己进行提问。 Java 集合类是否了解？ Set List Queue List: Vector, ArrayList, LinkedList, Stack Set: TreeSet, HashSet Queue Vector和ArrayList区别 首先要明确一点，从List接口下来的主要有三个实现类，Vector, ArrayList, LinkedList. Vector和ArrayList底层都是动态数据，不同的是Vector是线程安全（synchronized修饰） 所以如果说有哪些线程安全的List, 那就有SynchronizedList, Vector, CopyOnWriteList. 然后！Stack又是继承自Vector, 所以Stack也是线程安全的（这都不知道，罪孽啊）。 Set 和 List 区别 同步容器有哪些 Vector Stack HashTable HashMap是否了解 初始容量，负载因子，扩容？ 容量为什么是2的因子 插入：头插尾插？ 1.7是头插， 如何计算hash, 计算hash的时候为什么要取模 hashCode和equals的重写， equals和==的区别 HashMap有什么问题？ 做结构性修改的时候不安全，总结来说，头插涉及到好几个代码片段，他们不是原子操作，那么多线程时就会出事，比如形成环形链表。 针对HashMap的这些弊端有解决措施吗？ ConcurrentHashMap 讲一讲ConcurrentHashMap 1.7中使用分段锁， 1.8中使用CAS+synchronized, 1.8中引入了红黑树，1.7和1.8中size()方法也不一样，1.7中多次计算，然后决定是否加锁，1.8中使用baseCount+CounterCell 为什么从1.7的分段锁变成了1.8的CAS+synchronized 谈谈你对synchronized关键字的理解 是一种Java内置的锁，修饰方法或者代码块，修饰代码块时，底层是moniterenter和monitorexit指令实现的，也就是加锁的意思。 内存语义：可见性，原子性，有序性 synchronized和lock synchronized是内置的，lock是基于AQS的 synchronized等待中的线程不能响应中断，lock等待队列中的线程是可以相应中断的。 synchronized是非公平锁，ReentrantLock默认非公平锁，可以设置为公平锁。 synchronized发生异常时会自动释放，lock需要手动释放 synchronized是获取锁还是进入等待队列我们是不知道的，但是通过Lock的tryLock可以得知有没有获取锁成功。 lock可以有多个condition Monitor机制是否了解 volatile关键字是否了解 对Java中锁的了解 CAS是什么 聊聊你熟悉的设计模式 Java内存模型， JVM内存模型，类加载，垃圾回收，OOM fail-fast 和 fail-safe HashMap 和HashTable区别 继承不同：一个实现map接口，一个来自Dictionary 线程安全不同 允不允许null值：HashMap允许键或者值为null, 且只允许有一个键为null的值（因为如果有多个键为null时，我怎么知道我get的null是哪个null），但是可以有一个或者多个键的值为null, 且当hashmap中没有某个键时，get方法会返回null, 所以说，我们不能用get方法来判断hashmap中是否有某个键(因为get方法返回null的时候，可能是值为null, 也可能是key不存在)，而应该用containsKey() 线程池拒绝策略&gt; 直接丢弃 &gt; &gt; 丢弃队列中最老的 &gt; &gt; 抛出异常 &gt; &gt; CallerRunsPolicy: 将任务分给调用线程去执行 线程安全的list Vector 很古老 CopyOnWriteArrayList juc包中的，锁住了整个对象 synchronizedList Collections工具类中的 Spring为什么要用动态代理而不是静态代理？ 静态代理的代理关系是在编译期就生成的，比较死板，而且是需要从class文件转成运行时的类的，而动态代理比较灵活，直接在运行期生成字节码并加载到JVM中去，Spring中代理应该很多，用静态代理，不灵活，而且会生成很多不必要的class文件。 JUC 阻塞队列 ArrayBlockingQueue: 有界的阻塞队列 DelayQueue: 无界的阻塞队列，每个元素都有一个延时，只有过期了才能出队 LinkedBlockingQueue: PriorityBlockingQueue: SynchronousQueue: 只能装一个元素的队列 常见的OOM的情况 java.lang.OutOfMemoryError:Java heap space: 堆不够用了。或者内存泄漏 java.lang.OutOfMemoryError:GC overhead limit exceeded：当应用程序花费超过98%的时间用来做GC并且回收了不到2%的堆内存时，就会抛出该异常。 java.lang.OutOfMemoryError: PermGen space java.lang.OutOfMemoryError: Metaspace java.lang.OutOfMemoryError:Unable to create new native thread:线程建的太多了。 java.lang.OutOfMemoryError:Out of swap space? java.lang.OutOfMemoryError:Requested array size exceeds VM limit Out of memory:Kill process or sacrifice child ArrayList扩容， HashMap扩容 ArrayList的扩容是基于动态数组的，也就是说，当它的size快达到length时，会进行一个1.5倍的动态扩容，底层是通过Arrays.copyof()来实现的，这是一个浅拷贝。 Spring启动过程 web.xml中的ContextLoaderListener在容器启动时会触发初始化，调用contextInitialized, 初始化一个WebApplicationContext上下文。 然后初始化DispatcherServlet, 它会以上面得到的上下文作为自己的parent上下文，然后再初始化一个自己的上下文。 JUC工具类 CountDownLatch: 用于主线程等待子线程，主线程中设置await(),子线程中countDown()每次减一，只有当减到零的时候主线程中await()后面的内容才能继续执行。 如何实现：还是通过内聚AQS实现的，我们设置的count就是state, 每次的countDown()就是AQS的一个release操作，主线程的await()就是acquire()操作, 如果count不等于零，则假如同步队列自旋，自旋能出来的条件是count==0,总体来说套用还是AQS的框架。 CyclicBarrier: 作用和上面的差不多，用法相对简单，而且可以循环利用。上面的CountDownLatch主要用于一个线程等待其他线程都执行到某个地方时主线程才能继续，而CyclicBarrier主要用于多个线程之间互相等待，因为它只有一个await方法放在子线程中用于相互等待。 Samphare: 类似于操作系统中的信号量机制，一共五颗糖，那么也就最多只有五个线程能同时运行，只有当其中某个线程把糖还回来了其他线程没拿到糖的线程才能继续。 受检异常 非受检异常 受检异常:程序运行中容易出现的，情理可容的异常，出现了就要try catch或者throw 不受检异常：编译器不要求强制处理的异常，包括RunTimeException和Error Executor创建线程池 newCachedThreadPool 123return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); 核心池0，最大池Integer.MAX_VALUE,同步队列大小为1，所以相当于是每次都创建临时线程去工作的。 newSingleThreadExecutor 1234return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); 核心池1，最大池1，但是阻塞队列是无界的，LinkedBlockingQueue默认大小是Integer.MAX_VALUE,所以也容易造成OOM. newFixedThreadPool 123return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); 道理同上。 AQS Lock下的锁都是通过聚合一个AQS的子类来实现的，这里对AQS做一个简单的介绍。 AQS的核心有两个，一个是state, 一个是同步队列，通过对state值修改是否成功表示一个线程是否获取锁成功，未成功获取锁的线程则加入同步队列自旋。 AQS里还分了共享式获取锁和独占式获取锁，分别对应了不同的模板方法。 创建线程 继承Thread 继承Runnable Future + Callable: Future = service.submit(Callable) FutureTask包装Callable: service.submit(futuretask),通过futuretask.get获得结果 缓存一致性如何保证保证缓存一致性？ 加总线锁：CPU和其他部件的访问是通过总线进行的，总线加锁，那么就只能等一个CPU操作完了其他才能继续。 缓存一致性协议：当CPU写变量时发现该变量是共享变量时，就会通知其他CPU使他们的缓存无效，从而被迫只能从主存读取。 happens-before原则什么是happens-before？它是一套规则，这套规则阐述了多线程操作之间的内存可见性。 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。 Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 线程中断通过interrupt()方法可以修改标志位，然后监控标志位的变化伺机退出线程。这里需要注意，监控标注位的变化有两个方法： interrupted():静态方法，调用它时，标志位会被清除。这意味着如果你连着调用两次这个方法，那么第二次结果肯定是false. isInterrupted()：非静态方法，调用它时，标志位不会被清除 还需要注意的一点是如果被中断的线程是被wait()等方法阻塞的话，标志位会被清除且抛出一个中断异常，我们需要捕获异常进行退出。 线程状态 Spring核心方法Spring是容器，最基本的容器是BeanFactory, 然后ApplicationContext又继承自它，但其实不能认为ApplicationContext是BeanFactory的实现类，因为事实是ApplicationContext内部持有了一个实例化的BeanFactory(DefaultListableBeanFactory). refresh方法是整个容器启动的核心。方法主要有以下几个功能： obtainFreshBeanFactory(): 创建容器，加载注册Bean. prepareBeanFactory(): 设置类加载器，添加BeanPostProcessor finishBeanFactoryInitialization(beanFactory)：初始化所有的Singleton Beans createBeanInstance: 实例化bean populateBean: 属性设置，处理依赖 initializeBean: 处理各种回调 检查aware相关接口（aware接口是为了让bean可以获取到框架自身的一些对象） BeanPostProcessor前置处理 如果实现InitializeBean, 调用afterPropertiesSet() BeanPostProcessor后置处理‘ BeanDefinition是Bean装载进容器中的一种表示，里面具体有是否是单例，它的依赖，是否懒加载，类名称，等等。 JVMJVM内存结构本地方法栈 虚拟机栈 程序计数器 堆 方法区 方法区是一种规范，永久代是方法区的一种实现，jdk8以后，去掉了永久代，用元空间代替，元空间存在于直接内存中，同时把常量池放在了堆中， 常见的OOM 堆溢出：疯狂地给一个list里面加对象 虚拟机栈和本地方法栈：栈的请求深度大于本来深度时会栈溢出，比如递归没写base case的时候。疯狂创建线程的时候会造成OOM: unable to create native thread. 引用强引用：常见引用 软引用：内存溢出之前先回收软引用，如果回收了内存还不够再报异常。 弱引用：只能生存到下一次垃圾回收前 虚引用：唯一目的就是被回收时能收到一个系统通知。 stop the world枚举根节点的时候需要stop the world 如何实现自定义的类加载器 继承ClassLoader, 重写findClass方法。 垃圾收集器 serial ：采用复制算法的新生代收集器，单线程，需要stop the word ParNew: Serial的多线程版本，采用复制算法。 Parallel Scavenge: 并行的多线程新生代收集器，使用复制算法，关注吞吐量 Serial Old: Serial的老年代版本，使用标记-清除算法 Parallel Old: Parallel Scavenge老年代本，使用标记整理。 CMS收集器：Concurrent Mark-Sweep, 并发标记清除，分为： 初始标记：需要stop the world 并发标记： 重新标记 并发清除 它有什么问题呢？ cpu敏感，因为占用线程 无法处理浮动垃圾 内存碎片 G1收集器：Garbage-First, 特点 并行与并发 分代收集 空间整合：标记整理 可预测的停顿 避免全堆扫描 Remembered Set: G1收集器把堆分成若干个region, 当程序对引用类型进行操作时，会检查其引用的对象是否在不同的regon中，如果在，就把引用信息记录在remenbered set中。 CMS收集器设计原因：为了减少停顿以及和应用程序并行而设计。 G1收集器分成大小相同的若干region young GC: eden区满时会触发，这就涉及到要GC Root, 因为region的划分可能会使得老年代也引用了年轻代的对象，为了解决这个跨代问题，G1中引入了Rememer Set, 用来记录老年代的哪些对象引用了它。 global concurrent marking： 初始标记：stop the world, 标记了从GC Root开始直接可达的对象，期间执行一次young GC, 根区域扫描：主要扫描survivor, 并发标记: 最终标记: 使用snapshot-at-the-beginning(SATB)完成最终存活标记 清除垃圾 mixed GC:G1中的MIXGC选定所有新生代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region，在用户指定的开销目标范围内尽可能选择收益高的老年代Region进行回收。所以MIXGC回收的内存区域是新生代+老年代。 可以发现，global concurrent marking和CMS的过程是很类似的，不同的是G1中的global concurrent marking 是为mixed GC服务的。 和CMS相比的优势：有内存整理，可预测的停顿时间。 JVM命令 jmap: 生成堆转储快照。 jhat: 堆转储快照分析工具。 自己定义的类能被最顶级的类加载器加载吗？ 不能。Bootstrap类加载器只加载指定路径上的类，而且是按照名字识别的。 新生代和老年代所采用的GC算法 复制算法，标记清除算法。 数据结构 平衡树？红黑树？ 平衡树相比于红黑树，它的要求更为严格，它要求所有节点的左右子树高度差不超过1，这种严格要求每次插入或者删除后如果不满足条件就要进行旋转，而这个旋转是很耗时的。 相比之下，红黑树通过节点着色的要求，红黑树确保没有一条路径会比其它路径长出两倍。所以可以认为它是一种弱平衡树，而且相对于AVL树，它的旋转次数少，更适合于那种插入删除频繁的场景。 TreeMap底层就是红黑树。 MYSQL查询语句流程 事务 事务的四个特性：ACID 事务隔离： read uncommitted:一个事务未提交的内容可以被另一个事务读到，会导致脏读问题（指读到的东西不对）。 read committed: 一个事务只有提交了其他事务才能读到，大多数数据库默认的隔离级别。会导致不可重复读问题，也就是一个事务前后两次读到的内容可能会不一样。 repeatable read: 一个事务前后两次读到的内容是一样的。这是MySQL默认的隔离级别。 serializable: 事务之间串行执行。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 mysql redo log 和 bin log undo log redo log是innodb引擎所有。binlog是server层的。 redo log是物理日志，记录物理操作。 binlog是逻辑日志，记录逻辑操作。 redo log循环写。 binlog追加写。 undo log主要是为了保证原子性，用在MVCC中的 MySQL行锁，表锁 行锁有三种算法： 记录锁: 锁的是索引 gap lock next-key lock MySQL innodb如何解决幻读 MVCC + next-key lock MySQL主从复制 Slave上面的IO进程连上Mater,请求读取binlog的内容， Slave收到信息后，追加到relay-log中 Slave的SQL进程检查到relay-log的变化后，执行relay Log中的内容。 数据库范式 第一范式：没有重复列 第二范式：非主属性完全依赖于主属性（消除部分子函数依赖） 第三范式：属性不依赖于其他非主属性（消除传递依赖）、 分库分表的理解 分表可以解决单表压力，但是整体数据库的压力还在，所以就可以考虑分库了：把一些表放到新的数据库里 意向锁 首先要明确一点，意向锁是表级锁，它的出现主要是为了提升加锁判断时的性能。 举个例子，事务A给表中某行加了共享锁，这时候事务B想给表加个表锁，那么它就得知道能不能加，如果没有意向锁，那么这个判断就要逐行进行了。 而有了意向锁后，事情会变成这样：事务A加共享锁行锁的时候，数据库会先给表加个意向共享锁，意思就是告诉别的事务，这个表里有被加了共享行锁，那么这时候当别的事务想给这个表加排他锁表锁的时候，一检查发现有个共享意向锁，就知道这个排他锁表锁不能加了。 Redisredis一次通信过程 memcached区别？ 数据类型 事务 multi开启事务 exec提交事务 discard丢弃事务 watch: 提供类似CAS的作用，当被监视的值被其他客户端修改时，整个事务会失败。如果监控的这个值过期了，exec正常工作。 123456WATCH mykeyval = GET mykeyval = val + 1MULTISET mykey $valEXEC 持久化 redis支持的数据类型更为丰富：有string, list, set, hash, sorted set, 而memcached支持的数据类型比较简单，对于复杂类型需要自己在客户端进行支持。 redis支持主从复制模式，而memcached的服务器之间是没有关系的，需要客户端去做一致性hash处理，这样做的一个后果是集群扩展时可能导致大量缓存失效。 redis是单线程的，memached是多线程的。 redis中可以通过multi，exec，discard等命令开启事务，2.6以后还支持lua脚本，而memcached除了一些像increment/decrement这样的原子操作，是不支持事务的。 redis支持RDB和AOF两种持久化方式，而memcached本身是不支持持久化的，但是有一些基于memcached协议的项目支持持久化。 总结，从数据类型的角度考虑，从事务的角度考虑，从持久化的角度考虑。参考：https://www.jianshu.com/p/e94fa7340923 redis分布式锁 redis做分布式锁主要是实现作为锁的一种互斥的功能，也就是说给A加了就不能给B加，就像一个开关一样，要么朝开那边，要么朝关那边。实现这一功能的命令是setnx, 意思是set if not exist, setnx key value，当key不存在的时候设置value成功，key存在的时候不做动作。利用这个setnx就可以很生动的给多个服务加锁，还需要再加上一个expire命令，防止redis突然掉电导致锁不释放。但这么做也有个问题，万一redis在执行了setnx之后但是在执行expire之前掉电怎么办？其实是可以把这两条命令合成一条的。 redis KEYS命令和SCAN命令的区别 scan支持增量式迭代， 它们每次执行都只会返回少量元素， 所以这些命令可以用于生产环境， 而不会出现像 KEYS 命令、 SMEMBERS 命令带来的问题 —— 当 KEYS 命令被用于处理一个大的数据库时， 又或者 SMEMBERS 命令被用于处理一个大的集合键时， 它们可能会阻塞服务器达数秒之久。 不过， 增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 redis过期策略，内存淘汰策略过期策略： 定时过期：内存友好，但是会占用大量CPU处理过期资源 惰性过期：节省CPU,内存不友好 定期过期：这种方案 内存淘汰 noeviction allkeys-lru：从设置了过期时间的里面选 allkeys-random volatile-lru volatile-random volatile-ttl redis持久化原理？ RDB全量持久化 save命令：以阻塞方式全量持久化 bgsave: fork一个子进程做持久化 优点：文件小，恢复快，子进程做备份，不影响性能 缺点：隔一段时间同步一次，会有数据丢失 AOF做增量持久化 优点:安全性高，最多丢失一秒 缺点：文件体积大，恢复慢 redis string的实现使用一种叫做简单动态字符串（Simple Dynamic String，SDS）的数据结构，这个数据结构里记录了字符串已使用的长度，为使用的长度，通过动态的扩展与缩减长度，来提升性能。 redis事务redis事务命令可以将多个命令打包，需要注意的是其中有一个命令执行失败的话其他命令会继续执行，没有回滚。 缓存雪崩 缓存雪崩：指的是缓存大面积失效，所有请求一下子都打到数据库的情况。 解决：可以给失效时间加个随机数。 缓存穿透：指的是缓存没有，数据库也没有，直接打穿 解决：对请求进行校验；布隆过滤（用于验证一个数是否在一个集合中）。 缓存击穿：所有的请求都集中在一个热点key上，而这个key恰好刚刚失效。 解决：设置热点key永不过期 字典设计原理字典底层其实就是个哈希表，不过需要注意的是它有两个哈希表，通常情况下我们只用一个，只有在rehash的时候才会启用另一个。那何时进行rehash? 当键值对太多或者太少的时候就会对哈希表进行扩张或者收缩。那具体何时，具体如何？请看下一节。 渐进式rehash 何时rehash 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ； 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ； 为何要渐进 数据量太大的话会阻塞服务器很久 如何渐进 字典的数据结构里有两个哈希表，通常情况下只用一个，只有rehash的时候才会用到另一个，通过rehashidx的标记来一点一点的rehash, 在这过程中遇见增加则增加到新的上面，删除则依次寻找删除，更新也是以此寻找。 负载因子：used/size redis主从同步 ​ 一主多从，主写从读。一开始从会给主发一个psync命令，然后 主节点做一次bgsave, 然后后续操作存在buffer中，bgsave完成后将RDB文件发给从节点，从节点将其加载进内存。加载完成后再通知主节点把期间buffer内容发过来进行同步，此后主节点的每次写操作都会同步给从节点。 经过这么一波操作，主从就同步了，但是细心的同学可能会发现，万一后面又有命令操作主服务器呢？这时候就涉及到命令传播了，就是说后续每个修改命令，我们都同时也让从服务器执行以下，就ok了。 双写一致性先删缓存再更新数据库 也会有问题，可以采用延时双删策略，就是说过一会儿回来把脏缓存再删一次 或者严格点：串行化。 SDS设计原理为什么用动态字符串？反过来讲，用固定字符数组有什么问题？ 获取数组长度的时间复杂度 字符串append的时候会不会溢出？ SDS比较鸡贼的地方就在于它是有预留空间的，每次修改字符串后会多分配和当前字符串长度一样的空闲空间。 假如我要做一个拼接的操作，首先检查空闲长度够不够，如果不够，我先扩容到所需要的长度，然后拼接，你以为这就完了吗，并没有，拼接完了之后，还会给分配一个等量的空闲空间，以备不时之需。 RDB原理 pipelined好处 使得多次IO时间折合成一次。 redis哨兵？ 通过一个独立的进程运行哨兵，对主从节点进行监视，当主节点down掉之后会主动将从节点升为主节点，然后通过发布订阅模式同时其他从节点修改配置。 手写LRU 继承LinkedHashMap, 重写它的removeEldestEntry()方法 、、 一致性哈希 &gt; 哈希的整个值空间是一个圆，把服务器按照哈希算法映射到圆上，把数据也映射到圆上，每个数据对应的服务器就是从它所在位置向前走能走到的那个服务器。 &gt; &gt; 它的好处是新增和down掉服务器对整体数据的影响较小， &gt; &gt; 坏处是服务器数量极少的时候可能会导致数据分布不均匀。（可以通过添加一些虚拟节点来解决） 操作系统 信号量 信号量是一种同步机制，通过pv操作来实现互斥资源的访问，也就是wait 和 signal，但是要注意p操作和v操作是两个操作系统原语，也就是说它们是具有原子性的。 死锁 形成死锁的条件：互斥访问，请求保持，不可剥夺，循环等待 进程间通信 管道（pipe）,流管道(s_pipe)和有名管道（FIFO） 信号（signal） 消息队列 共享内存 信号量 套接字（socket) 进程和线程 说白了，他俩都是CPU工作时间段的描述，只不过粒度不同。 CPU执行进程，包括加载上下文，执行任务，保存上下文。 线程是对进程更小的划分，CPU执行进程任务的时候，又可以分成执行进程里的a线程，b线程，这些线程是共享上下文的。 select poll epoll select 一个最大的问题是能够监视的文件描述符数量存在最大限制，而且需要遍历文件描述符来获取已就绪的socket poll解决了文件描述符数量限制问题 select的几大缺点： （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 （3）select支持的文件描述符数量太小了，默认是1024 MQ使用场景 销峰，异步，解耦 销峰只得是，巨大流量涌进来的时候，先让它走消息队列，而不是直接打在服务器上。 异步可不可以用线程池做？ 线程池是基于内存的，掉电就没了，而且耦合度较高 消息队列会导致什么问题吗？ 数据的一致性问题：采用分布式事务解决。 可用性：万一MQ突然挂掉咋整 重复消费：幂等。进行校验 顺序消费： 消息堆积： 分布式事务主要通过半消息机制+回查来解决。 RocketMQ的架构？ NameServer: 管理元数据，包括对topic和路由信息的管理。 每个 Broker 在启动的时候会到 NameServer 注册，Producer 在发送消息前会根据 Topic 到 NameServer 获取到 Broker 的路由信息，Consumer 也会定时获取 Topic 的路由信息。 producer: 生产者 broker:消息中转，负责存储消息。 技术选型 首先宏观上讲，定制的肯定要比开源的好，主要的优势可以体现在： 可靠性：RocketMQ支持异步/同步刷盘;异步/同步Replication； ​ Kafka使用异步刷盘方式，异步R/同步eplication。 ​ RocketMQ所支持的同步方式提升了数据的可靠性，这对于金融IT很重要。 单机支持的队列：RocketMQ单机支持的队列更多，意味着可以有更多的topic 消费失败重试机制：RocketMQ支持消费失败重试。 消息顺序性：一台broker宕机后，RocketMQ消息不会乱序。 定时消息：kafka不支持 分布式事务消息：kafka不支持。 消息查询：kafka不支持。 消息回溯：kafka按照offset回溯，RocketMQ可以按照时间回溯。 所以阿里为什么要自研？ 金融业务对消息的可靠性，队列个数等很有要求。 当业务增长到一定规模，采用开源方案的技术成本会变高。 参考：http://jm.taobao.org/2016/03/24/rmq-vs-kafka/ 消费模式集群模式：一个消费者对应一个队列 广播模式：一个消费者对应tpoic下的所有队列 集群模式进度保存在队列上，广播模式保存在消费者上。 ​ RocketMQ是推还是拉 都有，但是推的本质还是拉 MQ如何保证高可用，如何保证消息不被重复消费（如何保证幂等），如何保证可靠性传输（如何处理消息丢失），如何保证消息的顺序性 如果项目中用到了MQ, 这些问题肯定跑不了，下面一一来看下。 高可用：在kafka中，一个topic分为多个partition, 而这些partition又是散落在不同的broker上的，并且每个partition在其他broker上又有备份，以此来达到高可用。 幂等：在MQ后面通过一些id之类的东西做校验。 如何保证可靠传输：言外之意，如何保证消息不丢，那么就要考虑消息会在哪丢了。 消费端弄丢了数据：首先要关闭自动提交offset, 进行手动提交，然后自己在消费端这边保证幂等。 MQ弄丢数据：也有可能，万一leader挂了，其他的follower还没同步完，这样会导致这个follower被选举成leader后，还缺了点数据。对于这种情况，需要进行一些设置，比如必须要所有副本写完，才算写成功，还有就是至少让一个follower和leader保持紧密联系。 生产者：我们要求必须是所有的副本也写成功了才算是发送成功。 网络get post区别 先说结论：没有本质区别，大部分所谓的区别其实都是浏览器或者服务器的一些限制。 get: 参数在url中； post:参数在请求体中。 （这个是Http协议用法的约定） get提交的数据长度有限制，post则可以无限大。（这个是服务器或者浏览器的区别） post会稍微安全一点，因为它的数据在请求体中。 get是幂等的，post不是，所以在网页回退或者刷新时，post的数据会被重新提交。 常见错误码 3**:页面重定向 4**：客户端错误 5**:服务器错误 301：资源永久移动。302：资源临时移动 cookie, session, token 为什么会有cookie, session? 因为http是个无状态的协议，通过cookie和session的操作可以让服务端知道请求是谁发来的。 那么cookie session有什么问题呢？在分布式场景下，每个服务器都要保存一份session, 很麻烦，但是如果把这些session集中放在一个服务器的话，又担心这个服务器崩了整个session就没了。 而token呢，整个用户信息都在里面，而且是经过加密的，每次客户端访问的时候只要带着这个token, 服务端解密一下就知道来者何人了。相比之下，用户信息既没有存在客户端也没有存在服务端。 Http1.0 和 Http2.0区别http1.0: 每次请求都要建立一个TCP连接 Head of Line Blocking: 请求队列的第一个请求因为服务器忙，导致后面的请求被阻塞。 http1.1: 支持持久连接：通过设置header里connection是close还是keep-alive, 一个TCP连接可以发送多个http请求 支持管道：本来情况是发一个请求，响应了才能发下一个。使用管道后就把客户端的队列搬迁到了服务端，客户端可以不用等这个响应就发下一个，但是服务端要按序响应。 可以使用多个TCP连接并行发请求。 http2.0 多路复用，一个HTTP连接可以处理多个请求 服务端推送 TCP如何保证可靠连接 三次握手，四次挥手 连续ARQ(回退N，超时重传）保证数据传输的正确性，滑动窗口进行流量控制 拥塞控制：慢开始，拥塞避免，快重传，快恢复 数据合理分片和排序 UDP优点 UDP是一种尽力而为的传输协议，它只是报文的搬运工，不做拼接，不做拆分，应用层下来的报文加个ip头就直接甩到下一层，他没有什么拥塞控制，想法就发，所以说是一种尽力而为，所以它适用于那些实时性比较高的场景。 TCP为何被称为流协议 说到流协议，我觉和和粘包拆包是有关系的，发送端出于性能考虑，会把几个小包合成一个大包去发送，在接收端又有自己的缓存，如果取数据不够快的话，缓存里就会连着存放好几个数据包。 UDP为何没有粘包 因为UDP发送端没有采用优化算法，而且接收端的缓冲区是链式结构。 OSI七层模型 ####TCP拥塞控制 满开始，拥塞避免， 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出重复确认，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段 快恢复：当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大 ​ 三次握手 http报文结构请求报文： 请求行，请求头，空行，请求体。 响应报文：状态行，响应头，空行，响应正文。 转发 重定向转发：服务端进行，只能访问到当前web容器下的url 重定向：进行两次请求，返回的302响应里面会包含一个新地址，这个地址不受容器范围限制。 分布式 分布式的优点 理论可以无限水平扩容 CAP理论 Consistency 一致性：每次读取，要么获得最新的数据，要么返回一个错误。 Available 可用性：每次都能获得一个非错误的响应，但不能保证获取到的是最新的。 Partition tolerance 分区容错性：节点或者网络故障时，仍能对外提供服务。 对一个分布式系统来说，P是基本要求，所以一般我们都是通过权衡CA, 同时想办法尽可能地提升P BASE理论 Basically Available 基本可用：损失部分可用性，保证核心可用。 Soft State 软状态：允许系统存在中间状态。 允许不同节点间副本同步的延时。 Eventually Consistency 最终一致性：所有副本经过一定时间，最终达到一致的状态。 分布式事务，两阶段提交，三阶段提交，Paxos 分布式事务：相比于普通的集中式事务来说，最大的问题就是它只能知道自身事务提交的情况，而对于其他机器上的事务，只能通过网络信息来了解。 因此，在分布式事务中，我们就提出了一个第三方，或者说叫做协调者，它负责协调所有机器上的事务。 两阶段提交：事务提交分为两个阶段，第一个是准备阶段，协调者发起询问，参与者执行询问，参与者返回响应。第二个是提交阶段，协调者根据参与者发回的请求决定提交还是回滚。 两阶段提交有什么问题呢？： 同步阻塞：一个参与者阻塞住了，其他人都得等。 单点故障：万一协调者挂了咋整。 数据不一致：协调者发送commit后只有一部分参与者收到了命令，而且此时协调者挂掉了 ，那就只有那部分提交了事务而其他的没有提交，就会造成数据不一致的情况。 两阶段提交无法解决的问题：假如在提交阶段，协调者发出commit之后宕机，收到这个commit命令的参与者也宕机，那么这时候即使有新的协调者，这条事务的状态也是不确定的。 在此之上，又提出了一个三阶段提交，它相当于是两阶段提交的升级版，它分为三个阶段： 三阶段提交：canCommit, preCommit, doCommit. 然后它还引入了一个超时机制。 相比于两阶段提交，三阶段提交主要是解决这个单点故障问题，当参与者超时还没收到commit命令时，它会自动提交，当然，这个也会导致不一致问题。 LinuxLinux查看内存命令 top, ps, free COWCopy On Write(写时复制)，说白了是一种优化策略，在操作系统层面和java层面都有实现。 操作系统层面：众所周知，fork()会产生一个子进程，它的内容是父进程的拷贝，需要注意，这里是一个虚拟地址空间的拷贝，就是说有各自的虚拟地址，但是共享物理地址（骚就骚在这了），看似拷贝，实则共享，等到真正父子进程哪个被修改的时候，我们才执行真正的物理内存的拷贝，需要注意的是，这里拷贝的是对应的页，而不是全部拷贝，不然内存哪里吃得消。 设计模式依赖倒置原则 我觉得依赖倒置的核心就是面向接口编程。具体来说就是： 上层不应该依赖于底层，两者都应该依赖于抽象 抽象不应该依赖于细节，细节应该依赖抽象。 设计原则单里一接迪开 单一职责原则： 里氏替换原则：能用基类的地方都能用子类 依赖倒置原则：面向接口编程。 接口隔离原则：接口要尽量做到精简，不要一个接口里啥都有 迪米特法则：类间尽可能解耦 开放封闭原则：对扩展开发，对修改封闭。 工具 nginx架构 一个master进程，多个worker进程， master进程负责读取和验证config文件，管理worker进程 每个worker进程都各自维护一个线程。 nginx如何热部署 每次修改config文件后，会重新生成新的worker,新的请求会交给新的worker处理，老worker工作完后就被kill nginx如何高并发 epoll模型 nginx挂了怎么办 keepalive + nginx, keepalive nginx负载均衡 轮询，哈希，最少连接 JWT JWT分为三部分，header, payload, signature, 然后整体会用base64URL转成字符串 JWT的特点 默认不加密，不能存储秘密数据 一旦签发，始重有效。 如何认识前后端分离 方便开发 2. 请求的压力不会都堆到应用服务器上。 Spring事务传播行为 required: 没有则创建，有则沿用。 supports: 没有则不用，有则沿用。 mandatory: 必须运行在事务内，没有就抛异常。 require_new: 无论是否存在，都会创建新事务。 not_supported: 不需要事务，没有也不创建，有则挂起。 never: 不支持事务，否则报异常。 nested: 嵌套事务。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"面经","slug":"面经","permalink":"http://example.com/tags/%E9%9D%A2%E7%BB%8F/"}]},{"title":"Redis持久化","slug":"Redis持久化","date":"2020-02-05T05:54:18.000Z","updated":"2023-05-29T14:17:39.321Z","comments":true,"path":"2020/02/05/Redis持久化/","link":"","permalink":"http://example.com/2020/02/05/Redis%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"","text":"最近自己做的项目中用到了redis, 特此记录一下redis的持久化相关内容。 redis虽说是内存数据库，但其实自己是有持久化的，它的持久化有两种方式：RDB持久化和AOF持久化。 RDB持久化会在一个特定的时间间隔进行一个快照文件的保存。 AOF持久化会记录每一个服务器收到的写操作。当服务重启时，这些操作记录会被重新执行从而重建数据。 从上面的描述可以发现一点，RDB的快照持久化方式并不是很可靠，因为它是每隔一段时间进行一次全面的快照，但是如果在这个时间段中间服务器崩了，那么距离上次保存快照以后的数据就会丢失。相比之下，AOF持久化方式更为可靠，只要有对数据库的写操作，他就记录，而不是隔一段时间一保存。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}]},{"title":"MySQL的锁","slug":"MySQL的锁","date":"2020-01-06T03:12:07.000Z","updated":"2020-01-06T03:12:07.000Z","comments":true,"path":"2020/01/06/MySQL的锁/","link":"","permalink":"http://example.com/2020/01/06/MySQL%E7%9A%84%E9%94%81/","excerpt":"","text":"先看锁的分类： 按照是否共享，可以分为： 共享锁（读锁） 排他锁（写锁） 按照锁的粒度，可以分为： 表锁 行锁 要谈锁，我认为是要结合事务隔离级别一起谈的，MySQL的事务隔离级别有： Read Uncommitted Read Committed Repeatable Read Serializable InnoDB默认的是行锁，而且行锁是加给索引的，所以如果没有索引，那也就只能被迫全表扫描了。 单纯的说“要给什么语句加什么锁”，这句话本身是靠不住的，因为要给某个语句是否加锁，加什么锁，取决于很多因素，如： 上下文，即事务的隔离级别 这条语句本身的特性：这条语句是单纯的select,还是select for update, select lock in share mode，还是insert, update 或者delete，带有修改意味的语句一般会被加X锁，普通的语句加S锁或者不加 执行时有没有用到索引，使用二级索引可能会需要回表，这时候对一级索引也要加锁，使用一级索引进行修改二级索引则二级索引也要加锁。 同一语句在不同的隔离级别下加锁情况也不一样。 在READ UNCOMMITTED 和 READ COMMITTED隔离级别下，因为不需要防止幻读的问题，所以加锁也都是一条记录一条记录的加，不存在范围锁（gap锁或者next-key lock） 但是在 REPEATABLE READ 下则不一样，因为需要防止幻读，加锁的时候不仅需要加锁自身，还要锁定一个范围。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"MySQL之MVCC","slug":"MySQL之MVCC","date":"2020-01-05T12:53:07.000Z","updated":"2020-01-05T12:53:07.000Z","comments":true,"path":"2020/01/05/MySQL之MVCC/","link":"","permalink":"http://example.com/2020/01/05/MySQL%E4%B9%8BMVCC/","excerpt":"","text":"讨论MySQL的MVCC的同时还应该讨论MySQL中的锁，不过本文先就MVCC进行讨论。 MVCC叫做多版本并发控制，它主要是为了实现多个事务之间的隔离性而提出的一种更高效的方法，为什么说更高效呢，因为锁也可以实现，只不过相比之下比较低效。 MVCC的核心有三： MySQL每一行记录的隐藏列之DATA_TRX_ID MySQL每一行记录的隐藏列之``DATA_ROLL_PTR` READ VIEW 我们下面一一进行解释。 MySQL的每一行记录都有两个隐藏列，DATA_TRX_ID和``DATA_ROLL_PTR。其中DATA_TRX_ID表示修改该行的事务ID,而DATA_ROLL_PTR`则指向该行的历史修改，它把所有的历史修改连成一个链表，像这样 而Read View是什么呢？它也是一种数据结构，m_ids上面我们讲到不同的事务对同一行的操作形成了一个链表，那么我们在执行一条SQL时到底应该选择链表中的哪一条作为结果呢？Read View正是为了解决这个事情的。 Read View里存放了我们当前活跃的事务的集合，所谓当前活跃，指的是这些事务还未被提交，当在不同的隔离级别下执行SQL时，通过检查版本链中的事务ID和Read View中的事务ID大小就可以决定要选择版本链中的哪个节点作为执行结果了。 具体是这样的： 如果被访问版本的trx_id属性值小于m_ids列表中最小的事务id，表明生成该版本的事务在生成ReadView前已经提交，所以该版本可以被当前事务访问。 如果被访问版本的trx_id属性值大于m_ids列表中最大的事务id，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。 如果被访问版本的trx_id属性值在m_ids列表中最大的事务id和最小事务id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。 还有两点需要注意的是： Read View是与SQL绑定的，而并不是事务 对于使用READ UNCOMMITTED隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用SERIALIZABLE隔离级别的事务来说，使用加锁的方式来访问记录。所以MVCC只在可重复读和读已提交这两个隔离级别下工作。 本文转自公众号：我们都是小青蛙，作者小孩子4919 参考： https://mp.weixin.qq.com/s/SCW_3AypO-rSolMcjCxVtA","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"二叉树遍历","slug":"二叉树遍历","date":"2020-01-01T02:51:05.000Z","updated":"2020-01-01T02:51:05.000Z","comments":true,"path":"2020/01/01/二叉树遍历/","link":"","permalink":"http://example.com/2020/01/01/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/","excerpt":"","text":"二叉树的遍历有层次遍历，前序遍历，中序遍历以及后续遍历。本文分别通过递归和非递归的方法来实现这些遍历。 二叉树的数据结构 123456789public class Node&#123; public int value ; public Node left ; public Node right ; public Node(int val)&#123; value = val ; &#125;&#125; 递归的写法其实很简单，主要是得有一个终止条件，有了这个终止条件后，一切都好说。 1234567public void preOrderRecur(Node root)&#123; if(head == null) return ; System.out.println(root.value) ; preOrderRecur(root.left) ; preOrderRecur(root.right) ;&#125; 1234567public void inOrderRecur(Node root)&#123; if(head == null) return ; inOrderRecur(root.left) ; System.out.println(root.value) ; inOrderRecur(root.right) ;&#125; 1234567public void postOrderRecur(Node root)&#123; if(head == null) return ; postOrderRecur(root.left) ; postOrderRecur(root.rigth) ; System.out.println(root.value) ;&#125; 从上面的代码可以看到，只要写好了终止条件，其他的都很好说。下面主要介绍非递归的写法。 前序遍历的顺序是跟左右，然后，对于一棵二叉树，其实也就只有三个节点：跟左右，当你这么想的时候，问题就变简单了：用一个栈，首先根节点入栈，好，此时栈中有元素了； 这时候我们出栈一个元素，访问它，然后以此将它的右孩子、左孩子入栈，然后出栈、访问，然后右孩子、左孩子入栈，如此重复。 为什么入栈时要先右孩子后左孩子呢？因为是栈啊，先进后出。 1234567891011121314151617181920public void preOrderIte(Node root)&#123; Stack&lt;Node&gt; stack = new Stack() ; Node cur = root ; if(cur != null) &#123; stack.push(cur) ; &#125; while (!stack.empty())&#123; cur = stack.pop(); System.out.println(cur.value); if(cur.right!=null)&#123; stack.push(cur.right) ; &#125; if(cur.left!=null)&#123; stack.push(cur.left) ; &#125; &#125; &#125; 再来考虑一下中序遍历，左、根、右。 就是说，首先我需要找到最左下方那个元素，然后依次左根右地遍历。那么我在向下寻找地过程中用一个栈把它地路径都存起来岂不是美滋滋。 1234567891011121314151617public void inOrderIte(Node root)&#123; Stack&lt;Node&gt; stack = new Stack&lt;&gt;() ; Node cur = root ; if(cur!=null) &#123; stack.push(cur); cur = cur.left; &#125; while (!stack.empty() || cur !=null) &#123; while (cur != null) &#123; //一直伸到最左下方 stack.push(cur); cur = cur.left; &#125; cur = stack.pop(); System.out.println(cur.value); cur = cur.right; &#125; &#125; 再来看下后序遍历，左右根。 同样地，我们认为这个二叉树只有三个节点，根，左，右，我们期望的遍历顺序是：左右根，左右根反过来的顺序是什么：根右左，是不是有点像先序遍历。所以我们可以先尝试搞一个它的逆序遍历根右左，然后把这个遍历顺序放到一个栈里面重新输出一下就可以了。 先重新审视一下先序遍历的代码 1234567891011121314151617181920public void preOrderIte(Node root)&#123; Stack&lt;Node&gt; stack = new Stack() ; Node cur = root ; if(cur != null) &#123; stack.push(cur) ; &#125; while (!stack.empty())&#123; cur = stack.pop(); System.out.println(cur.value); if(cur.right!=null)&#123; stack.push(cur.right) ; &#125; if(cur.left!=null)&#123; stack.push(cur.left) ; &#125; &#125; &#125; 大概就是先根节点入栈，然后根节点出栈，右孩子入栈，左孩子入栈。 我们只需要稍微改动一下，就可以变成后序遍历。 1234567891011121314151617181920212223242526public void postOrderIte(Node root)&#123; Stack&lt;Node&gt; stack = new Stack() ; Stack&lt;Node&gt; stack2 = new Stack&lt;&gt;(); Node cur = root ; if(cur != null) &#123; stack.push(cur) ; &#125; while (!stack.empty())&#123; cur = stack.pop(); //每次s1的pop都对应着s2的push stack2.push(cur); if(cur.left!=null)&#123; stack.push(cur.left) ; &#125; if(cur.right!=null)&#123; stack.push(cur.right) ; &#125; &#125; while (!stack2.empty())&#123; System.out.println(stack2.pop().value); &#125; &#125; 在先序里，每次s1的pop都对应着一次print, 在后序里，每次s1的pop都对应着s2的push. 还有就是，在先序里，先入栈右孩子，再入栈左孩子，在后序里，翻了过来，应为我们有两个栈。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"TCP如何保证可靠传输","slug":"TCP如何保证可靠传输","date":"2019-12-26T09:14:42.000Z","updated":"2019-12-26T09:14:42.000Z","comments":true,"path":"2019/12/26/TCP如何保证可靠传输/","link":"","permalink":"http://example.com/2019/12/26/TCP%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93/","excerpt":"","text":"首先，它是面向连接的，也就是它的三次握手和四次挥手，保证了每次发送数据前先建立连接，发送完数据后断开连接 它的确认和重传机制。它会对每次发送的数据包进行一个确认，如果过了很久发送端还没有收到这个确认，就会进行重传。 数据校验。头部有校验和，用以检验数据包的完整性。 流量控制：通过滑动窗口以及连续ARQ协议进行数据包的接收，而且当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。 拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://example.com/tags/TCP/"}]},{"title":"TCP的三次握手和四次挥手","slug":"TCP的三次握手和四次挥手","date":"2019-12-23T08:08:26.000Z","updated":"2019-12-23T08:08:26.000Z","comments":true,"path":"2019/12/23/TCP的三次握手和四次挥手/","link":"","permalink":"http://example.com/2019/12/23/TCP%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/","excerpt":"","text":"在讨论TCP的三次握手与四次挥手之前，首先我们需要了解TCP报文格式： 这里面需要留意的有： 序列号：标识本次数据包的序号 确认号：对于发送发送方数据包的确认，值是收到的数据包的序列号+1，即下次期待收到的数据包序列号 标志位： 下图展示了三次握手以及四次回收的过程： 这里需要注意各个阶段的状态。 下面分别进行分析 三次握手阶段： 客户端向服务端发送SYN数据包，表示想和服务端建立连接 服务端收到这个数据包后，给予客户端回应，所以ACK=1,表示自己收到了客户端的数据包，同时它也想和客户端建立连接，所以在这里回传一个SYN 客户端收到这个ACK+SYN数据包后，表明它可以向服务端发送请求并接收响应，至此它单方面的连接已经建立起来了，可是对于服务端来说，它只是才发送了一个ACK+SYN包，还不知道自己能不能收到客户端的回应，所以客户端需要再回一个ACK表示客户端收到了服务端的ACK+SYN包，至此服务端也可以确定自己能向客户端发送请求并接收响应了，所以服务端这一方的连接也建立起来了，至此整个三次握手完成，连接建立。 所以回首上述过程，为什么是三次？因为前两次可以确保客户端可以正常发送请求和接收响应，后两次可以保证服务端可以发送请求和接收响应。 四次挥手阶段： 当客户端和服务端建立好连接并通信结束后，它俩就要说say goodbye了，那么怎么告别呢？ 分手总有一个人先说再见，在四次挥手里，首先客户端发送一个FIN包，意思是“服务端，我已经说完了，你还有什么要说的吗？”此时客户端已经无fuck说，就看服务端还有什么要说的，客户端此时进入FIN_WAIT1状态。 服务端收到这个包后，知道客户端已经没有话对他讲了，但是万一他还有话对客户端讲呢？所以他先发一个ACK包给客户端，意思是“好的我知道了，但是我可能还有话要对你讲”。 然后呢服务端就进行最后的道别，说完最后一番话后，他发一个FIN包给客户端，意思是“我已经说完了，我们可以拜拜了”。 客户端收到这个FIN包后，回一个ACK包给服务端，意思是“好的我知道了，see you nala”,服务端收到这个包后就先行挂断了电话，客户端等一段时间后发现确实没音了自己也就挂了电话，至此四次握手结束。","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://example.com/tags/TCP-IP/"}]},{"title":"同步与异步，阻塞与非阻塞","slug":"IO中的同步异步，阻塞非阻塞","date":"2019-12-20T14:13:46.000Z","updated":"2019-12-20T14:13:46.000Z","comments":true,"path":"2019/12/20/IO中的同步异步，阻塞非阻塞/","link":"","permalink":"http://example.com/2019/12/20/IO%E4%B8%AD%E7%9A%84%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%EF%BC%8C%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/","excerpt":"","text":"同步与异步，阻塞与非阻塞这几个词可以说是很常见了，但是网络上关于它们的解释却又众说纷纭，其中一个主要原因就是我们是在脱离了上下文在谈论这个问题，所以本文主要是基于Network IO来讨论。 在《UNIX网络编程：套接字联网API》一书中，一共比较了五种IO模型： 阻塞式IO (blocking IO) 非阻塞式IO (non-blocking IO) IO多路复用（IO multiplexing） 信号驱动式IO () 异步IO (asynchronous IO) 在正式开始讨论这五种IO模型之前，让我们先明确一件事：一个IO操作通常包括两个阶段： 等待数据准备好 从内核向进程复制数据 对应到Socket 的输入操作时，就是首先等待数据从网络中到达，然后将数据从内核缓冲区复制到进程缓冲区 （看不懂没关系，下面有图的）。 阻塞式IO开局一张图： 这里recvfrom是一个系统调用，当应用进程调用了这个系统调用后，当前进程从用户态切换到内核态，然后内核开始IO的第一阶段：等待数据。当数据准备好之后（比如从网络上接收到了完整的数据包），此时数据是在内核缓冲区的，然后操作系统会把数据从内核缓冲区复制到用户空间，并返回成功指示。 需要注意的是，在等待数据和拷贝数据阶段，应用进程都在阻塞。 非阻塞式IO继续上图： 我们把非阻塞式IO和上面的阻塞式IO对比来看。对于阻塞式IO，在等待数据阶段，如果数据还没准备好，内核这边也不吭声，应用进程在那死等 （即阻塞应用进程），直到返回结果。 而非阻塞式则不一样，当内核态这边收到这个系统调用后，如果数据还没准备好，它会先返回给应用进程一个错误信息，告诉应用进程数据还没准备好，应用进程知道后，可以先转去做其他事情，待会儿再来询问一下 （我们称之为轮询，polling），如此反复，直到有一回数据准备好了，这时候操作系统将数据从内核复制到用户空间，并且在此期间，应用进程是阻塞的。 所以对于非阻塞式IO来说，在数据准备阶段，应用进程不阻塞，在数据拷贝阶段，仍然阻塞。 IO多路复用IO multiplexing, 有些地方也叫 event driven IO. 其核心在于：使用单个进程就可可以同时处理多个网络连接的IO，它主要是基于select函数或者poll函数来实现的。 基本原理是这样的：一个select函数它可以负责监控多个socket，准确的来说，我们可以调用select告知内核我们对哪些描述符（读、写或异常）感兴趣，然后select回去轮询我们感兴趣的这些事件，当其中的一个或者多个事件发生时，它就会告诉通知一下应用进程说：“嗨，你感兴趣的某某某出现了”。然后引用进程此时再发起系统调用recvfrom，此时就没有数据准备阶段了，而是直接数据拷贝，在此过程中应用进程依然阻塞。 可以看到的是，相比于阻塞式IO，这里的多路复用似乎性能更差，因为它有两个系统调用（select, recvfrom）而阻塞式IO只有一个（recvfrom）. 多路复用的优势不是说处理单个连接能有多快，而是可以单进程处理多个连接。 信号驱动式IO我们也可以使用信号，让内核在描述符就绪时就发送SIGIO信号通知我们，这种模型称之为信号驱动式IO。 首先我们需要开启套接字的信号驱动式IO功能，并通过sigaction系统调用安装一个信号处理函数。该系统调用立即返回，应用进程继续工作 (即没有被阻塞)，当数据准备好后，内核发送SIGIO到应用进程。然后应用进程再调用recvfrom读取数据。 它的优势在于在等待数据期间应用进程不被阻塞。 异步IO上面介绍的几种IO模型中，在第二个数据拷贝阶段都是阻塞的。异步IO则不然，它的工作机制是：告诉内核去完成某个动作，然后内核完成后再去告知应用进程。在这整个过程中，应用进程都是没有被阻塞的。 各种IO模型比较下图对比了上述五种IO模型的对比。可以看出，对于前四种，在第二阶段都是阻塞的，而异步IO则不同，它全程无阻塞。 同步IO？ 异步IO？我们先看下POSIX对同步IO和异步IO的定义： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;An asynchronous I/O operation does not cause the requesting process to be blocked; 翻译过来就是说： 同步IO：导致请求进程阻塞，直到IO操作完成 异步IO：不会造成请求进程阻塞 按照这个定义，那么上面的五种IO模型中，哪几个在IO操作的时候会应用进程会被阻塞呢？ 前四种都是。（这里需要注意，这里指的是IO操作，即recvfrom这一系统调用，在数据从内核复制到用户空间这一过程中，前四种都是阻塞的，除了异步IO模型） 总结让我们来总结一下上面提到的几种IO模型： 阻塞式IO：全程死等 非阻塞式IO: 应用进程不断轮询直到数据准备好，然后进行数据拷贝，在此期间应用进程阻塞 多路复用IO: 其实它也是一种轮询，与非阻塞式IO不同的是： 非阻塞式IO中是应用进程主动轮询，而多路复用IO中是通过select系统调用让内核去轮询的，轮询期间应用进程被select系统调用阻塞 多路复用IO中select可以同时关注多个socket的IO，从而实现了单进程管理多个socket IO 信号驱动式IO：数据准备过程中不阻塞，数据拷贝过程中阻塞。 异步IO：全程不阻塞，内核完成任务后告知应用进程一声就好。 这里讲的同步异步，阻塞非阻塞只是针对Socket IO来讲的，如果换个背景，定义可能会有所不同。","categories":[{"name":"OS","slug":"OS","permalink":"http://example.com/categories/OS/"}],"tags":[{"name":"IO模型","slug":"IO模型","permalink":"http://example.com/tags/IO%E6%A8%A1%E5%9E%8B/"}]},{"title":"Java垃圾收集灵魂三问","slug":"Java垃圾收集灵魂三问","date":"2019-12-13T13:30:46.000Z","updated":"2019-12-13T13:30:46.000Z","comments":true,"path":"2019/12/13/Java垃圾收集灵魂三问/","link":"","permalink":"http://example.com/2019/12/13/Java%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%81%B5%E9%AD%82%E4%B8%89%E9%97%AE/","excerpt":"","text":"最近在重新看JVM的内容，这篇文章重新梳理一下垃圾回收中的相关内容。 Java中的垃圾回收(Garbage Collection, GC)指的是回收堆和方法区中不再使用被使用到的对象，即垃圾。 GC中需要考虑的三个主要问题： 什么是垃圾：即哪些对象可以被定义为垃圾 何时回收 如何回收 本文将针对上述三个问题一一解答。 什么是垃圾？这里就涉及到两种判断对象是否存活的算法： 引用计数法给每个对象添加一个计数器，当它被某些地方引用是，计数器加一，引用失效时，计数器减一，那些计数器为零的对象就是垃圾了。这种方法的一个关键问题是会出现循环引用，即对象A里面的成员引用了对象B，而对象B里面的成员又引用了对象A 可达性分析算法通过一系列成为“GC Roots”的对象作为起点，从这些节点开始向下搜索，搜索走过的路径叫做引用链，当一个对象到GC Roots没有任何引用链相连时，则说明这个对象不可用。 那么问题来了，什么是GC Root,哪些对象可以成为GC Root? 在Java中，可以作为GC Root的对象包括以下几种： 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI引用的对象 其实上面的GC Root也是有规律可循的，分为两种：一种是栈中引用的对象（包括虚拟机栈和本地方法栈），一种则是方法区中的静态属性和常量引用的对象 如何回收标记清除算法内存碎片过多 复制算法通过折半内存空间来避免出现内存碎片 标记整理算法内存变动频繁，需要整理所有存活对象的内存地址 分代收集算法将堆空间分为新生代和老年代，新生代又分为一个比较大的Eden区和两个比较小的survivor区。 两个survivor区起的就是一个缓冲的作用。 新生代98%的对象朝生夕死，采用复制算法。 老年代采用标记-整理算法。 何时回收常见的垃圾收集器：","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}]},{"title":"Java中的LongAdder","slug":"Java中的LongAdder","date":"2019-12-05T03:25:22.000Z","updated":"2019-12-05T03:25:22.000Z","comments":true,"path":"2019/12/05/Java中的LongAdder/","link":"","permalink":"http://example.com/2019/12/05/Java%E4%B8%AD%E7%9A%84LongAdder/","excerpt":"","text":"最近发现JUC包里除了AtomicLong外还有LongAdder，所以打算研究一下它俩的异同。 AtomicLongAtomicLong是JUC包中的原子类，通过CAS来实现long类型的加减。 那么既然都有AtomicLong类了，为什么还要有一个LongAdder类？因为从名字来看，LongAdder也是用来操作long类型的。 LongAdder的设计思想先翻译一段官方文档里的解释： LongAdder是通过多个变量一起来维护一个long型总和。什么意思呢？它主要是为了计算一些统计信息的，在多线程竞争的场景下，它给每个线程都分配一个变量，每个线程各自修改自己的变量，然后它有个sum()方法，可以计算所有变量的总和，通过这种方式来减少多线程之间的竞争。 当多个线程去更新一个公有的sum总和时，我们更偏向于用LongAdder而非AtomicLong. 这两个类特性相似，但是在多线程竞争激烈的场景，LongAdder具有更好的性能（这一点也可想而知，毕竟AtomicLong使用的是CAS）。 上面的描述也就基本上解释了LongAdder的缘起缘灭了，它主要是为统计而生，而非那种细粒度的同步控制。 其实这个也就相当于一种分治，非中央集权而是分而治之，让每个线程维护自己的那个变量，最后综合统计一下。 详情我们在这里从源码角度讨论一下LongAdder. 先看下它的继承关系： 1public class LongAdder extends Striped64 implements Serializable 它最核心的一个方法就是add()方法了 123456789101112131415/** * Adds the given value. * * @param x the value to add */ public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) &#123; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); &#125; &#125; 看着很简单，但里面的逻辑判断却不少。先简单介绍下这里面的一些陌生类型和方法。 Cell[]：Cell类里面其实就是维护了一个变量，这个数组用来存在每个线程的自己维护的变量。具体细节是这样的：对每个线程计算hash，将得到的hash值作为Cell数组的下标。 casBase()：对base变量进行CAS,什么是base变量呢？当有竞争是使用Cell[]数组给每个线程维护一个变量，当没有竞争是LongAdder就只操作一个base变量就可以了。 getProbe()：得到当前线程对应的哈希值，再和数组长度进行与运算就得到了对应的下标（有没有一点hashmap的影子？）. longAccumulate()：当基本的操作都失败时，执行这个方法。 为了方便理解代码逻辑，我画了一个流程图： 可以看到大概流程是先操作Cell数组，数组空的话再操作base,如果都没成功再考虑longAccumulate（），虽然我也没仔细研究longAccumulate()里的代码，但是大概可以猜到，它应该是上述未成功操作的plus版，操作逐渐升级。 这种设计思想可以学习一手","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Java中的并发工具类","slug":"Java中的并发工具类","date":"2019-12-02T03:28:28.000Z","updated":"2019-12-02T03:28:28.000Z","comments":true,"path":"2019/12/02/Java中的并发工具类/","link":"","permalink":"http://example.com/2019/12/02/Java%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/","excerpt":"","text":"CountDownLatch多线程的使用中往往有这样的场景：某个线程需要等到其他线程执行完毕后才能继续执行，即线程的“等待其他线程”的功能（注意这里说的不是wait()）。这时候就可以用CountDownLatch类来实现，当然了，Thread.join()方法也具有这个功能，只不过相比之下，CountDownLatch功能更加丰富。 通过一个例子来看下： 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.concurrent.CountDownLatch;public class CountDownLatchTest &#123; static CountDownLatch cdl = new CountDownLatch(3) ; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot; is running&quot;); cdl.countDown(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot; is running&quot;); cdl.countDown(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot; is running&quot;); cdl.countDown(); &#125; &#125;).start(); try &#123; cdl.await(); System.out.println(&quot;sub thread executed&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在上面的代码中，我们新建了三个子线程，现在想要等到三个子线程都执行完毕了输出一句sub thread executed. 我们使用了CountDownLatch来实现这个功能。 1static CountDownLatch cdl = new CountDownLatch(3) ; 这句话设置CountDownLatch计数器的值为3，表示对三个线程进行计数。 1cdl.countDown(); 在每个线程里执行这句话，将计数器的值减一。 1cdl.await(); 在主线程中使用await()方法等待计数器值为0的时候就开始执行后续代码。 所以需要注意一个问题，如果我们设置计数器值为3，但是在子线程中只执行力两次coutDown()，那么主线程中的await()方法后面的内容永远也不会被执行到。 CyclicBarrierCyclicBarrier用于让一组线程都到达某个状态后然后统一同时开始继续执行。从名字来看，CyclicBarrier就是可以循环利用的屏障，所以它的作用也就是在线程执行中插入一个屏障，当所有的线程都执行到屏障这里后，才能统一继续往下执行。 通过下面的代码来看： 123456789101112131415161718192021222324252627public class CyclicBarrierTest &#123; static int THREAD_COUNT =3 ; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3); for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; 到达屏障前&quot;); try &#123; cyclicBarrier.await(); System.out.println(Thread.currentThread().getName() + &quot; 到达屏障后&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; 创建了三个线程，同时CyclicBarrier的计数器为3，在每个线程的执行代码中插入一句： 1cyclicBarrier.await(); 那么该代码后续的内容需要等到所有线程都执行到屏障这里才能继续执行。 执行结果： 123456Thread-1 到达屏障前Thread-0 到达屏障前Thread-2 到达屏障前Thread-2 到达屏障后Thread-1 到达屏障后Thread-0 到达屏障后 CyclicBarrier相比于CountDownLatch，区别之一在于它可以循环利用，这也是它名字里cyclic的意义所在，CyclicBarrier的计数器可以通过reset()重置。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Java中的等待/唤醒机制","slug":"Java中的等待-唤醒机制","date":"2019-11-28T11:40:52.000Z","updated":"2019-11-28T11:40:52.000Z","comments":true,"path":"2019/11/28/Java中的等待-唤醒机制/","link":"","permalink":"http://example.com/2019/11/28/Java%E4%B8%AD%E7%9A%84%E7%AD%89%E5%BE%85-%E5%94%A4%E9%86%92%E6%9C%BA%E5%88%B6/","excerpt":"","text":"等待/唤醒机制是多线程之间进行通信（同步）的一种方式，这里对它在Java中的使用做一个总结。 Object的wait()和notify()这个算是比较原始的一种等待/唤醒机制，这两个方法都是Object类中定义的方法，也就是说每个对象都拥有这两个方法。 它们一般都是和synchronized关键字配合使用的。 Condition接口Condition接口是为了对Lock的一个等待/通知机制的实现。这里需要提一下，Lock接口是在synchronized后面提出的锁机制，相比于synchronzied关键字，它能够响应中断。而Condition正是为Lock中提供了等待/通知机制。 阻塞队列阻塞队列也是一种线程间通信的方式，其核心在于两个线程互相通信去使用同一个队列，而这两个线程间的通信就是通过等待/通知机制完成的。在阻塞队列中，如果生产者线程发现当前队列满了，那么他就会调用await()方法，挂起生产者线程。当消费者线程从队列中消费了元素后，然后通过signal()方法唤醒生产线程。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java中的Condition","slug":"Java中的Condition","date":"2019-11-12T05:26:50.000Z","updated":"2019-11-12T05:26:50.000Z","comments":true,"path":"2019/11/12/Java中的Condition/","link":"","permalink":"http://example.com/2019/11/12/Java%E4%B8%AD%E7%9A%84Condition/","excerpt":"","text":"前面的文章中，我们了解了Java中的Lock接口，以及相关的实现类ReentrantLock、ReentrantReadWriteLock。它们都是通过聚合一个AQS来实现的。同时讨论了为什么有了Synchronized关键字之后还要有Lock。 我们知道Synchronized关键字是Monitor机制在Java中的一种具体实现，每个对象都有wait()、notify()和notifyAll()方法来进行线程通信。 那么问题来了，在提出了Lock之后，我们使用Lock加锁的时候有没有类似的一组监视器方法呢？这就是我们今天要讨论的Condition接口。Condition接口和Object类的监视器方法有相同又有不同。 定义先来看下Condition接口里定义的方法： 是不是和Object中定义的方法很类似。 使用ConditionObject类实现了Condition接口，作为一个AQS的内部类，所以它的创建依靠于Lock对象，通过newCondition()方法创建它。 使用也十分简单，但是记得使用时要加锁。 12345678910111213141516171819202122Lock lock = new ReentrantLock() ;Condition condition = lock.newCondition();//线程Alock.lock();try &#123; condition.await();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;finally &#123; lock.unlock();&#125;//线程Block.lock();try&#123; condition.signal();&#125;catch(InterruptedException e)&#123; e.printStackTrace();&#125;finally&#123; lock.unlock();&#125; 阻塞队列就是使用Condition来实现生产者和消费者的通信的 实现Condition作为AQS的内部类被实现，所以它是可以共享一些AQS的资源的。 Condition的实现有三个关键点：等待队列、等待和通知。 同步队列和等待队列同步队列：线程获取同步状态失败时会进入的队列，首节点表示获取同步状态成功的节点。 等待队列：存放调用了Condition.await()方法的线程节点。 await()当线程执行Condition.await()时，线程节点从同步队列中被移除，加入对应Condition的等待队列中。 signal()当线程执行Condition.signal()时，对应Condition等待队列中的首节点被移除，转而加入的同步队列中。 需要注意的是，对于同一个Lock，等待队列是可以有多个的。 同时可以发现，对于一个线程节点，要么在同步队列中，要么在等待队列中。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Lock","slug":"Lock","permalink":"http://example.com/tags/Lock/"}]},{"title":"Java创建线程的方式","slug":"Java创建线程的方式","date":"2019-11-11T06:34:02.000Z","updated":"2019-11-11T06:34:02.000Z","comments":true,"path":"2019/11/11/Java创建线程的方式/","link":"","permalink":"http://example.com/2019/11/11/Java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%96%B9%E5%BC%8F/","excerpt":"","text":"继承Thread类继承Thread类，重写run()方法。 1234567891011public class ExtendThread extends Thread &#123; @Override public void run() &#123; super.run(); System.out.println(&quot;this is sub thread extends from Thread&quot;); &#125; public static void main(String[] args) &#123; new ExtendThread().start(); &#125;&#125; java中是单继承，如果使用这种方式的话，每个类即是一个线程。 实现Runnable接口重写run()方法。 1234567891011121314public class RunnableThread implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;this is thread implements Runnable&quot;); &#125; public static void main(String[] args) &#123; Runnable runnable = new RunnableThread() ; new Thread(runnable).start(); &#125;&#125; Callable+Future先看下Callable接口的定义 12345678910public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 再来看下Future 12345678public interface Future &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 我们一般配合线程池来使用，因为： 1` Future submit(Callable task);`` Future submit(Runnable task, T result);``Future submit(Runnable task);` 例子： 12345678910111213141516171819public class CallableThread implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=0; i&lt;100; i++) sum += i ; return sum; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService service = new ThreadPoolExecutor(5,10,60L, TimeUnit.SECONDS,new ArrayBlockingQueue(10)); Future future = service.submit(new CallableThread()) ; System.out.println(future.get()); &#125;&#125; 上面实现Runnable接口已经比继承自Thread类的实现方法更为优雅了，但是这种方法还有一个问题，就是无法获得子线程的执行结果。这时候就需要Callable接口，它和Runnable接口效果差不多，唯一不同的是有返回值。这里配合Future来接收。 Callable+FutureTaskFutureTask 1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 1public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 例子： 123456789101112131415161718192021222324public class FutureTaskThread implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=0; i&lt;100; i++) sum += i ; return sum; &#125; public static void main(String[] args) &#123; FutureTask futureTask = new FutureTask(new FutureTaskThread()) ; ExecutorService service = new ThreadPoolExecutor(5,10,60L, TimeUnit.SECONDS,new ArrayBlockingQueue&lt;&gt;(10)); service.submit(futureTask) ; try &#123; System.out.println(futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java线程池","slug":"Java线程池","date":"2019-11-07T12:44:46.000Z","updated":"2019-11-07T12:44:46.000Z","comments":true,"path":"2019/11/07/Java线程池/","link":"","permalink":"http://example.com/2019/11/07/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"什么是线程池线程池，和连接池、常量池一样，是一种池化思想。大概意思是预先把线程都创建好，放到一个池子里，用的时候就去拿，用完了再给下一个任务用，以达到一种资源的高效利用。 为什么要有线程池为什么要有线程池？和这个问题相对应的一个问题是不用线程池行不行？答案是可以的。比如我们在想使用多线程的时候直接new一个Thread也是可以的，那么这两种方式有什么区别呢？每用一次new一次这样性能是很差的，而且用一次，new一次，很麻烦，而且这些线程之间很难统一管理。如果使用线程池，我们可以将这些线程重复利用，避免重复创建，浪费系统资源，同时方便我们统一管理，比如并发数量，定时执行等。 设计思想了解了什么是线程池以及为什么要有线程池之后，我们来看下在Java中是如何设计线程池的。 首先线程池线程池，既然是个池子，那也就是个容器，所以我们需要个容器来装这些线程，在Java中这个容器（池子）是HashSet. 线程池的设计中有三个主要模块： 核心池（core pool） 最大池(maximum pool) 队列（BlockingQueue） 大概思想是这样的，当需要创建一个线程时，我先检查池子中已有的线程（Worker）数量是否大于核心池数量，如果没有，继续在核心池里创建线程（Worker）. 如果核心池已经满了，那再有新的线程需要执行，我先把它放到一个队列里候着。 如果队列也满了，现在考虑往最大池里创建线程（Worker）。关于core pool和maximum pool的关系是这样的，core pool相当于公司的正式员工，maximum pool相当于临时工。当有顾客来时，先仅着正式员工用，正式员工不够了，让顾客先在大厅休息一哈，如果大厅也满了，再让临时工也工作起来。 如果maximum pool也满了，则执行拒绝策略。 我们通过一个流程图来展示下它的执行过程： 源码分析接下来我们从源码角度更细致地分析一下上述过程。 首先看构造函数 corePoolSize: 核心线程数。 maximumPoolSize: 最大线程数 workQueue: worker数量达到核心线程数后要加入的队列 keepAliveTime: 临时工的最大存活时间，如果临时工超过这个时间还没有工作，就会被销毁。 threadFactory: 用来创建线程的工厂。 handler: 线程池拒绝策略。 再来看下关于线程池状态和线程数量的相关定义： 使用原子变量ctl的高三位表示线程状态，低29位标识线程池中的线程数量。 再来看下线程池中最重要的方法execute(): 其实注释已经讲的很清楚了，这里三个框分别代表上面一节中的加入核心池，加入队列以及加入最大池。需要注意的是，在加入队列的时候，是进行了一个double check的，也就是说在将任务加入队列后重新判断线程池是否在运行，如果不在运行则执行拒绝策略，如果在运行但是worker数量为零则新增非核心线程。另外一个点就是何时执行拒绝策略？两种情况：线程池shutdown或者线程池满。 再来看下addWorker()方法干了些啥： 使用常见有两种创建方式 使用ThreadPoolExecutor()创建 1ExecutorService executorService = new ThreadPoolExecutor(5,10,60L,TimeUnit.SECONDS, new ArrayBlockingQueu(10)) 提交任务时： 123executorService.execute(new Runnable()&#123; //省略若干行代码&#125;) 使用Executor框架创建 1ExecutorService executorService1 = Executors.newFixedThreadPool(5); 但是，《阿里巴巴开发手册》中有这样的规定： 我们以FixedThreadPool为例来看下 这里的队列用的是LinkedBlockingQueue&lt;&gt;， 没有初始化容量，则默认的就是Integer.MAX_VALUE，因此如果不断的向队列中塞任务的话，就有可能导致OOM.","categories":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"MySQL索引篇","slug":"MySQL索引篇","date":"2019-11-06T08:47:54.000Z","updated":"2019-11-06T08:47:54.000Z","comments":true,"path":"2019/11/06/MySQL索引篇/","link":"","permalink":"http://example.com/2019/11/06/MySQL%E7%B4%A2%E5%BC%95%E7%AF%87/","excerpt":"","text":"提到MySQL索引，都会讲到B树和B+树，今天来梳理一下。 最开始是二叉查找树，但是这种树不平衡，有时候会退化成一条链表，使得查找时间边长，于是就有了二叉平衡树。 理论上讲，二叉平衡树已经能满足一些查找需求了，为什么还要有B树呢？ 因为数据库在磁盘中，而查找的时候需要读一部分数据到磁盘中，这就涉及到了IO，IO的时候是以磁盘块为单位读取的，或者说是以页为单位。我们使用树这种数据结构，一个磁盘块应该包含一个或者若干个节点，然后以节点为单位读入。那么AVL树有什么问题？它的每个节点太“瘦弱”了，只能装一个键值对，假如一个节点就是一个磁盘块的化，这就导致我们查询的时候增大IO次数。那么有什么对应办法呢？就是让每个节点“胖一点”，即让每个节点多装几个键值对。这就引出了B树。 B树突破了二叉，每个节点有多个键值对，这样一来，节点个数减少，我们查询的IO次数也会减少。 那还有没有优化的余地呢？上面我们讲到每个节点都含有多个键值对，为了更一步充分利用节点的空间，我们可以让非叶子节点只含有键，只有叶子节点才会包含数据，也就是键对应的值，这么一来，非叶子节点就能装更多的键了，树的高度和节点数就能更进一步被降低了。这种只用叶子节点保存数据的树就是B+树了。 不止如此，在B树的基础上，B+树的还用双向链表链接起了每个叶子节点，这样有什么好处呢？可以很方便的实现范围查询。 还有一个需要了解的是聚簇索引和非聚簇索引。 所谓聚簇索引，指的是以主键作为索引构建B+树，而且叶子节点存储数据的索引结构。 非聚簇索引，首先索引不是主键，其次它的叶子节点存放的不是数据而是索引对应的主键（需要注意的是这里InnoDB和MyISAM实现略有区别，InnoDB存放的是主键，而MyISAM存储的是文件地址，我们这里以InnoDB为主进行讲解）。也就是说，对于非聚簇索引，你首先需要根据索引找到主键，然后再根据主键进行聚簇索引查找，这一过程我们称之为回表。 所以这里我们就可以看到使用主键进行查询的好处：只需要查询一颗B+树（这里再加一点，对于每张表来说，每个索引就相当于一颗B+树）。 同时一些文章里也会提到，通常要求我们建表的时候选一个自增主键作为索引，为什么要这样要求呢？因为索引底层是由B+树实现的，自增主键可以使得我们再插入节点时减少业分裂，当当前页满时只需要再创建一个新页继续添加数据即可，不用对之前已有的页进行分裂。 那么就又有一个问题了，自增主键如何选？假如一个表里有身份证号，且能够保证它是自增的，我们可以用它做主键吗？可以是可以，但是要知道，普通索引的叶子节点是主键，你用身份证号做主键，这意味着叶子节点就很占空间了，肯定没有我们自己设置的自增主键划算。 联合索引，覆盖索引，最左匹配原则。 都说加索引可以提高查询效率，但是当我们查询时where后面有多个条件时，难道我们要为每一列都加个索引吗？其实不是的，一种更好的方法是可以加联合索引，并且联合索引是满足最左匹配原则的。什么意思呢，假如我们建立了联合索引key(a,b,c)，那么在今后的查询中，(a), (a,b), (a,b,c)这三种查询条件都是可以使用我们的联合索引来加快查询速度的。 覆盖索引主要是针对非聚簇索引和联合索引说的，指的是叶子节点中已经包含了我们要查询的列，这样就免的进行回表这一操作了。 总结： 其实可以看到，这些数据结构都不是凭空产生，一般都是为了满足某个需求才被人们创建。所以在某些程度上，知道一种技术为什么存在要比技术本身更为重要，否则永远只能是一个技术的学习者，而不是缔造者。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"Spring IoC 容器的实现(一)","slug":"Spring-Ioc容器的实现-一","date":"2019-11-02T12:04:31.000Z","updated":"2019-11-02T12:04:31.000Z","comments":true,"path":"2019/11/02/Spring-Ioc容器的实现-一/","link":"","permalink":"http://example.com/2019/11/02/Spring-Ioc%E5%AE%B9%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%B8%80/","excerpt":"","text":"本文开门见山，直接讨论Spring IoC容器的初始化过程。 关于Spring容器，有一个最基本的接口，叫做BeanFacotory, 它提供了容器最基本的一些特性。所有的容器都是基于它的。还有一个较为高级一点的容器接口，叫做ApplicationContext，它在BeanFactory的基础上，又提供了其他一些高级特性，比如访问资源。 本文以ApplicationContext的一个具体实现类FileSystemXmlApplicationContext为例，探究spring容器的初始化过程。先来看下它的主要代码。 显示构造函数： 123456789public FileSystemXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125; &#125; 这里的refresh()方法标志着容器初始化的启动，也是我们后面分析的重点。 还有一个方法 123456protected Resource getResourceByPath(String path) &#123; if (path != null &amp;&amp; path.startsWith(&quot;/&quot;)) &#123; path = path.substring(1); &#125; return new FileSystemResource(path); &#125; 它会在启动容器的过程中调用。 先看下FileSystemXmlApplicationContext的继承关系 下面正式分析BeanDefinition的Resource定位 refresh()方法在AbstractApplicationContext中实现： 代码虽长，其实只做了两件事：框出来的部分创建容器，剩余部分对创建好的容器进行一系列设置。继续来看创建容器的部分： 这里的refreshBeanFactory()是个抽象方法，在AbstractRefreshableApplicationContext中实现。 AbstractRefreshableApplicationContext 继续来看createBeanFactory() 123protected DefaultListableBeanFactory createBeanFactory() &#123; return new DefaultListableBeanFactory(getInternalParentBeanFactory()); &#125; 返回一个DefaultListableBeanFactory容器 再看loadBeanDefinitions(), 它同样是个抽象方法，它在AbstractXmlApplicationContext中实现 它先创建一个reader，然后通过这个reader加载BeanDefinition,继续看它的重载方法 对于xml的上下文来说，它走的应该是第二个if, 里面调用了XmlBeanDefinitionReader 的loadBeanDefinitions()方法，继续看 继续看它的重载方法 继续来看具体是如何获取资源的： ResourceLoader是个接口，这里使用了DefaultResourceLoader类实现的方法 好，到此整个分析过程差不多结束了，重新梳理一下： 在BeanDefiniton的Resource定位中，始于FileSystemXmlApplicationContext的refresh()方法，这里是容器初始化的开端，同时也是定位资源的开端。 这里的refresh()方法来自父类AbstractApplicationContext, 这个方法里面获得了容器并对容器进行了一系列操作。 这里获得容器的方obtainFreshBeanFactory()使用了模板方法模式，里面的模板方法refreshBeanFactory()交由具体子类实现，在这里是由子类AbstractRefreshableApplicationContext实现。 在AbstractRefreshableApplicationContext的refreshBeanFactory()中，创建了容器，并进行BeanDefinition的加载。 这个加载方法loadBeanDefinitons()同样是模板方法，涉及一系列的调用。具体它是通过一个BeanDefinitonReader来加载BeanDefinition的，加载的过程中就涉及到对各种形式location的解析。解析完之后差不多就真正完成了对resource的定位了。 总的来说，做了两件事。目的是初始化容器，首先你得有个容器，比如桶，其次你得有水，那么就得找到水在哪，上面主要描述的就是一个找水的过程。 起源于refresh,但是要找到水，还需要靠Reader 相当于下面这个过程 1234ClassPahtResource res = new ClassPathResouce(&quot;bean.xml&quot;) ;DefaultListableBeanFactory factory = new DefaultListableBeanFactory();XmlBeanDefinitionReader reader = new XmlBeanDefinionReader(factory);reader.loadBeanDifinition(res) ; 使用IoC容器时，需要以下几个步骤（即初始化容器的步骤）： 创建抽象资源，包括Ioc配置文件，Beandefiniton 创建BeanFactory 创建reader,读取BeanDefinition并回传给BeanFactory,完成载入和注册。 画一个调用的关系图就能更好的理解这个过程了。 ​ 参考《Spring技术内幕》","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring Ioc容器实现之BeanDefinition的Resource定位","slug":"Spring-Ioc容器实现之BeanDefinition的Resource定位","date":"2019-11-02T12:03:58.000Z","updated":"2019-11-02T12:03:58.000Z","comments":true,"path":"2019/11/02/Spring-Ioc容器实现之BeanDefinition的Resource定位/","link":"","permalink":"http://example.com/2019/11/02/Spring-Ioc%E5%AE%B9%E5%99%A8%E5%AE%9E%E7%8E%B0%E4%B9%8BBeanDefinition%E7%9A%84Resource%E5%AE%9A%E4%BD%8D/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"排序总结","slug":"排序总结","date":"2019-11-01T07:54:53.000Z","updated":"2019-11-01T07:54:53.000Z","comments":true,"path":"2019/11/01/排序总结/","link":"","permalink":"http://example.com/2019/11/01/%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/","excerpt":"","text":"十种常见经典排序 比较排序： 通过比较来决定元素间的相互顺序 非比较排序： （冒泡排序，快排，插入，选择，基数，桶，希尔，归并，堆） 冒泡排序算法思想相邻元素两两比较，将较大（较小）的交换到后面。 代码123456789101112public int[] bubbleSort(int[] arr)&#123; for(int i=0; i&lt;arr.length; i++)&#123; for(int j=0; j&lt;arr.length-i-1; j++)&#123; if(arr[j]&gt;arr[j+1])&#123; int t = arr[j] ; arr[j] = arr[j+1] ; arr[j+1] = t ; &#125; &#125; &#125; return arr ;&#125; 复杂度分析时间复杂度：$O(n^2)$ 空间复杂度：$O(1)$ 是否稳定稳定 选择排序1. 算法思想将整个数组分为两部分：有序的和无序的，每次从无序的那一部分中选择最小（最大）的追加在有序部分的末尾。 2. 代码1234567891011121314public int[] selectionSort(int[] arr)&#123; for(int i=0; i&lt;arr.length; i++)&#123; int minIdx = i; //用来定位每次最小值的位置 for(int j=i+1; j&lt;arr.length; j++)&#123; //内层循环用来选择最小值,每个元素和当前最小值比较 if(arr[j]&lt;arr[minIdx])&#123; minIdx = j ; &#125; &#125; int t = arr[i] ; arr[i] = arr[minIdx] ; arr[minIdx] = t ; &#125; return arr ;&#125; 3. 复杂度分析时间复杂度：$O(n^2)$ 空间复杂度：$O(1)$ 4. 是否稳定选择排序涉及到当前位置元素和后半段最小元素的交换，交换的两个元素不一定相邻，中间可能夹杂着和它们相等的元素，所以不稳定。 插入排序 算法思想 基本思想和选择排序类似，也是将整个数组划分为有序和无序两个片段。选择排序注重从无序的后半段里挑出最小（最大）的元素追加到有序部分的末尾，而插入排序注重从无序的后半段随便选一个然后按顺序插入到有序的前半段。所以选择排序重心在从无序的后半段选择，而插入排序重心在于往有序的前半段插入。 代码 1234567891011121314151617public int[] insertionSort(int[] arr)&#123; for(int i=1; i&lt;arr.length; i++)&#123; //外层循环负责从无序的后半段拿出来一个数 int temp = arr[i] ; int j; for( j=i-1; j&gt;=0; j--)&#123;//内层循环负责将aar[i]插入到前面 if(temp&lt;arr[j])&#123; arr[j+1] = arr[j] ; &#125; else &#123; arr[j+1] = temp ; break; &#125; &#125; arr[j+1] = temp ; &#125; return arr; &#125; 代码的关键在于需要用一个临时变量将正在比较的无序元素保存起来，然后依次向后移动有序元素，等到找到真正属于它的位置时再将它插入。 代码二： 123456789101112131415public int[] insertionSort2(int[] arr)&#123; for(int i=1; i&lt;arr.length; i++) &#123; int temp = i ; for(int j=i-1; j&gt;=0; j--)&#123; if(arr[temp]&lt;arr[j])&#123; int t = arr[temp] ; arr[temp] = arr[j] ; arr[j] = t; temp=j; &#125; &#125; &#125; return arr; &#125; 代码的关键在于需要用一个临时变量将正在比较的无序元素保存起来。相比代码一，这里边比较边交换。 复杂度分析 时间复杂度：$O(n^2)$ 空间复杂度：$O(1)$ 是否稳定 稳定 希尔排序 算法思想 希尔排序是个加强版的插入排序。按照不同的步长将元素分组，比如步长为2就代表每隔两个元素为一组，然后对每组进行插入排序，然后不断缩小步长，插入排序，直至步长为1. 代码 123456789101112131415161718public int[] shellSort(int[] arr)&#123; for(int gap=arr.length/2; gap&gt;0; gap/=2)&#123; //分成gap组，第gap个元素表示第1组的第二个元素 //进行插入排序,需要注意这里并不是一组一组的排，而是从第gap个一直往后遍历，会轮询对每个组排序，因为从gap往后遍历，遇到的元素要么是从本组第二个元素开始遍历到的，要么是其他组的从第二个元素开始的，所以可以用插入排序。 for(int i=gap; i&lt;arr.length; i++)&#123; int temp = i; for(int j=temp-gap; j&gt;=0; j-=gap)&#123; if(arr[temp]&lt;arr[j])&#123; int t = arr[temp] ; arr[temp] = arr[j] ; arr[j] = t; temp=j; &#125; &#125; &#125; &#125; return arr;&#125; 复杂度分析 时间复杂度：$O(n^2)$ 空间复杂度：$O(1)$ 是否稳定 不稳定 归并排序 算法思想 典型的分治思想，先将数组一分为二，最每个小数组分别排序，排好之后合并两个小数组得到最终结果。 代码 使用递归 123456789101112131415161718192021222324252627282930313233343536public class MergeSort &#123; public void mergeSort(int[] arr, int temp[], int start, int end)&#123; //先判断数组长度是否大于2 if(end-start&lt;2)&#123; return arr; &#125; int mid = start+(end-start)/2 ; mergeSort(arr, temp, start, mid); mergeSort(arr, temp, mid, end); merge(arr, temp, start, mid, end) ; &#125; public void merge(int[] arr, int[] res, int start, int mid, int end)&#123; System.arraycopy(arr,start,res,start,end-start); int i= start; int j= mid; int k=start ; while(i&lt;mid &amp;&amp; j &lt; end)&#123; if(res[i] &lt; res[j])&#123; arr[k++] = res[i++] ; &#125; else&#123; arr[k++] = res[j++] ; &#125; &#125; while(i&lt;mid)&#123; arr[k++] = res[i++] ; &#125; while(j&lt;end)&#123; arr[k++] = res[j++] ; &#125; &#125;&#125; 这段代码，嗯，有点东西，首先为了严格遵守空间复杂度，临时数组的创建的是在归并排序外面完成的，否则会因为递归不断创建临时数组，空间复杂度就会超过$O(n)$。其次，需要保证我们排序之后引用指向的还是原数组，即排序前后数组引用指向的是同一块空间，这一点也很重要，否则虽然排序效果达到了，但是引用指向的对象早已物是人非，很不优雅。 复杂度分析 时间复杂度： $$ \\begin{equation} \\begin{aligned} f(n) &amp;= 2f(\\frac{n}{2})+\\frac{n}{2}\\&amp; =2^2f(\\frac{n}{2^2})+\\frac{2}{2}n\\&amp;=2^3f(\\frac{n}{2^3})+\\frac{3}{2}n\\&amp;=2^kf(\\frac{n}{2^k})+\\frac{k}{2}n\\&amp;=n\\log{n}+\\frac{n}{2}\\log{n}\\&amp;=O(n\\log{n}) \\end{aligned} \\end{equation}$$ ​ 空间复杂度：$O(n)$ 是否稳定 稳定。 快速排序1. 算法思想快排的关键在于把枢轴（pivot）放到对应的位置，即枢轴前面的数都比它小，后面的数都比它大。这样枢轴就把整个数组划分成了两部分。那么问题来了，如何把确定枢轴真正的位置呢？即如何把枢轴放到真正的位置呢？ 假设对于数组a 0 1 2 3 4 5 6 7 8 9 72 6 57 88 60 42 83 73 48 85 我们刚开始认为a[0],令x=a[0]是枢轴，那我们分别用j=9从后往前遍历，以及用i=1从前往后遍历。 从后往前遍历时，遇到比x小的则暂时停止， 从前往后遍历时，遇到比x大的则暂时停止， 然后交换i和j位置上的元素，直到i和j相遇，这时的位置就是枢轴的位置，此时交换当前位置元素和枢轴元素。 总结一下，快排的关键在于：从两边向中间进行搜索，以此确定枢轴位置，然后递归进行此方法。 2. 代码12345678910111213141516171819202122232425262728293031323334public int quickSort(int[] arr, int left, int right) &#123; //假如选择arr[0]作为枢轴 int i = left; int j = right; if (left &gt; right) return 0; int t = arr[left]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; arr[j] &gt;= t) &#123; j--; &#125; while (i &lt; j &amp;&amp; arr[i] &lt;= t) &#123; i++; &#125; //交换 if (i &lt; j) &#123; int t1 = arr[i]; arr[i] = arr[j]; arr[j] = t1; &#125; &#125; arr[left] = arr[i]; arr[i] = t; quickSort(arr, left, i - 1); quickSort(arr, i + 1, right); return 0; &#125; 3. 复杂度分析快排的时间复杂度取决于枢轴选择的好坏，即划分的位置。从上面代码可以看出，划分操作的时间复杂度是$O(n)$。当划分的两个子数组长度分别是n-1和0时，复杂度最高，递归公式为$T(n)=T(n-1)+T(0)+O(n)$, 解为$O(n^2)$. 当两个数组长度接近等长时，复杂度最低, 递归公式为$T(n)=2T(n/2)+O(n)$, 解为$O(nlogn)$. 堆排序1. 算法思想要理解堆排序，首先要理解什么是堆，什么是大顶堆，什么是小顶堆。 首先，堆也是一种二叉树，其次，堆的父节点总是比两个子节点大（大顶堆）或比两个子节点小（小顶堆）。 堆排序的核心在于两点： 堆调整：首先将一个无序的数组序列调整成大顶堆，这样一来根节点就是整个序列的最大值了。 交换并重新调整：将根节点元素和堆最后一个元素交换，这样一来最后一个元素就是最大的了，剩下的前n-1个元素是无序的，重新调整。 那么就有一个问题了，如何调整？我们从最后一个非叶子节点开始，比较它和它的两个儿子的大小，如果它的儿子比它大，则进行交换。 那么问题又来了，如何确定非叶子节点？学过二叉树性质的朋友应该知道，最后一个非叶子节点的下标应该是$(a.length/2)-1$. 2. 代码1234567891011121314151617181920212223242526272829303132333435public void heapSort(int[] arr) &#123; //先调整堆 heapAdjust(arr, arr.length); //交换并重新调整 for (int i = 0; i &lt; arr.length; i++) &#123; int t = arr[0]; arr[0] = arr[arr.length - i - 1]; arr[arr.length - i - 1] = t; heapAdjust(arr, arr.length-i-1); &#125; &#125; //调整堆，从当前节点一直向下探索到叶子节点 public void heapAdjust(int[] arr, int len) &#123; for (int k = len / 2 - 1; k &gt;= 0; k--) &#123;//从最后一个非叶子节点开始 int j = k ; for (int i = k * 2+1; i &lt; len; i =i*2+1) &#123;//找到左孩子的位置 if (i+1&lt;len &amp;&amp; arr[i] &lt; arr[i + 1]) //找到两个孩子里面的较大者 i += 1; if (arr[j] &lt; arr[i]) &#123; //比较较大孩子与父节点的大小 int t = arr[i]; //进行交换 arr[i] = arr[j]; arr[j] = t; j=i; //交换完之后要继续向下探索，所以在此更新一下父节点的位置，即更新的子节点成了新的父节点 &#125; &#125; &#125; &#125; 3. 复杂度分析计数排序1. 思想它不是通过比较进行排序，而是通过额外开辟一块空间，通过下标来暗示这里存的是哪个元素，通过数组值来表示存的这个元素有几个。 具体操作是这样的： 找出待排序的数组中最大和最小的元素； 统计数组中每个值为i的元素出现的次数，存入数组C的第i项； 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。 代码12345678910111213141516171819202122232425262728293031public int[] countingSort(int[] arr)&#123; //寻找最大值和最小值 int min=arr[0], max = arr[0] ; for (int i=0; i&lt;arr.length; i++)&#123; if(arr[i] &gt; max) max = arr[i] ; if(arr[i] &lt; min) min = arr[i] ; &#125; //创建额外计数数组 int cntArr[] = new int[max-min+1] ; //开始计数 for(int i=0; i&lt;arr.length; i++)&#123; cntArr[arr[i]-min]++; &#125; //计数数组累加,cntArr[i]表示小于等于i的数有多少个 for(int i=1; i&lt;cntArr.length; i++)&#123; cntArr[i] += cntArr[i-1] ; &#125; //输出排序 int res[] = new int[arr.length] ; for(int i= arr.length-1; i&gt;=0; i--)&#123; res[cntArr[arr[i] - min]-1] = arr[i] ; &#125; return res ; &#125; 3. 分析这种排序算法适用于那种待排序序列比较集中的情况，这样创建的额外数组空间比较小，节省资源。 它是一种稳定排序。 桶排序1. 思想上面的计数排序核心思想在于我们使用一个额外的数组来进行计数，桶排序在思想上和计数排序有所类似，只不过桶排序中的桶直接拿来装待排序的元素了。在桶排序中，我们通过某种映射，把某些元素映射到某些桶里，然后对每个桶中元素进行排序，最后把所有桶连接起来。在这里，对桶中元素排序我们使用稳定的排序方法，如快排，这样最后我们的桶排序也是稳定的。 2. 代码基数排序1. 思想从个位开始，按照每个进制位对元素进行稳定排序。 参考十大经典排序算法（动图演示）","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"Java泛型","slug":"Java泛型","date":"2019-10-31T01:40:05.000Z","updated":"2019-10-31T01:40:05.000Z","comments":true,"path":"2019/10/31/Java泛型/","link":"","permalink":"http://example.com/2019/10/31/Java%E6%B3%9B%E5%9E%8B/","excerpt":"","text":"为什么要有泛型它的一个主要目标是将运行时才能发现的错误转移到编译期。 泛型是什么所谓泛型，就是将类型参数化，即把类型也作为一种参数。如何做到这点呢？通过解耦类或方法与所使用的类型之间的约束。 表面使用泛型类1234567891011121314151617181920212223242526public class GenericsDemo &lt;T&gt; &#123; private T var ; public void setVar(T v)&#123; var = v ; &#125; public T getVar()&#123; return var; &#125; public static void main(String[] args) &#123; GenericsDemo demo1 = new GenericsDemo(); demo1.setVar(&quot;string&quot;); System.out.println(demo1.getVar()); demo1.setVar(1); System.out.println(demo1.getVar()); GenericsDemo&lt;Integer&gt; demo2 = new GenericsDemo&lt;Integer&gt;() ;// demo2.setVar(&quot;stirng&quot;); demo2.setVar(1); System.out.println(demo2.getVar()); &#125;&#125; 可以看出，虽然我们定义了泛型类，但是在使用它的时候是可以不传入泛型实参的，如果不传， 在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型。 泛型接口定义方式和泛型类相似 123public interface Generator&lt;T&gt; &#123; T next() ;&#125; 需要注意的是当有个类实现这个泛型接口时的操作 实现类和接口都没写泛型参数 1234567public class FruitGenerator implements Generator &#123; @Override public Object next() &#123; return null; &#125;&#125; 如果接口写了泛型参数，但是没有传入实参，则实现类也必须写上，不然会报错 1234567public class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt; &#123; @Override public T next() &#123; return null; &#125;&#125; 如果接口写了泛型参数，且传入了实参，那么使用接口中泛型的地方都要换成传入的实参类型，但是这并不影响给这个实现类添加自己的泛型。 12345678public class FruitGenerator&lt;T&gt; implements Generator&lt;String&gt; &#123; private T fruitVar ; @Override public String next() &#123; return null; &#125;&#125; 泛型方法123public &lt;T&gt; T getData(T data)&#123; return data; &#125; 泛型通配符通配符就是?,是一个泛型实参，以一个泛型类作为形参为例： 1234567891011121314151617181920212223import java.util.*;public class Test &#123; public static void main(String[] args) &#123; List&lt;String&gt; name = new ArrayList&lt;String&gt;(); List&lt;Integer&gt; age = new ArrayList&lt;Integer&gt;(); List&lt;Number&gt; number = new ArrayList&lt;Number&gt;(); name.add(&quot;icon&quot;); age.add(18); number.add(314); getData(name); getData(age); getData(number); &#125; public static void getData(List&lt;?&gt; data) &#123; System.out.println(&quot;data :&quot; + data.get(0)); &#125;&#125; 我们在main里定义了三个list,每个list装入的类型都不一样，现在想用一个getData()方法来获取这三个list里面的值，这里的关键就在于getData()的形参怎么写了，如果给作为形参的list传入泛型实参，比如String,那么age和number这两个list就不能作为实参传进来了。怎么办呢？使用通配符，给形参的list加了通配符之后，就意味着海纳百川，不管实参是什么样的list都能传进来。 其实你也会发现，如果给形参list不加泛型也可以，因为到头来泛型都会被擦除掉。需要注意的是，这里的通配符List&lt;?&gt;，从逻辑上讲，它应该是其他List&lt;具体类型实参&gt;的父类。 当然了，通常也不会单独拿出来一个通配符来使用的，它一般都是配合上界或下界一起使用的。 内部原理​ 泛型只在编译器有效，在编译过程中，正确检验泛型结果后，**会将泛型相关信息擦除 ， 并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法 **。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"泛型","slug":"泛型","permalink":"http://example.com/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"海量数据处理","slug":"海量数据与空间限制面试题","date":"2019-10-30T06:59:07.000Z","updated":"2019-10-30T06:59:07.000Z","comments":true,"path":"2019/10/30/海量数据与空间限制面试题/","link":"","permalink":"http://example.com/2019/10/30/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%8E%E7%A9%BA%E9%97%B4%E9%99%90%E5%88%B6%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"海量数据相关的面试题已经是个老生常谈的话题了。相比于小量数据，海量数据存在两点限制：内存装不下或者读取太慢。 关于海量数据的面试题一般有一下几种： 寻找出现次数最多/最少/没有出现的数 对于海量数据的处理方式也不外乎以下几种： 分而治之(将大文件拆分成小文件) hash bitmap 题目1. 海量日志数据，提取出某日访问百度次数最多的那个IP思路 这是一道关于统计次数的题，一般使用hashmap或者bitmap就可以解决，使用hashmap时要注意空间是否满足要求。 这个问题有两个点：海量数据，次数最多。 先看第二个点。 把这个问题再提取一下：就是让你在海量数据里去找出现次数最多的那个数。 再提取一下：就是统计次数。问题就很清楚了，使用hash就可以解决。 然后再看第一个点。 海量数据，意味着数据太多，你的hash map内存可能放不下。怎么办？拆分！将这个海量数据拆分成若干个小文件，然后在每个小文件里统计出现次数最多的，最后综合所有的小文件中次数最多的ip找到王中王。是不是有点像归并排序？ 那么怎么拆分？假设要拆分成N个文件，可以这么做：hash(IP)%N 拓展这个问题是找出现次数最多的那个数。那么怎么找出现了一次的？或者，给定一个数，怎么判断它有没有在海量数据中出现过？下面我们一一来看。 2.5亿整数中找出不重复的整数。 找出不重复的数，其实也是统计次数，统计只出现一次的那些数，所以上述分割+hash的算法依然可用，不过这里我们再给出另一种更简单的方法：基于bitmap的方法。 对于每个数，我们使用2bit来表示，00表示出现0次，01表示出现1次，10表示出现多次。 2.5亿个整数，需要多少bit才能表示完呢，假设这些整数都是int类型的，那么最多也就只有$2^{32}$种数，已经能表示20多亿了，完全够应付这里的2.5亿，再考虑到每个数用2bit来表示出现次数，一共需要$2^{32}*2$bit=1GB.就可以表示这2.5亿个数的出现次数了。 需要注意的是，上面算出来的1G其实算是大的了，因为真正的并没有$2^{32}$个数，所以没必要开辟这么大空间，现在的开源实现如谷歌的EWAHCompressedBitmap已经对bitmap的内存分配做了很多优化，对于很稀疏的海量数据，那些稀疏数据之间的空缺是没必要申请空间的。 给定一个数，判断其是否在海量数据中。 同样可以使用bitmap解决。 给一串连续的数，缺失了一个，如何找出缺失的那个？ 求和呀 32位无符号整数的范围是0~4294967295，现在有40亿个数，让你 （a）找出所有缺失的数 （b）只找出其中一个缺失的数 ​ 划分区间，使用区间计数确定区间，然后再用bitmap","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"Java中的finalized方法","slug":"Java中的finalized方法","date":"2019-10-27T07:31:44.000Z","updated":"2019-10-27T07:31:44.000Z","comments":true,"path":"2019/10/27/Java中的finalized方法/","link":"","permalink":"http://example.com/2019/10/27/Java%E4%B8%AD%E7%9A%84finalized%E6%96%B9%E6%B3%95/","excerpt":"","text":"finalize是什么finalize()是定义在Object类中的一个方法，用于垃圾回收。 finalize原理当JVM的GC打算回收某个对象时，如果这个对象覆盖了finalize()方法，并且finalize()方法没有被执行过，会把这个对象放在一个叫做F-Queue的队列中，稍后由一个由虚拟机自动建立的，低优先级的Finalizer线程去触发finalize的执行。稍后GC将对F-Queue中的对象进行第二次小规模标记，如果这个对象仍然不可达，那么就把它回收了，如果在finalize()方法中这个对象实现了自救——将自己与GC Root关联起来，那么它将会被移出队列，不会被回收。 需要注意以下几个问题： finalize()只会被执行一次 对象不一定被垃圾回收，所以对应的，finalize也不一定会被执行 为什么要有finalize在JNI代码中做清理工作 作为确保某些非内存资源(如Socket、文件等)释放的一个补充","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"finalize","slug":"finalize","permalink":"http://example.com/tags/finalize/"}]},{"title":"Java中的异常","slug":"Java中的异常","date":"2019-10-27T06:26:42.000Z","updated":"2019-10-27T06:26:42.000Z","comments":true,"path":"2019/10/27/Java中的异常/","link":"","permalink":"http://example.com/2019/10/27/Java%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8/","excerpt":"","text":"参考 Java提高篇——Java 异常处理","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"异常","slug":"异常","permalink":"http://example.com/tags/%E5%BC%82%E5%B8%B8/"}]},{"title":"Java中的内部类","slug":"Java中的内部类","date":"2019-10-22T00:25:54.000Z","updated":"2019-10-22T00:25:54.000Z","comments":true,"path":"2019/10/22/Java中的内部类/","link":"","permalink":"http://example.com/2019/10/22/Java%E4%B8%AD%E7%9A%84%E5%86%85%E9%83%A8%E7%B1%BB/","excerpt":"","text":"分类成员内部类得先创建外部类，然后才能创建内部类。 保存了一个指向外部对象的引用，所以可以访问外部对象的成员。 方法内部类匿名内部类匿名类没有名字，继承自父类或者实现了某个接口，它是没有构造器的，因为它连名字都没有。 通过使用实例初始化，就能达到为匿名内部类创建一个构造器的效果（其实就是在定义类的时候在大括号里面再加个大括号写入想要初始化的内容）。 静态内部类（嵌套类 Nested Class）嵌套类的对象和外部类的对象没有关系。 不能访问非静态的外部类对象。 接口内部类如果想要某些公共代码，可以被某个接口的所有不同实现所共用，则可以使用接口内部的嵌套类。 为什么需要内部类先摘抄一段《Think in Java》里的解释： 每个接口都能独立的继承自一个（接口的）实现，所以无论外围类是否已经继承了某个（接口的）实现，对于内部类都没有影响。也就是说，内部类允许继承多个非接口类型。 内部类可以有多个实例，每个实例都有自己的状态信息，并且其与外围类对象的信息相互独立。 在单个外围类中，可以让多个内部类以不同的方式实现同一个接口，或继承同一个类。 我自己的理解： 如果说类是Java中的一个基本单元，那么内部类的存在就打破了这种说法。内部类的粒度更小，它允许在类的内部进一步的DIY, 提供了更高的灵活性。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"内部类","slug":"内部类","permalink":"http://example.com/tags/%E5%86%85%E9%83%A8%E7%B1%BB/"}]},{"title":"Java中的ReentrantReadWriteLock","slug":"Java中的ReentrantReadWriteLock","date":"2019-10-17T13:59:10.000Z","updated":"2019-10-17T13:59:10.000Z","comments":true,"path":"2019/10/17/Java中的ReentrantReadWriteLock/","link":"","permalink":"http://example.com/2019/10/17/Java%E4%B8%AD%E7%9A%84ReentrantReadWriteLock/","excerpt":"","text":"ReentrantReadWriteLock 看下它的类图 可以看到ReentrantReadWriteLock实现了ReadWriteLock接口。ReadWriteLock就是读写锁的意思，那么问题来了，为什么要有个读写锁呢？为什么要把读锁和写锁分开呢？这里就是出于对性能的考虑了，多个线程之间，可以同时读，但是不可以同时写或者一个读一个写，所以分开之后，读锁和写锁各司其职，可以提高效率。 和ReentrantLock锁的实现方法一样，ReentrantReadWriteLock也是通过聚合了AQS的实现类来来实加锁和释放锁的功能的。 在ReentrantReadWriteLock里面有三个比较重要的内部类，Sync,ReadLock和WriteLock. 其中Sync同样继承自AQS，用来做线程同步，它聚合到了ReadLock和WriteLock的定义中。 然后ReadLock和WriteLock作为静态内部类，都继承自Lock接口，在里面实现各自的加锁解锁功能。 读写状态的获取32位的state，高16位表示读状态，低16位标识写状态 写锁的获取与释放（可重入，排他锁）写锁是一个支持重入的排他锁。 如果有读锁，则获取写锁失败。 如果有其他线程的写锁，则获取写锁失败 获取其实注释已经写的很清楚了， 如果读数量非零或者写数量非零，或者锁的拥有者是其他线程，则获取锁失败。 如果总的状态数（读数量和写数量的总和）大于阈值，则获取锁失败。 否则获取锁成功，更新状态 当前获取状态 是否成功 当前写 成功 当前读 失败 其他写 失败 其他读 失败 简言之，如果锁被读线程（无论是不是当前线程）或者其他写线程占用，则获取写锁失败 释放 读锁的获取与释放读锁是一个支持重入的共享锁。 只要其他写线程没有获取写锁，则当前线程能够成功获取读锁。 当前获取状态 是否成功 当前写 成功 当前读 成功 其他写 失败 其他读 成功 如果写锁被其他线程获取，则当前线程获取读锁失败；如果当前线程获取了写锁或写锁未被获取，则增加读状态，成功获取读锁。 锁降级有种 一环套一环的感觉。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Lock","slug":"Lock","permalink":"http://example.com/tags/Lock/"}]},{"title":"Java中的AQS","slug":"Java中的AQS","date":"2019-10-17T05:47:12.000Z","updated":"2019-10-17T05:47:12.000Z","comments":true,"path":"2019/10/17/Java中的AQS/","link":"","permalink":"http://example.com/2019/10/17/Java%E4%B8%AD%E7%9A%84AQS/","excerpt":"","text":"AbstractQueuedSynchronizer 简写AQS, 队列同步器，是用来构建锁或者其他同步组件的基础框架，Lock接口的实现，如ReentrantLock等都有它的身影，都是通过它来实现线程同步的。从名字可以看出，首先它是个同步器，其次它里面还有个队列。 AQS使用了模板方法模式，这意味着AQS类里面大体有两种方法：需要被子类重写的涉及到具体细节的方法和模板方法，而模板方法就大致刻画了这个方法的整体功能。 看下AQS提供的需要重写的方法 需要重写的方法独占式boolean tryAcquire(int arg) 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; 独占式获取的具体操作。通过CAS设置state boolean tryRelease(int arg) 123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException(); &#125; 独占式释放的具体操作。当前线程释放同步状态，队列中接下来的线程则有机会获得同步状态。 共享式int tryAcquireShared(int arg) 123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; 共享式获取同步状态。 boolean tryReleaseShared(int arg) 123protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; 共享式释放同步状态 番外boolean isHeldExclusively() 123protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException(); &#125; 同步器是否被当前线程独占 而模板方法又分为两类：共享式的锁操作和独占式的锁操作，所谓共享式，指的是多个线程可以同时获取同步状态，独占式指的是同一时间只能有一个线程获取同步状态，其他未获取到同步状态的线程只能排队。 下面我们来看下AQS提供的模板方法： 模板方法独占式void acquire(int arg) 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 独占式获取同步状态，不成功则进入同步队列等待，如果进入队列也失败了，则中断自己。 void acquireInterruptibly(int arg) 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; 作用和acquire()差不多，唯一不同的是它能够响应中断。 boolean tryAcquireNanos(int arg, long nanosTimeout) 1234567public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); &#125; 增加了超时限制，如果一段时间后还没获得同步状态，则返回false. boolean release(int arg) 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; 独占式释放同步状态，唤醒队列中的下一个线程。 共享式void acquireShared(int arg) 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; 共享式获取同步状态，如果失败，加入队列。 void acquireSharedInterruptibly(int arg) 1234567public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); &#125; 共享式获取同步状态，且响应中断。 boolean tryAcquireSharedNanos(int arg, long nanosTimeout) 1234567public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout); &#125; 共享式获取同步状态，且有超时限制 boolean releaseShared(int arg) 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; 共享式释放同步状态。 番外Collection&lt;Thread&gt; getQueuedThreads() 123456789public final Collection&lt;Thread&gt; getQueuedThreads() &#123; ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node p = tail; p != null; p = p.prev) &#123; Thread t = p.thread; if (t != null) list.add(t); &#125; return list; &#125; 查询线程中的队列集合。 通过上述分析可以看到，通过模板模式的设计，当用户自己想要实现一个同步器时，只需要继承自AQS, 实现那些需要被覆盖的方法，然后对外提供一些接口就行了，就像ReentrantLock一样，它的lock(),tryLock(),release()等方法都是调用同步器的acquire(),tryAcquire()和release()方法，对实现者友好，更对用户友好。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Lock","slug":"Lock","permalink":"http://example.com/tags/Lock/"}]},{"title":"Java中的Lock","slug":"Java中的Lock","date":"2019-10-16T02:05:07.000Z","updated":"2019-10-16T02:05:07.000Z","comments":true,"path":"2019/10/16/Java中的Lock/","link":"","permalink":"http://example.com/2019/10/16/Java%E4%B8%AD%E7%9A%84Lock/","excerpt":"","text":"Lock是JUC包中的一个接口，是在synchronized关键字之后出现的，用来提供锁的功能，本文主要讨论Lock接口以及其实现类，以及为什么有了synchronized关键字了还要有Lock. synchronized作为内嵌的Java关键字，其可以隐式地获取和释放锁，它简化了同步的管理，同时也固化了锁的获取和释放，缺少灵活性。 在Java SE 5 之后，新增了Lock接口（以及相关实现类），相比于Synchronized关键字，它需要显式的获取和释放锁，同时增加了超时获取、响应中断等方法。 先来看下它的实现关系 我们会主要讨论圈出来的三个实现类 再来看下Lock接口的成员 其中lock(),tryLock(),tryLock(ong, TimeUnit)以及lockInterruptibly()用来加锁，unlock()用来解锁。需要注意的是如果使用lockInterruptibly()方法来获取锁的话，如果线程没有获取成功而进入等待队列，那么这个线程是可以响应中断的，相比只下，使用synchronized关键字获取锁时如果进入等待队列，线程是不能响应中断的。 Lock接口只是定义了实现锁的一系列约定，比如lock(),unLock()以及tryLock()等，具体的实现都是交给它的实现类去做的，比如ReentrantLock,ReentrantReadWriteLock.ReadLock和ReentrantReadWriteLock.WriteLock等。而这些实现类能够实现锁功能的关键，在于它们都聚合了一个AQS的实现类，AQS是一个抽象类，通过模板方法模式，提供了一系列状态同步的方法。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Lock","slug":"Lock","permalink":"http://example.com/tags/Lock/"}]},{"title":"https协议","slug":"https协议","date":"2019-10-15T13:51:10.000Z","updated":"2019-10-15T13:51:10.000Z","comments":true,"path":"2019/10/15/https协议/","link":"","permalink":"http://example.com/2019/10/15/https%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"相比于http的明问传输，易被篡改的特点，提出了https。 https利用了对称加密和非对称加密，引入了第三方机构CA,证书权威机构 协议上讲它在应用层下面加了个SSL/TLS层。 首先服务端会向第三方机构申请证书，如何申请呢？服务端告诉认证中心自己的个人身份信息以及公钥，认证中心经过核实后发给服务端一个证书。证书包含了哪些内容呢？ 证书颁发机构名称 证书本身的数字签名（先hash再用机构的私钥加密） 被机构私钥加密过的证书持有者的公钥 签名证书用到的hash算法 服务端网址 还有一个前提，就是现在的浏览器都默认内置了CA根证书，包含了CA的公钥。 有了这些东西后，客户端现在想和服务端通信，服务端把证书发给客户端，客户端根据自己的根证书里面的公钥，去 验证证书真假（先拿证书公钥把签名解密得到摘要A，然后根据相应hash算法对证书重新计算摘要得到摘要B，看两个是否相等） 证书是真的以后，用机构公钥解密证书持有者的公钥（注意证书持有者也就是服务端有一对密钥，证书也有一对） 然后拿解密出来的公钥加密后面真正通信时需要用到的对称加密的密钥进行加密，发给服务端，服务端拿自己的私钥解密得到密钥，开始通信。 总结：https思想上的创新点在哪里呢？引入了第三方机构和非对称加密，所以说如果这个第三方机构凉了那也就真凉了，反正这些做法都不能说从根本上解决安全问题，因为总有一个起始点是不安全的。据说量子密码可以突破这个起始点？","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"https","slug":"https","permalink":"http://example.com/tags/https/"}]},{"title":"强化学习","slug":"强化学习","date":"2019-10-14T11:47:30.000Z","updated":"2019-10-14T11:47:30.000Z","comments":true,"path":"2019/10/14/强化学习/","link":"","permalink":"http://example.com/2019/10/14/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"前言强化学习是一类算法, 是让计算机实现从一开始什么都不懂, 脑袋里没有一点想法, 通过不断地尝试, 从错误中学习, 最后找到规律, 学会了达到目的的方法。 那计算机通过什么来学习呢? 原来计算机也需要一位虚拟的老师, 这个老师比较吝啬, 他不会告诉你如何移动, 如何做决定, 他为你做的事只有给你的行为打分, 那我们应该以什么形式学习这些现有的资源, 或者说怎么样只从分数中学习到我应该怎样做决定呢? 很简单, 我只需要记住那些高分, 低分对应的行为, 下次用同样的行为拿高分, 并避免低分的行为。 所以说，强化学习具有分数导向性。 一些决策性的问题适合用强化学习。 常用RL方法： Model-Free RL Q Learning Sarsa Model-Based RL Q-Learning关键在于Q表","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"http://example.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"Java中的final关键字","slug":"Java中的final关键字","date":"2019-10-11T07:54:43.000Z","updated":"2019-10-11T07:54:43.000Z","comments":true,"path":"2019/10/11/Java中的final关键字/","link":"","permalink":"http://example.com/2019/10/11/Java%E4%B8%AD%E7%9A%84final%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"用法修饰变量修饰基本类型：基本类型的值不可被改变 修饰引用：引用的指向不能被改变 被final修饰的基本类型和String类型会在编译器被放到常量池 修饰方法方法不可被覆盖 修饰类类不可被继承 原理我们反编译如下代码： 123456789public final class Tiger &#123; private final String name =&quot;tiget&quot; ; private final int a = 1; public final void run()&#123; System.out.println(&quot;tiger is running&quot;); &#125;&#125; 得到：","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"关键字","slug":"关键字","permalink":"http://example.com/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"}]},{"title":"Java中new对象时到底发生了什么","slug":"Java中new对象时到底发生了什么","date":"2019-10-10T08:12:49.000Z","updated":"2023-05-29T14:17:39.311Z","comments":true,"path":"2019/10/10/Java中new对象时到底发生了什么/","link":"","permalink":"http://example.com/2019/10/10/Java%E4%B8%ADnew%E5%AF%B9%E8%B1%A1%E6%97%B6%E5%88%B0%E5%BA%95%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/","excerpt":"","text":"Java中有许多创建对象的方式，比如使用new关键字，使用反射，使用序列化/反序列化，使用克隆，其内部原理也都不一样，本文主要讨论在使用new关键字创建对象的前前后后JVM都做了那些事。要讲清楚这个事情，需要了解一定的JVM内存模型，以及类加载机制。 ###缘起 首先要明白，创建对象这是一个运行期的动作，在运行期前面，还有一个编译期。编译期就是将我们写的java文件编译成class文件的过程，运行期指的是JVM动态加载class文件并执行的过程。在讨论创建对象之前，首先要经过编译器，生成了需要的class文件。关于class文件的介绍可以查看这篇文章。 ###使用new创建对象 这一过程涉及到许多类加载的知识。使用new关键字创建对象时，主要经过以下几个过程： 虚拟机遇到new指令，到常量池定位到这个类的符号引用。 检查符号引用代表的类是否被加载、解析、初始化过。 虚拟机为对象分配内存。 虚拟机将分配到的内存空间都初始化为零值。 执行方法，成员变量进行初始化。 我们写一段简单的代码来帮助理解上述过程： Father.java 1234567891011121314public class Father &#123; private String privateFiled = &quot;privateField&quot; ; protected String protectedField = &quot;protectedField&quot; ; public String publicField = &quot;publicField&quot; ; private void privateMethod()&#123; &#125; protected void protectedMethod()&#123; &#125; public void publicMethod()&#123; &#125;&#125; Son.java 1234567public class Son extends Father &#123; private String name ; public void introduce()&#123; System.out.println(&quot;I&#x27;m son&quot;); &#125;&#125; Test.java 12345public class Test &#123; public static void main(String[] args) &#123; Father son = new Son(); &#125;&#125; 下面我们来逐一解释这几个过程。 ####虚拟机遇到new指令，到常量池定位到这个类的符号引用 我们在Test.java中的main方法中使用new关键字创建Son对象，我们反编译一下Test.java： 常量池： 指令： 可以看到在main方法首先就是new指令，需要new一个Son对象，这时候JVM回去常量池中寻找这个类的符号引用。可以看到这个符号引用在常量池中索引为2，继续在常量池中查看第二个常量，发现它是一个class,并且class的名字存储在第15个常量，第15个常量是个字符串，内容是Son，由此就找到了需要创建的类的符号引用。 检查符号引用代表的类是否被加载、解析、初始化过上一步中我们已经知道了需要new出一个Son对象，这一步的目的就是检查代表Son的对应类有没有被初始化，这里其实是类加载的内容。也就是说，要想在运行期使用某个类，在此之前必须把这个类对应的class文件加载到内存，并对数据进行校验、解析和初始化，才能转换成可以被JVM直接使用的Java类型。如果这个类还没有被初始化，则执行类加载过程进行初始化。 虚拟机为对象分配内存好，经过上述步骤，我们和类相关的工作已经做完了，现在内存中也有了JVM可以用的java类型了，接下来就是准备对象相关事宜。 首先就是给对象分配内存，那么分配多少呢？其实对象的大小在类加载完成后就已经确定了， 这里要做的只不过是把人家需要的空间给分配出来就行。这里需要注意的是对象的结构，有对象头、实例字段和对齐填充字段，所以分配的空间肯定是要比我们所能看到的空间大的。 关于继承，是如何分配内存的 对于继承自父类的子类来说，在创建子类的时候，并不会创建父类，只不过是在调用自类的构造方法的时候会调用父类的构造方法进行成员变量的初始化，仅此而已。试想一下任何类都继承自Object类，如果每次创建自类的时候都要创建一个父类，那将会造成多少冗余。 那既然没有创建父类，我们讲的子类能访问继承自父类的非private的成员变量和方法又是哪来的呢？其实在分配内存的时候，JVM会给子类自身以及从父类继承下来的各种属性和方法都分配空间的，注意是各种。虽然官方文档里讲的是被private修饰的成员变量不会被继承，但是可以通过public的getter和setter来获得和修改，但是笔者认为，其实private变量也被继承下来了，只不过直接访问不到而已。 分配内存时是如何保证线程安全的 在分配内存的时候，都会给每个线程预先划分好一小块内存，叫做TLAB(Thread Local Allocation Buffer),这部分内存是本地线程独享的，以此来防止多个线程给同一块地址空间上分配对象。 内存一定是分配在堆上吗 逃逸分析、栈上分配、标量替换等技术使得不那么一定了。 如果分配到堆上，分配到堆上的哪里 看是小对象还是大对象。小对象分配到Eden,大对象放到Old Gen. 虚拟机将分配到的内存空间都初始化为零值需要注意的是，这里的初始化为零值并不是我们自己写的代码里的赋值操作，而是JVM自带的操作。 执行方法，成员变量进行初始化这里才是真正执行我们自己的构造方法，在构造方法里要先调用父类的构造方法，一直向上回溯一直到最根源，从最根源的父类构造方法开始依次向下调用。 需要注意的是，这里标题写的是成员变量初始化，而我内容写的是执行构造方法，但事实是，有些成员变量的初始化工作并不是写在构造方法里面的，那这是怎么回事呢？ 实际上，如果我们对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将其中的代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后(还记得吗？Java要求构造函数的第一条语句必须是超类构造函数的调用语句)，构造函数本身的代码之前。 下面这段代码 12345678910111213141516171819202122public class Test2 &#123; private int i = 1; private int j = i + 1; public Test2(int var)&#123; System.out.println(i); System.out.println(j); this.i = var; System.out.println(i); System.out.println(j); &#125; &#123; // 实例代码块 j += 3; &#125; public static void main(String[] args) &#123; new Test2(8); &#125;&#125; 经过编译器优化后的构造函数就变成了 12345678910public Test2(int var)&#123; i = 1 ; j = i + 1 ; j += 3 ; System.out.println(i); System.out.println(j); this.i = var; System.out.println(i); System.out.println(j); &#125; 所以输出应该是 12341585 从&lt;clinit&gt;() &lt;init&gt;()的角度再次考虑考虑两个概念： 类初始化 指的是类加载过程中的最后一个阶段。 类实例化 指的是创建对象的过程。 在Java中， 创建一个对象常常需要经历如下几个过程：父类的类构造器() -&gt; 子类的类构造器() -&gt; 父类的成员变量和实例代码块 -&gt; 父类的构造函数 -&gt; 子类的成员变量和实例代码块 -&gt; 子类的构造函数。 &lt;clinit&gt;()是什么 clinit是class类构造器对静态变量，静态代码块进行初始化。由所有静态字段的赋值操作以及静态代码块按出现顺序构成。参考这篇文章 &lt;init&gt;()是什么 init是instance实例构造器，对非静态变量解析初始化 。由所有实例变量的赋值，所有实例代码块以及构造函数里面的代码构成。其中实例变量的赋值以及实例代码块是放在最前面执行的。 下面以一个例子来说明&lt;clinit&gt;()和&lt;init&gt;() 考虑下面这段代码： 12345678910111213141516171819202122232425262728293031323334public class StaticTest &#123; public static void main(String[] args) &#123; staticFunction(); &#125; static StaticTest st = new StaticTest(); static &#123; //静态代码块 System.out.println(&quot;1&quot;); &#125; &#123; // 实例代码块 System.out.println(&quot;2&quot;); &#125; StaticTest() &#123; // 实例构造器 System.out.println(&quot;3&quot;); System.out.println(&quot;a=&quot; + a + &quot;,b=&quot; + b); &#125; public static void staticFunction() &#123; // 静态方法 System.out.println(&quot;4&quot;); &#125; int a = 110; // 实例变量 static int b = 112; // 静态变量&#125;/* Output: 2 3 a=110,b=0 1 4 *///:~ 我们来分析一下，staticFunction()是个静态方法，对它的调用就用到了invokestatic指令，所以会进行类加载，涉及到加载、验证、准备、解析、初始化几个阶段，其中在初始化阶段会调用&lt;clinit&gt;()进行类变量的初始化，而&lt;clinit&gt;()由静态字段的赋值操作以及静态代码块按照出现顺序组成，所以&lt;clinit&gt;()内容大概是这样的： 12345static StaticTest st = new StaticTest();static &#123; //静态代码块 System.out.println(&quot;1&quot;);&#125;static int b = 112; 注意！请看我的手法！在这里神奇的事情发生了，我们说上面这段代码是&lt;clinit&gt;()的内容，也就是类加载过程中初始化阶段的内容，但是！你会发现在类初始化的时候已经混进来了类实例化的操作，也就是说，这个类可能还没有创建好呢但是就已经开始进行实例化了，并且实例化的代码还放在了&lt;clinit&gt;()代码的开头，可以这样做吗？答案是可以的，但是这样就会造成一个问题，你在实例化代码时执行构造函数里面的内容时，里面的静态变量其实都还没有被来得及赋值。我们先将上述代码进一步细化, 将静态变量st的赋值分解为两个操作：创建对象和赋值。 123456789int a = 110;System.out.println(&quot;2&quot;);// 实例代码块System.out.println(&quot;3&quot;);//实例构造器System.out.println(&quot;a=&quot; + a + &quot;,b=&quot; + b);//实例构造器给静态变量st赋值 System.out.println(&quot;1&quot;); //静态代码块static int b = 112; 这个就是完整的&lt;clinit&gt;()的内容了，可以看出，在初始化阶段，输出： 123423a=110,b=01 初始化结束，调用staticFunction(),输出 14 所以，最后输出为： 1234523a=110,b=014 在程序最后的一行，增加以下代码行： 1static StaticTest st1 = new StaticTest(); 那么，此时程序的输出又是什么呢？ 加入这行代码后，&lt;clinit&gt;()内容变为： 123456789101112131415int a = 110;System.out.println(&quot;2&quot;);// 实例代码块System.out.println(&quot;3&quot;);//实例构造器System.out.println(&quot;a=&quot; + a + &quot;,b=&quot; + b);//实例构造器给静态变量st赋值 System.out.println(&quot;1&quot;); //静态代码块static int b = 112;int a = 110;System.out.println(&quot;2&quot;);// 实例代码块System.out.println(&quot;3&quot;);//实例构造器System.out.println(&quot;a=&quot; + a + &quot;,b=&quot; + b);//实例构造器给静态变量st1赋值 所以初始化阶段输出为： 123456723a=110,b=0123a=110,b=112 初始化结束，调用staticFunction(),输出 14 所以，最后输出为： 1234567823a=110,b=0123a=110,b=1124 总结好，我们来总结一下创建对象的过程: 要new出一个对象，首先是需要这个对象的类型信息的，也就是对应的类，如果内存中还没有这个类型信息的话，JVM要先执行类加载过程，将class文件加载进内存，并且经过准备阶段、解析阶段以及初始化阶段，最后变成能被JVM使用的类型（加载进来的东西都放在方法区，也就是说方法区放的是类信息）。如我们前面所说，万事万物皆对象，其实class文件在被载入内存初始化后也是个类，叫做Class类，所以话句话说，要new一个对象，首先要看内存中有没有这个对象对应的Class类。然后就是分配内存（这里要注意继承情况下内存是如何分配的）、初始化零值以及执行构造方法。 参考深入理解Java对象的创建过程：类的初始化与实例化 JVM类生命周期概述：加载时机与加载过程 万万没想到，JVM内存结构的面试题可以问的这么难？","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}]},{"title":"一次由继承引发的思考","slug":"一次由继承引发的思考","date":"2019-10-10T02:20:30.000Z","updated":"2019-10-10T02:20:30.000Z","comments":true,"path":"2019/10/10/一次由继承引发的思考/","link":"","permalink":"http://example.com/2019/10/10/%E4%B8%80%E6%AC%A1%E7%94%B1%E7%BB%A7%E6%89%BF%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"","text":"本文主要讨论，我在考虑java种private修饰的属性和方法到底有没有被继承下来的一系列思考。 使用反射？观察class文件？new一个对象时到底发生了啥？创建一个对象常常需要经历如下几个过程：父类的类构造器() -&gt; 子类的类构造器() -&gt; 父类的成员变量和实例代码块 -&gt; 父类的构造函数 -&gt; 子类的成员变量和实例代码块 -&gt; 子类的构造函数。 先依次执行实例变量初始化和实例代码块初始化，再执行构造函数初始化。也就是说，编译器会将实例变量初始化和实例代码块初始化相关代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后，构造函数本身的代码之前。 类的实例化是指创建一个类的实例(对象)的过程； 类的初始化是指为类中各个类成员(被static修饰的成员变量)赋初始值的过程，是类生命周期中的一个阶段。 参考深入理解Java对象的创建过程：类的初始化与实例化","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"继承","slug":"继承","permalink":"http://example.com/tags/%E7%BB%A7%E6%89%BF/"}]},{"title":"HashMap中的hash方法","slug":"Map中的hash方法","date":"2019-10-08T12:50:13.000Z","updated":"2019-10-08T12:50:13.000Z","comments":true,"path":"2019/10/08/Map中的hash方法/","link":"","permalink":"http://example.com/2019/10/08/Map%E4%B8%AD%E7%9A%84hash%E6%96%B9%E6%B3%95/","excerpt":"","text":"在HashMap,HashTable和ConcurrentHashMap中，hash()方法主要是拿来做定位，即通过对key进行散列，从而确定这个entry的存储位置。但是为了避免发生碰撞，java中的hash方法还是有许多细节操作的。 HashMapjdk 7代码如下： 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; 上述代码中，hash()方法负责生成哈希码，indexFor()方法负责确定地址。可以看到，哈希码的生成主要通过随机种子和hashCode进行异或，后面的两行代码是为了进行混淆。因为最终索引（存储地址）是通过哈希码取模数组长度得到的，这意味着只有有限比特位（length-1 个比特位）会影响到最终结果，混淆的作用就是为了尽力让哈希码的每个位置在确定索引时都发挥作用。 说到这里，请留意下hashCode方法，这是Object类的一个native方法，返回的是对象的地址，在HashMap中被重写了 1234public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue());&#125; 当然equals方法也被重写了，这里就不再赘述。 jdk 81234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 直接拿hashCode和高16位异或。 HashTablejdk 7相比于HashMap，HashTable是线程安全的，而且它的hash方法也显得很朴实无华，没有添加扰动， 1234private int hash(Object k) &#123; // hashSeed will be zero if alternative hashing is disabled. return hashSeed ^ k.hashCode(); &#125; 它没有indexFor方法，取而代之的是一句代码 1int index = (hash &amp; 0x7FFFFFFF) % tab.length; 为什么没加扰动呢，我是这么考虑的。 从性能角度考虑，HashMap采用2的次幂作为容量有一部分是出于性能考虑，使用2的次幂后，无论是扩容还是indexFor,都可以通过位运算加快运算速度。 而HashTable通过synchronized关键字来保证线程安全，它在性能上已经落后HashMap了，所以对2的次幂要求不是很高。再者，HashTable初始容量为11，按照$2n+1$扩容，容量一直是素数，而这个素数恰好能使得在取模的过程中让key分散均匀一些，所以也就没有加扰动。 jdk 812int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length; 分别将hash方法和indexFor方法变成了两句话。（可以看到1.8中HashMap和HashTable都摒弃了hashSeed. ConcurrentHashMapjdk 7123456789101112131415161718private int hash(Object k) &#123; int h = hashSeed; if ((0 != h) &amp;&amp; (k instanceof String)) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // Spread bits to regularize both segment and index locations, // using variant of single-word Wang/Jenkins hash. h += (h &lt;&lt; 15) ^ 0xffffcd7d; h ^= (h &gt;&gt;&gt; 10); h += (h &lt;&lt; 3); h ^= (h &gt;&gt;&gt; 6); h += (h &lt;&lt; 2) + (h &lt;&lt; 14); return h ^ (h &gt;&gt;&gt; 16); &#125; 和HashMap中做法差不多，只不过加的不是同一种扰动。 jdk 81234static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; 愈发简洁，参考1.8中的HashMap,和高16位异或，然后与了HASH_BITS,主要是为了防止出现负数。 1static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash 可以看到，1.8中HashMap和ConcurrentHashMap的hash设计都简单了许多，其实一定程度上也和红黑树的引入有关系，1.8版本引入了红黑树，在一定程度上降低了哈希冲突后的检索耗时，所以在散列的尽可能均匀上下功夫不多。 参考全网把Map中的hash()分析的最透彻的文章，别无二家","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"}]},{"title":"HashMap中的容量","slug":"HashMap中的容量","date":"2019-10-08T12:16:14.000Z","updated":"2019-10-08T12:16:14.000Z","comments":true,"path":"2019/10/08/HashMap中的容量/","link":"","permalink":"http://example.com/2019/10/08/HashMap%E4%B8%AD%E7%9A%84%E5%AE%B9%E9%87%8F/","excerpt":"","text":"为什么建议初始化容量真正的容量是多少为什么是2的次幂","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"}]},{"title":"Spring的一点思考","slug":"Spring的一点思考","date":"2019-10-02T11:55:38.000Z","updated":"2019-10-02T11:55:38.000Z","comments":true,"path":"2019/10/02/Spring的一点思考/","link":"","permalink":"http://example.com/2019/10/02/Spring%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/","excerpt":"","text":"何为控制反转以前对于有依赖关系的类，比如类A依赖类B，那么使用时一般是要在A里面new个B，如果使用spring,则将控制权交给IoC容器，让IoC容器负责bean的创建以及依赖关系的调解（即依赖注入）。 何为依赖注入为一个对象获取它所依赖的对象的引用（在此之前，肯定要把这个bean注入到spring容器中）。 如何依赖注入 通过setter 通过构造方法 通过接口 何为面向切面编程","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://example.com/categories/JavaWeb/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"记一次Http 415的经历","slug":"记一次Http-415的经历","date":"2019-10-01T05:45:19.000Z","updated":"2019-10-01T05:45:19.000Z","comments":true,"path":"2019/10/01/记一次Http-415的经历/","link":"","permalink":"http://example.com/2019/10/01/%E8%AE%B0%E4%B8%80%E6%AC%A1Http-415%E7%9A%84%E7%BB%8F%E5%8E%86/","excerpt":"","text":"问题重现： 使用spring mvc实现一个简单的登录功能，前后端分离，使用nginx反向代理实现跨域请求 这个问题困扰了我一天多，从最开始检查nginx配置到检查表单提交再到查看http请求头再到检查后端spring相关配置以及注解的问题，最后终于找到问题。整个过程中除了415当然还蹦出了其他各种错误，如400，405，500，不过415错误一直断断续续贯穿始终。下面来复盘一下整个过程。 从实际生产角度考虑，我需要实现一个前后端分离的系统，由于静态资源和后端服务可能不在同一个端口，甚至不在同一个服务器，所以必然存在跨域的问题，跨域是由于浏览器的同源策略导致的，为了保证其安全性，这里暂不去讨论同源策略是什么。解决跨域的方法很多，但大多数都是要修改前端代码或者后端代码，这是很不优雅的，所以我选择了使用nginx的反向代理功能来实现这一需求，将静态资源放在nginx上。 nginx排查部分nginx配置： 1234567891011listen 8800; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /api/ &#123; proxy_pass http://localhost:8080/; &#125; location / &#123; root E:\\SimpleMall-Admin-Web; index login.html; &#125; 静态资源url: localhost:8800 后端服务：localhost:8080 请求url: /api/login 刚开始一直以为是nginx配置有问题，因为我看到请求的url一直都是localhost:8800/api/login，我当时以为发起请求后应该是localhost:8080/login，以为会有个跳转的动作，后来我发现是自己对反向代理理解有误，这个代理过程对用户透明，所以我们是看不到url的变化的。 ajax 表单提交然后检查ajax提交表单过程 为什么使用ajax呢？因为这是个前后端分离的系统，所以页面应该跳到哪里这些事后端应该是不知道的，它只需要根据请求返回一些json就可以了。 然后发现，表单提交这有我不知道的东西： 关于提交按钮的两种写法： 写法一： 1&lt;input id=&quot;commit&quot; type=&quot;submit&quot; onclick=&quot;login()&quot; /&gt; 写法二： 1&lt;input id=&quot;commit&quot; type=&quot;button&quot; onclick=&quot;login()&quot; /&gt; 当然还可以写成button标签的形式，不过提交作用和第一种写法是一样的。 对于这两种写法，如果我们没有写这个onclick事件， 对于写法一：我们点击这个按钮他会自动提交整个form,即使form里面action也没写它也会提交，方法默认为GET,且会刷新整个页面，除非把form的onsubmit事件设置成返回false. 对于写法二：必须我们自己写这个onclick事件后它才会提交. 但是如果我们都写了onclick事件，那么他俩在请求上是没有区别的。 因为我们都自己实现了onclick事件，所以下面选其一，使用第二种方式。 我们在js里面使用ajax来实现提交的动作： 12345678910111213141516171819202122function login()&#123; var usn = $(&quot;#userName&quot;).val(); var pwd = $(&quot;#passWord&quot;).val(); var datas = &#123;&quot;userName&quot;:usn,&quot;passWord&quot;:pwd&#125; $.ajax(&#123; //几个参数需要注意一下 type: &quot;POST&quot;,//方法类型 dataType: &quot;text&quot;,//预期服务器返回的数据类型 url: &quot;/api/login&quot; ,//url data: datas, success: function (result) &#123; alert(result) console.log(result);//打印服务端返回的数据(调试用) if (result.resultCode == 200) &#123; alert(&quot;SUCCESS&quot;); &#125; &#125;, error : function() &#123; alert(&quot;异常！&quot;); &#125; &#125;); &#125; 同时在后端使用@RequestBody注解来解析。 12345678910@Controllerpublic class AdminController &#123; @RequestMapping(value = &quot;/login&quot;,method = RequestMethod.POST,consumes = &quot;application/json&quot;) public @ResponseBody String login(@RequestBody Administrator administrator)&#123; String userName = administrator.getUserName(); String passWord = administrator.getPassWord(); System.out.println(userName+&quot;================&quot;+passWord); return &quot;dddddd&quot; ; &#125;&#125; data 为js对象，无ContentType 1234567891011121314151617$.ajax(&#123; //几个参数需要注意一下 type: &quot;POST&quot;,//方法类型 dataType: &quot;text&quot;,//预期服务器返回的数据类型 url: &quot;/api/login&quot; ,//url data: datas, success: function (result) &#123; alert(result) console.log(result);//打印服务端返回的数据(调试用) if (result.resultCode == 200) &#123; alert(&quot;SUCCESS&quot;); &#125; &#125;, error : function() &#123; alert(&quot;异常！&quot;); &#125; &#125;); 报错415，请求头如下： 可以看到，请求头的Content-Type是默认的application/x-www-form-urlencoded形式，而RequestBody注解是按照Content-Type来寻找对应的转换器进行解析的，并且它无法解析这种形式（至于为什么不能我们后面再分析）。 所以我们修改ContentType data为js对象，ContentType为json 123456789101112131415161718$.ajax(&#123; //几个参数需要注意一下 type: &quot;POST&quot;,//方法类型 dataType: &quot;text&quot;,//预期服务器返回的数据类型 url: &quot;/api/login&quot; ,//url data: datas, contentType: &#x27;application/json;charset=utf-8&#x27;, success: function (result) &#123; alert(result) console.log(result);//打印服务端返回的数据(调试用) if (result.resultCode == 200) &#123; alert(&quot;SUCCESS&quot;); &#125; &#125;, error : function() &#123; alert(&quot;异常！&quot;); &#125; &#125;); 报错400，请求头 因缺思厅，Content-Type变成了json,而请求体变成了拼接形式，又发现报的是400错误，说明我们请求无效，这个无效通常有两种原因： 前端提交数据的字段名称或者是字段类型和后台的实体类不一致，导致无法封装； 前端提交的到后台的数据应该是json字符串类型，而前端没有将对象转化为字符串类型； 很明显，后端是按照ContentType来解析的，且RequenstBody是可以解析json类型的，那么问题就只能是出现在了第二种。可以发现，前一次和这一次我们传给data的都是一个jacascript对象，而不是一个json字符串，所以我们将js对象转成json字符串再试试。 data 为json字符串，ContentType为json 123456789101112131415161718$.ajax(&#123; //几个参数需要注意一下 type: &quot;POST&quot;,//方法类型 dataType: &quot;text&quot;,//预期服务器返回的数据类型 contentType: &#x27;application/json;charset=utf-8&#x27;, url: &quot;/api/login&quot; ,//url data: JSON.stringify(datas), success: function (result) &#123; alert(result) console.log(result);//打印服务端返回的数据(调试用) if (result.resultCode == 200) &#123; alert(&quot;SUCCESS&quot;); &#125; &#125;, error : function() &#123; alert(&quot;异常！&quot;); &#125; &#125;); 返回200，访问成功 注意：此时还是要写Content Type的，不然就会415. 对于表单提交来说，当然也不是非用json传值不可，只是我觉得它比较方便，在这里也是可以直接将表单数据序列化然后传给后端的。 我们将前端改成这样： 1234567891011121314151617$.ajax(&#123; //几个参数需要注意一下 type: &quot;POST&quot;,//方法类型 dataType: &quot;text&quot;,//预期服务器返回的数据类型 url: &quot;/api/login&quot; ,//url data: $(&quot;form&quot;).serialize(), success: function (result) &#123; alert(result) console.log(result);//打印服务端返回的数据(调试用) if (result.resultCode == 200) &#123; alert(&quot;SUCCESS&quot;); &#125; &#125;, error : function() &#123; alert(&quot;异常！&quot;); &#125; &#125;); 后端改成这样： 123456public @ResponseBody String login(String userName,String passWord)&#123; System.out.println(userName+&quot;================&quot;+passWord); Administrator adm = new Administrator(); return &quot;ddddddddddddddd&quot; ; &#125; 然后就可以快乐的接收数据啦 可以看出，因为数据格式是默认的这种模式，所以不能用RequestBody解析，只能这样挨个接收，很麻烦，所以这也是为啥我想用json的原因。 下面来分析一下@RequestBody到底干了啥 RequestBody讲到这里，大概能遇到的问题差不多都讲道理，然而困扰我最久的，以上都不是，而是： 编译文件没有即使更新！我当时内心真是。。。","categories":[{"name":"后端","slug":"后端","permalink":"http://example.com/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"RequestBody","slug":"RequestBody","permalink":"http://example.com/tags/RequestBody/"}]},{"title":"Java中的fail fast","slug":"Java中的fail-fast","date":"2019-09-29T11:32:50.000Z","updated":"2019-09-29T11:32:50.000Z","comments":true,"path":"2019/09/29/Java中的fail-fast/","link":"","permalink":"http://example.com/2019/09/29/Java%E4%B8%AD%E7%9A%84fail-fast/","excerpt":"","text":"不知道到大家在操作Java集合类的时候有没有遇到过ConcurrentModificationException异常，反正我是遇到过，今天就来聊一下这个异常的缘起缘灭。 fail fast上述异常都是由这个叫做fail fast的机制导致的，fail fast是Java集合类的一种异常检测机制，当多个线程并发修改一个集合类的结构时，就有可能触发上述异常。我们以ArrayList为例来探究一下。 ArrayList中有一个成员变量叫做modCount，jdk8文档里面是这么介绍它的： The number of times this list has been structurally modified. Structural modifications are those that change the size of the list, or otherwise perturb it in such a fashion that iterations in progress may yield incorrect results. This field is used by the iterator and list iterator implementation returned by the iterator and listIterator methods. If the value of this field changes unexpectedly, the iterator (or list iterator) will throw a ConcurrentModificationException in response to the next, remove, previous, set or add operations. This provides fail-fast behavior, rather than non-deterministic behavior in the face of concurrent modification during iteration. 大概意思就是说：它是用来记录这个list被结构性修改的次数，所谓结构性修改指的是那些让它的大小发生改变的操作。并且，这个字段是被iterator使用的。 iterator我们再来看下iterator. 我们在集合类中一般是这样使用集合类的： 可以发现，它这里有两种方法，一种是iterator,还有一种是listIterator，有iterator方法很好理解，是因为ArrayList实现了Iterable接口，而iterator方法就是这个接口里的方法 Iterable接口 这三个方法定义如下： 可以看到，两个listIterator()方法返回的是一个ListItr对象，iterator方法返回的是一个Itr对象。我们来看下这两个对象有什么区别： Itr对象 ListItr对象 看来这两个内部类在AbstractList中就有了，只不过在这里进行了优化。下面这张类图就很能说说明问题了： 可以看出，ListItr就相当于是专门给list做的一个iterator,提供了一些下标访问的方法，但是平时用的还是比较少。 好，看完了iterator,我们来正式看下ConcurrentModificationException是怎么肥四 ConcurrentModificationExceptionfail fast出现在哪里的，根据上述问的描述，出现在发生结构性修改的地方，好，我们看一下add(),remove()的代码： 可以看到，发生结构性修改的地方，都会有modount++的操作。可是这里也没有看到抛出异常的代码呀。别急，其实都藏在Iterator里面，这里以内部类Itr为例： 请注意图中我圈出来的地方，这个内部类有个字段叫做expectedModCount，顾名思义就是期望被修改的次数，它被赋值成modCount，然后，对于这个内部类里面的每一个方法，都包含了一个叫做checkForComodification()的方法，这个方法做了什么呢？ 可以看到，它做的事情就是比较modCount和expectModCount是否相等，不等的话就抛出这个异常。在Itr类里面，只有一个地方修改了expectedModCount类： 那么什么时候他俩才会不等呢？ 这个内部类里面对expectedModCount初始化的值就是modCount的值，如果说要不等，那么可能有这么两种情况： 修改了expectedModCount，没有修改modCount 修改了modCouont，没有修改expectedModCount 其实看到这里，我们的疑惑大概也就解开了，在Itr类里面，对expectedModCount的修改只有上面那一处，而且还是将modCount赋值给他，这意味着，要发生这个异常，只能是我们在别处（Iterator以外的地方）对list进行了结构性修改，这时候只改了modCount，然后又使用Itr进行遍历操作，这时候这两个值就不相等了，这里推荐阅读H大的这篇文章，讲的很清楚：为什么阿里巴巴禁止在 foreach 循环里进行元素的 remove/add 操作 当然了，上述只是发生这个异常的一种原因啦，其实查看源代码你会发现其他地方也有这个异常，比如你使用多线程进行遍历或者修改的时候，因为数组越界也有可能触发这个异常。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"fail fast","slug":"fail-fast","permalink":"http://example.com/tags/fail-fast/"}]},{"title":"Nginx教程","slug":"Nginx教程","date":"2019-09-27T12:10:02.000Z","updated":"2019-09-27T12:10:02.000Z","comments":true,"path":"2019/09/27/Nginx教程/","link":"","permalink":"http://example.com/2019/09/27/Nginx%E6%95%99%E7%A8%8B/","excerpt":"","text":"前提需要： 编译器及相关工具：gcc编译器，make工具 由于命令apt-get install gcc gcc-c++报错Couldn&#39;t find any package by regex &#39;gcc-c+, 所以我们可以直接装apt-get -y install build-essential 模块依赖性： pcre库（正则表达式匹配的库），zlib库（压缩用的），openssl库（安全套接字库） 这些都安装在/usr/lcal/src中 这里我使用wget命令安装。以pcre为例： 123456wget ftp://ftp.pcre.org/pub/pcre/pcre2-10.33.tar.gztar -zxvf pcre2-10.33.tar.gzcd pcre2-10.33./Configuremakemake install 同样的方法安装 zlib,openssl 安装nginx: 12345wget http://nginx.org/download/nginx-1.16.1.tar.gztar -xzf nginx-1.16.1.tar.gz./configure --with-pcre=../pcre2-10.33makemake install 因为这里的安装需要上面的一些依赖库，我这里只加上pcre就可以了，具体情况可能和版本有关系，需要注意。 12345apt install nginx-coreapt install nginx-extrasapt install nginx-fullapt install nginx-light 装好的目录长这样： 1234CHANGES LICENSE README conf contrib man srcCHANGES.ru Makefile auto configure html objs 错误集锦： 1src/core/ngx_regex.h:15:10: fatal error: pcre.h: No such file or directory pcre2换成pcre","categories":[{"name":"教程","slug":"教程","permalink":"http://example.com/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/tags/Nginx/"}]},{"title":"Java中的类加载","slug":"Java中的类加载","date":"2019-09-24T11:10:35.000Z","updated":"2019-09-24T11:10:35.000Z","comments":true,"path":"2019/09/24/Java中的类加载/","link":"","permalink":"http://example.com/2019/09/24/Java%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD/","excerpt":"","text":"本文主要讨论两个问题：何时类加载？如何类加载？ 何为类加载类加载时机类加载的过程序：java文件被编译成.class文件放在磁盘中 加载阶段： 根据类的全限定名将字节码加载到内存，加载到内存哪里呢？方法区！ 可以认为，.class文件是类的静态结构，而加载阶段就是把这种静态结构编程动态的运行时结构 根据这个字节码生成一个java.lang.Class对象 我们讲过，万物皆可为对象，所以我们口口声声所讲的类也是对象 这一阶段有许多类加载器的作用： 启动类加载器（Bootstrap ClassLoader）: 加载&lt;JAVA_HOME&gt;\\lib中的类库到虚拟机 扩展类加载器（Extension ClassLoader）:负责加载&lt;JAVA_HOME&gt;\\lib\\ext中的类库 应用程序类加载器（Application ClassLoader）：负责加载用户类库上所指定的类库。 判断两个类相等，不仅要它们的全限定名相同，而且要加载它们的类加载器也相同， 双亲委派模型： ​ 这是一种层次结构，或者说是树状结构，其目的，是让越基础的类被越基础的类加器加载。举个例子，对于java.lang.Object类，它存在于rt.jar中，它是万类之祖，所以无论出现在程序中的哪里，它应该都是同一个Object类，使用双亲外派模型就可以很好的实现这个效果：无论我们使用哪个类加载器加载它，最终都会传递给启动类加载器加载，从而保证了Object类的唯一性。 验证阶段：​ 主要从安全性的角度考虑，验证class文件中的字节流是否安全，是否合法。 准备阶段：​ 为类变量分配空间，并设置初始值 这个阶段只给类变量分配，实例变量还在后头。 注意是设置初始值，不是赋值，初始值都是默认为0 类变量放在哪？ 方法区！ 解析阶段：​ 将常量池内的符号引用变为直接引用，关于常量池，符号引用，可以参考这篇文章。符号引用主要有： 类和接口的全限定名（这个常量在类索引或者父类索引中就会用到） 字段的名称和描述符 （这个在字段表集合中会被用到） 方法的名称和描述符（这个在方法表集合中会被用到） 所以说，解析阶段就是将上述三种符号引用解析成直接引用。 类或者接口解析： ​ 主要需要判断当前指向类或者接口的引用是不是数组，如果不是数组，那就直接加载对应的类或者接口； 如果是数组，且数组元素也是对象，则需要先加载元素，最后生成数组对象 字段解析： ​ 首先根据字段表中的信息找到其所在类或者接口，然后一直从当前类向上回溯，直到找到对应字段，否则返回NoSuchFieldError 类或者接口方法解析： ​ 首先根据字段表中的信息找到其所在类或者接口，如果当前是类方法，但找到的是接口，出错，如果当前是接口方法，找到的是个类，也出错，IncompatibleClassChangeError，（为什么这样的，因为常量池中对类和方法使用的是一个表结构定义的，所以有时候可能会有歧义，需要这样判断） 上述条件满足后，从当前类或者接口一直回溯向上找，直到找到对应方法 初始化阶段：​ 类加载的最后一个阶段。这一阶段，JVM才真正开始执行我们写的java代码。换个角度讲，这个阶段，jvm执行类构造器&lt;clinit&gt;()方法。 &lt;clinit&gt;()类构造器方法，&lt;init&gt;()对象构造器方法, 所以，&lt;clinit&gt;()用来初始化类变量，包括被static修饰的变量和包含在static语句块中的变量，而&lt;init&gt;()方法修饰非静态变量。 关于&lt;clinit&gt;()的执行规则 &lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句中可以赋值，但是不能访问。 &lt;clinit&gt;()方法与实例构造器&lt;init&gt;()方法（类的构造函数）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的&lt;clinit&gt;()方法执行之前，父类的&lt;clinit&gt;()方法已经执行完毕。因此，在虚拟机中第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。也就意味着父类中定义的静态语句块/静态变量的初始化要优先于子类的静态语句块/静态变量的初始化执行 &lt;clinit&gt;()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对类变量的赋值操作，那么编译器可以不为这个类生成&lt;clinit&gt;()方法。 接口中不能使用静态语句块，但仍然有类变量（final static）初始化的赋值操作，因此接口与类一样会生成&lt;clinit&gt;()方法。但是接口与类不同的是：执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法，只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的&lt;clinit&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕，但如果执行&lt;clinit&gt;()方法的那条线程推出后，其他线程唤醒之后不会再次进入/执行&lt;clinit&gt;()，因为在同一个类加载器下，一个类型只会被初始化一次（单例模式种就有利用这种类加载机制去实现的）。如果在一个类的&lt;clinit&gt;()方法中有耗时很长的操作，那就可能造成多个线程阻塞，在实际应用中这种阻塞往往是很隐蔽的。 从上述规则我们可以得到以下结论： ​ 1. 静态变量确实是先于实例变量被创建的（这点很重要！后面讲到的单例模式的实现就会用到这一点），类变量在类加载的时候就被赋值了。而实例变量要等到new的时候。 参考： 《深入理解java虚拟机》","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"类加载","slug":"类加载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"}]},{"title":"Java中的volatile关键字","slug":"Java中的volatile关键字","date":"2019-09-17T12:55:18.000Z","updated":"2019-09-17T12:55:18.000Z","comments":true,"path":"2019/09/17/Java中的volatile关键字/","link":"","permalink":"http://example.com/2019/09/17/Java%E4%B8%AD%E7%9A%84volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"本文需要了解：Java内存模型 缓存一致性问题为了提高CPU从内存中读写的速度，在CPU和和内存中间添加了缓存，有一级缓存，二级缓存，甚至三级缓存，从一级到三级，容量变大，速度变低。对于多个CPU场景，一般是每个CPU都有自己的一级和二级缓存而公用三级缓存。 在多CPU多线程的读写场景下，多个线程有可能会访问同一块内存区域，以写操作为例，多个线程都会把内存中的值读到自己的CPU中，然后修改，然后暂时放到自己的缓存中，这样就导致每个线程保的缓存中对同一变量可能有不同值的现象，即缓存一致性问题。 缓存一致性协议为了解决缓存一致性问题，通常有两种方法： 在总线加LOCK锁 缓存一致性协议 在总线加锁是一种阻塞的方式，显然是不高效的。 缓存一致性协议（Cache Coherence Protocol），最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。 MESI的核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 volatile关键字内存语义 可见性 有序性 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 volatile是不能保证原子性的，在指令层面，原子性是通过monitorenter和monitorexit两个指令实现的，而volatile的指令层面只有lock指令. 在以下两个场景中可以使用volatile来代替synchronized： 1、运算结果并不依赖变量的当前值，或者能够确保只有单一的线程会修改变量的值。 2、变量不需要与其他状态变量共同参与不变约束。 比如说，作为线程退出的标记量，或者DCL的单例模式中的使用。 既生synchronized，何生volatile说到底，synchronized是通过加锁来实现原子性、可见性和有序性的。既然是锁，肯定是有开销的，虽然说自1.6开始又给synchronized添加了轻量级锁，偏向锁，但性能损耗还是有的。而且，加锁其实是一个阻塞的过程。 相比之下，关于二者的性能对比，由于虚拟机对锁实行的许多消除和优化，使得我们很难量化这两者之间的性能差距，但是我们可以确定的一个基本原则是：volatile变量的读操作的性能消耗与普通变量几乎无差别，但是写操作由于需要插入内存屏障所以会慢一些，即便如此，volatile在大多数场景下也比锁的开销要低。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"http://example.com/tags/volatile/"}]},{"title":"Java中的ReentrantLock","slug":"Java中的ReentrantLock","date":"2019-09-17T06:56:35.000Z","updated":"2019-09-17T06:56:35.000Z","comments":true,"path":"2019/09/17/Java中的ReentrantLock/","link":"","permalink":"http://example.com/2019/09/17/Java%E4%B8%AD%E7%9A%84ReentrantLock/","excerpt":"","text":"ReentrantLock, 从名字来看，可重入锁，今天来看下它的具体实现。 特性：排他锁，内部实现了公平锁和非公平锁。 它的继承关系如下： 以及还有三个内部类：Sync, NonfairSync , FairSync.其中后两个都继承自Sync，而Sync又继承自AQS 可以看出，ReentryLock是在自己内部实现了公平锁和非公平锁的。 可以看到，ReentryLock继承的Lock接口实现了lock,tryLock, unLock等方法, 这也是本文讨论的重点。 先来从整体上把握一下ReentrantLock, ReentrantLock之所以能有锁的功能，是因为它聚合了AQS类（当然这也是AQS类设计的初衷，AQS通过模板方式模式实现，设计者希望我们自己设计的状态同步组件重写具体的细节类，然后将这个状态同步组件聚合到我们的锁里面），ReentrantLock也正是这么做的。 ReentrantLock的设计逻辑是这样的： 在AQS中，有模板方法和需要重写的细节方法。模板方法负责搭建获取锁和释放锁的框架，细节方法延迟到子类中去实现。 上图AQS类中，蓝色方法为模板方法，绿色方法为可能需要覆盖的方法，即在蓝色方法中调用了绿色方法。Sync继承自AQS, 而NonfairSync和FairSync继承了Sync,相当于最终要在公平锁和非公平锁中实现细节方法。可以看到，共享式的获取锁和释放锁是没有被实现的，所以说，ReentrantLock是独占锁。 我们来看下Sync的定义。 这里Sync继承自AQS, 用来实现状态同步。 我们看下NonfairSync的实现 它实现了父类的lock方法，首先通过CAS设置线程持有锁的状态，如果修改成功，则锁属于当前线程，否则，调用acquire()方法. acquire()方法在AQS类中实现， 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 如果使用tryAcquire()获取锁失败，则把这个线程加入等待队列中。（tryAcquire()又是在NonFairSync中实现的，有点绕，它的实现又调用了父类Sync中的nonfairTryAcquire()方法） 公平锁FairSync 可以看到，相比于非公平锁的lock方法，公平锁的lock方法一开始执行就是排队，即acquire()方法，而非公平锁的lock方法上来二话不说就是先插队，即通过CAS改变自身持有该锁的状态 对于tryAcquire()方法，公平锁的判断条件里多了一个自己是否在队列首的判断。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Lock","slug":"Lock","permalink":"http://example.com/tags/Lock/"}]},{"title":"剑指offer题解","slug":"剑指offer题解","date":"2019-09-15T09:25:15.000Z","updated":"2019-09-15T09:25:15.000Z","comments":true,"path":"2019/09/15/剑指offer题解/","link":"","permalink":"http://example.com/2019/09/15/%E5%89%91%E6%8C%87offer%E9%A2%98%E8%A7%A3/","excerpt":"","text":"重建二叉树前序遍历用来确定根节点，中序遍历用来确定左右子树以及大小 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;public class ReconsBinTree &#123; public static void main(String[] args) &#123; int[] pre=&#123;1,2,4,7,3,5,6,8&#125;; int[] in = &#123;4,7,2,1,5,3,6,8&#125;; TreeNode root = reConstructBinaryTree(pre,in);// System.out.println(root); lastOrder(root); &#125; //前序遍历提供跟节点，中序遍历提供切分以及左右子树的大小 public static TreeNode reConstructBinaryTree(int[] pre, int[] in) &#123;// TreeNode root = new TreeNode(pre[0]); TreeNode root = reconstruct(pre[0],pre,0,pre.length,in,0,in.length); return root; &#125; public static TreeNode reconstruct(int rootVal,int[] pre,int preStart, int preEnd, int[] in, int inStart, int inEnd)&#123; TreeNode root = new TreeNode(rootVal); int rootIdxAtPre = getIndex(pre,preStart,preEnd,root.val) ; int rootIdxAtIn = getIndex(in,inStart,inEnd,root.val); if(rootIdxAtIn&gt;0)&#123; //说明有左孩子，索引以左就是左孩子 int lidx = rootIdxAtPre+1;// TreeNode left = new TreeNode(pre[preStart+lidx]);// root.left=left; root.left = reconstruct(pre[preStart+lidx],pre,preStart+1,preStart+1+rootIdxAtIn,in,inStart,inStart+rootIdxAtIn); &#125; else root.left=null; if(inStart+rootIdxAtIn&lt;inEnd-1)&#123; int ridx = rootIdxAtIn+1;// TreeNode right = new TreeNode(pre[preStart+ridx]);// root.right=right; root.right = reconstruct(pre[preStart+ridx], pre,preStart+rootIdxAtIn+1,preEnd,in,inStart+rootIdxAtIn+1,inEnd); &#125; else root.right=null; return root; &#125; //返回相对位置索引 public static int getIndex(int[] arr, int start, int end, int val)&#123; for(int i=start; i&lt;end; i++)&#123; if(arr[i]==val) return i-start; &#125; return -1; &#125; //后续遍历测试 public static void lastOrder(TreeNode root)&#123; if(root!=null) &#123; if (root.left != null) lastOrder(root.left); if (root.right != null) lastOrder(root.right); &#125; System.out.println(root.val); &#125;&#125; 用两个栈实现队列123456789101112131415161718192021222324252627282930313233343536373839import java.util.Stack;/** * 思路：从stack1 push,从stack2 pop. */public class Stack2Q &#123; static Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); static Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); public static void push(int node) &#123; stack1.push(node) ; &#125; public static int pop() &#123; int node ; //stack2中有的话直接pop if(!stack2.isEmpty())&#123; node = stack2.pop(); &#125; else &#123;//没有的话先从stack1转移到stack2 while (!stack1.isEmpty())&#123; int tnode = stack1.pop(); stack2.push(tnode); &#125; node = stack2.pop(); &#125; return node ; &#125; public static void main(String[] args) &#123; push(1); push(2); push(3); push(4); System.out.println(pop()); System.out.println(pop()); &#125;&#125; 旋转数组的最小数字1234567891011121314151617181920212223242526272829303132333435363738/** * 利用旋转数组的特性，使用二分查找： * 如果中间数大于array[start]且大于array[end],区后半段 * 如果中间数大于array[start]且小于array[end]，取前半段 * 如果中间数小于array[start]，取前半段 * * 需要注意下标的取法 */public class MinNumInRotateArray &#123; public static int minNumberInRotateArray(int[] array) &#123; int min = binSearch(array,0,array.length-1); return min; &#125; static int binSearch(int[] arr, int start, int end)&#123; int res; if(end-start&lt;=0)&#123; res = arr[start]; return res; &#125; int mid = (start+end)/2; if(arr[mid]&gt;=arr[start] &amp;&amp; arr[mid] &gt;=arr[end] )&#123; res = binSearch(arr,mid+1,end);//后面 &#125; else &#123; res = binSearch(arr,start,mid);//前面 &#125; return res; &#125; public static void main(String[] args) &#123; int[] array=&#123;3,4,5,1,2&#125;; System.out.println(minNumberInRotateArray(array)); &#125;&#125; 跳台阶一道典型的动态规划问题，对于跳上第n个台阶，只有两种跳法： 从第n-1个台阶跳一步上去 从第n-2个台阶跳两步上去 所以我们有 $$ f(n)=\\left{\\begin{aligned}&amp;1 &amp; n=1 \\&amp;2 &amp; n=2 \\&amp;f(n-1)+f(n-2) &amp; n \\ge 3\\end{aligned}\\right.$$ 其实就是个Fibonaci数列，可以用递归求解，但是太麻烦，我们用DP来求解 数组版12345678910111213141516171819202122232425public class JumpFloor &#123;//public static int JumpFloor(int target) &#123; if(target==1)&#123; return 1; &#125; if(target==2)&#123; return 2; &#125; int[] dp = new int[target+1]; dp[1]=1; dp[2]=2; for (int i=3; i&lt;=target; i++)&#123; dp[i]=dp[i-1]+dp[i-2]; &#125; return dp[target];&#125; public static void main(String[] args) &#123; System.out.println(JumpFloor(3)); System.out.println(JumpFloor(4)); &#125;&#125; 精简版12345678910111213141516171819202122public class JumpFloor &#123; public static int JumpFloor(int target) &#123; if(target==1)&#123; return 1; &#125; if(target==2)&#123; return 2; &#125; int pre=1,cur=2,res=0; for(int i=3; i&lt;=target; i++)&#123; res = pre+cur; pre=cur; cur=res; &#125; return res; &#125; public static void main(String[] args) &#123; System.out.println(JumpFloor(3)); System.out.println(JumpFloor(4)); &#125;&#125; 变态跳台阶题目描述: 一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 解析： 同样的，先写出递归方程，然后用递归或者DP来求解。 相比于上面那一道普通跳台阶，这里只不过是能跳的台阶多了一些。 矩形覆盖题目描述我们可以用21的小矩形横着或者竖着去覆盖更大的矩形。请问用n个21的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 解析同样的，先写状态转移方程： $$ f(n)=\\left{\\begin{aligned}&amp;1 &amp; n=1 \\&amp;2 &amp; n=2 \\&amp;f(n-1)+f(n-2) &amp; n \\ge 3\\end{aligned}\\right.$$ 依然是个斐波那契数列问题 可以用递归和DP解决 其实讲道理，我觉得这道题也可以用排列组合来求解的 代码1234567public int RectCover(int target) &#123; if (target == 1) return 1; if (target == 2) return 2; return RectCover(target - 1) + RectCover(target - 2); &#125; DP: 123456789101112131415161718public int RectCover(int target) &#123; int sum,p1,p2 ; if(target &lt;=0) return 0; if (target == 1) return 1; if (target == 2) return 2; p1=1; p2=2; sum=0; for (int i = 3; i&lt;=target; i++)&#123; sum = p1 +p2 ; p1 = p2 ; p2 = sum ; &#125; return sum; &#125; 二进制中1的个数题目描述 输入一个整数n，输出该数二进制表示中1的个数。其中负数用补码表示。 解析方法一： 无符号右移输入的数字，然后和1逻辑与 方法二：保持输入不动，每次右移数字1然后逻辑与 方法三：将n和n-1逻辑与，消除一个n最右边的数字1 代码方法一： 123456789101112131415public class NumberOf1 &#123; public int NumberOf1(int n) &#123; int count = 0; while (n!=0)&#123; count += (n&amp;1) ; n = n&gt;&gt;&gt;1; &#125; return count; &#125; public static void main(String[] args) &#123; System.out.println(new NumberOf1().NumberOf1(0x80000000)); &#125;&#125; 数值的整数次方题目描述给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 保证base和exponent不同时为0 解析 方法一：for循环暴力输出，需要考虑到指数为负数等边界情况 方法二：使用递归将指数拆解进行计算。 调整数组顺序使奇数位于偶数前面题目描述输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。 解析这个问题使用冒泡排序的思想也可以解决，相邻元素比较并交换，问题在于这样做的话无谓的比较和交换比较多。比如说有一长串都是奇数或者偶数，这种情况我们就可以跳过了，其实是有点类似与KMP算法的。 所以我们需要两个指针，一个指向当前出现的第一个偶数，一个指向第一个偶数出现后的第一个奇数，然后奇数放在偶数位，偶数们依次后移。 代码1234567891011121314151617181920212223242526272829303132333435public void reOrderArray(int [] array) &#123; int feven=0; //第一个偶数的位置 int fodd=1; // 第一个偶数后第一个奇数的位置 int i=0; if(array==null || array.length==1) return ; while(fodd&lt;=array.length)&#123; for(; feven&lt;array.length; feven++)&#123; //寻找第一个偶数的位置 if(isEven(array[feven]))&#123; break; &#125; &#125; for(fodd=feven+1; fodd&lt;array.length; fodd++)&#123;//找到偶数后第一个奇数的位置 if(!isEven(array[fodd]))&#123; break; &#125; &#125; if(fodd&gt;=array.length) break; int t = array[fodd] ; for(int j = fodd-1; j&gt;=feven; j--)&#123; array[j+1] = array[j]; &#125; array[feven] = t ; &#125; &#125; public boolean isEven(int e)&#123; return e%2==0 ; &#125; 或者 12345678910111213public class Solution &#123; public void reOrderArray(int [] array) &#123; for(int i= 0;i&lt;array.length-1;i++)&#123; for(int j=0;j&lt;array.length-1-i;j++)&#123; if(array[j]%2==0&amp;&amp;array[j+1]%2==1)&#123; int t = array[j]; array[j]=array[j+1]; array[j+1]=t; &#125; &#125; &#125; &#125;&#125; 很类似于冒泡排序，每一轮冒泡保证至少有一个元素归位。 其实就是个冒泡排序，只不过我们常见的冒泡排序里面比较的是元素大小，这里比较的是元素奇偶，还有很重要的一点就是冒泡排序是稳定的，对应到题目中就是保证奇数和奇数，偶数和偶数之间的相对位置不变。 这里相当于是一个通用性的冒泡排序，至于按照什么条件进行相邻元素比较是可插拔的，实在是妙啊。 所以理论上讲，这道题只要是稳定的排序算法应该是都可以用的。 那哪些排序稳定哪些排序不稳定呢？ 一言以蔽之：涉及到非相邻交换的排序都是不稳定的，比如选择排序，比如快速排序，希尔排序，比如堆排序。 链表中倒数第k个结点题目描述输入一个链表，输出该链表中倒数第k个结点。 分析用标尺法就可以解决。 代码12345678910111213141516171819202122232425262728293031323334/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode FindKthToTail(ListNode head,int k) &#123; ListNode cur = head ; if(head == null)&#123; return null ; &#125; if(k==0)&#123; return null; &#125; ListNode post = cur.next ; int i = 1 ; while(post != null &amp;&amp; i&lt;k)&#123; post = post.next ; i++; &#125; if(i&lt;k)&#123; return null ; &#125; while(post !=null)&#123; cur = cur.next; post = post.next ; &#125; return cur ; &#125;&#125; 树的子结构题目描述输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） 问题分析学会把问题分解。对于这个问题，分成两个子问题：1. 遍历A树，看当前节点和B树的根节点是否相等，如果相等，继续看A当前节点的左右子树和B的左右子树结构是否一样，注意是结构是否一样而不是判断左右子树是否相等，因为题目问的是子结构，而不是子树。 二叉树镜像题目描述操作给定的二叉树，将其变换为源二叉树的镜像。 输入描述:123456789101112二叉树的镜像定义：源二叉树 8 / \\ 6 10 / \\ / \\ 5 7 9 11 镜像二叉树 8 / \\ 10 6 / \\ / \\ 11 9 7 5 问题分析二叉树是一种递归结构，关于它的问题一般都是有框架可循的，无论是这道翻转二叉树还是上面的子结构。其框架大概是： 当前节点做好当前节点的事，其他的交给递归。 那么这道题也是一样，对于当前节点，交换一下左右指针就行，其他的交给递归。 代码1234567891011121314151617181920212223242526 /**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public void Mirror(TreeNode root) &#123; if(root==null) return ; if(root!=null)&#123; TreeNode temp = root.left ; root.left= root.right; root.right = temp ; &#125; Mirror(root.left) ; Mirror(root.right) ; &#125;&#125; 顺时针打印矩阵题目描述输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 问题分析整个过程分为四步，从左到右，从上到下，从右到左，从下到上。 顺序是不变的，变的是上下左右的边界，比如第一次从左到右遍历完后，那么上界就增加了一，从上到下遍历完后，后界就缩小了一，以此类推。 代码12345678910111213141516171819202122232425262728293031323334353637import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; printMatrix(int [][] matrix) &#123; ArrayList res = new ArrayList() ; int up = 0; int down = matrix.length-1 ; int left = 0 ; int right = matrix[0].length-1 ; while(true)&#123; for(int col=left; col&lt;=right; col++)&#123; res.add(matrix[up][col]) ; &#125; up++ ; if(up&gt;down) break ; for(int row=up; row&lt;=down; row++)&#123; res.add(matrix[row][right]); &#125; right--; if(right&lt;left) break ; for(int col=right; col&gt;=left; col--)&#123; res.add(matrix[down][col]); &#125; down-- ; if(down&lt;up) break ; for(int row=down; row&gt;=up; row--)&#123; res.add(matrix[row][left]) ; &#125; left++ ; if(left&gt;right) break ; &#125; return res; &#125;&#125; 字符串的排列 题解停更了很久，最近重新刷的时候感觉有些东西还是要总结，所以继续开始。 题目描述输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。 问题分析这道题说到底，还是个回溯的问题，回溯解法之前也写到过，最需要注意一个问题，就是回溯完之后记得回退！这点很重要，具体回退的地方就在我们递归函数结束的下一行，这其实就是labuladong老哥讲的框架！框架！框架！八皇后问题也是回溯，都是有框架的。说到这里，安利一波公众号 labuladong, 以及这篇讲回溯的文章 ,其中还涉及到了八皇后问题，非常棒！ 然后目前下面的解法并不是最优解，因为有重复字符，所以我们可以考虑先把字符放在set里再操作，这样就可以减少重复执行的次数了。 代码1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.ArrayList;import java.util.TreeSet;public class Solution &#123;// private ArrayList&lt;String&gt; res = new ArrayList(); TreeSet&lt;String&gt; res = new TreeSet(); private StringBuilder ele = new StringBuilder(); public ArrayList&lt;String&gt; Permutation(String str) &#123; StringBuilder sb = new StringBuilder(str); for(int i=0; i&lt;sb.length(); i++)&#123; traverse(sb,i); ele.deleteCharAt(ele.length()-1); &#125; return new ArrayList&lt;&gt;(res); &#125; public void traverse(StringBuilder sbd, int loc)&#123; char prefix = sbd.charAt(loc); StringBuilder sb = new StringBuilder(sbd).deleteCharAt(loc); if(sb.length()==0)&#123; ele.append(prefix); res.add(new String(ele)); // ele.deleteCharAt(ele.length()-1); return; &#125; ele.append(prefix); for(int i=0; i&lt;sb.length(); i++)&#123; traverse(sb,i); ele.deleteCharAt(ele.length()-1); &#125; &#125; public static void main(String[] args) &#123; ArrayList&lt;String&gt; res =new Solution().Permutation(&quot;aac&quot;); for (String str: res) &#123; System.out.println(str); &#125; &#125;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://example.com/tags/%E5%89%91%E6%8C%87offer/"}]},{"title":"Java中的synchronized关键字","slug":"Java中的synchronized关键字","date":"2019-09-13T08:51:50.000Z","updated":"2023-05-29T14:17:39.315Z","comments":true,"path":"2019/09/13/Java中的synchronized关键字/","link":"","permalink":"http://example.com/2019/09/13/Java%E4%B8%AD%E7%9A%84synchronized%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"本文主要从两个方面讲解synchronized关键字，第一个是用法，第二个是原理，即为什么synchronized关键字能够保持线程同步。 用法synchronized的修饰对象主要有以下两种： 修饰一个代码块。 synchronized(this|object) &#123;&#125;:获得对象级的锁。当多个线程访问同一对象内的同步代码块时，只能互斥访问 synchronized(类.class) &#123;&#125;:获得类级别的锁。当多个线程访问由这个类定义的所有对象的的同步方法时，只能互斥访问。 修饰一个方法。 修饰非静态方法。获得对象级的锁，当多个线程访问同一对象的同步方法时，只能互斥访问。 修饰静态方法。获得类级的锁，当多个线程访问由这个类定义的所有对象的的同步方法时，只能互斥访问。 修饰代码块获取对象锁 多个线程访问同一对象的同步代码块 12345678910111213141516171819202122232425262728293031class SynTest implements Runnable &#123; @Override public void run() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(Thread.currentThread().getName() + &quot; &quot; + i); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; //定义对象 SynTest synTest = new SynTest(); //两个thread传入的是同一对象 Thread thread1 = new Thread(synTest); Thread thread2 = new Thread(synTest); thread1.start(); thread2.start(); &#125;&#125; 输出： 12345678910Thread-0 0Thread-0 1Thread-0 2Thread-0 3Thread-0 4Thread-1 0Thread-1 1Thread-1 2Thread-1 3Thread-1 4 可以看到对于同一对象的同步代码块，同一时间只能有一个线程去访问。 多个线程访问不同对象的同步代码块 我们稍微修改以下上述代码，分别定义两个SyntTest对象 1234567891011121314151617public class Test &#123; public static void main(String[] args) &#123; //定义两个对象 SynTest synTest1 = new SynTest(); SynTest synTest2 = new SynTest(); //两个thread传入的是不同对象 Thread thread1 = new Thread(synTest1); Thread thread2 = new Thread(synTest2); thread1.start(); thread2.start(); &#125;&#125; 输出： 12345678910Thread-0 0Thread-1 0Thread-1 1Thread-0 1Thread-0 2Thread-1 2Thread-0 3Thread-1 3Thread-1 4Thread-0 4 可以看到，我们获取到的是对象级的锁，而两个线程访问的是两个对象里不同的同步方法，所以不存在同步问题。 多个线程访问同一对象的同步代码块和非同步代码块 123456789101112131415161718192021222324252627282930313233343536373839404142434445class SynTest implements Runnable &#123; void print1() &#123; synchronized (this) &#123; System.out.println(&quot;this is thread1&quot;); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; void print2() &#123; System.out.println(&quot;this is thread2&quot;); &#125; @Override public void run() &#123; if(Thread.currentThread().getName().equals(&quot;thread1&quot;))&#123; print1(); &#125;else &#123; print2(); &#125; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; SynTest synTest = new SynTest(); //两个thread传入的是同一对象 Thread thread1 = new Thread(synTest, &quot;thread1&quot;); Thread thread2 = new Thread(synTest, &quot;thread2&quot;); thread1.start(); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread2.start(); &#125;&#125; 我们让thread1在synchronized代码段中停留十秒钟，如果有阻塞，那么这段时间thread2应该是不会有输出的，得等到thread1输出完它才输出。而事实是： 12this is thread2this is thread1 说明不同线程执行同一对象的同步代码段和非同步代码段是互相不受干扰的。 需要注意的是，上面的代码中synchronized修饰的都是this，意味这访问同步代码段的线程持有了这个对象的锁，那么括号里的对象可以换成其他的Object吗，答案是可以的。严格来讲，对于代码块的使用场景是这样的：这接下来的一块代码里，可能会并发修改某个对象的问题，那么我们应该给这个对象加锁，也就是括号里应该写的是这个对象。但事实是，你可以随便指定一个对象包含的变量，都可以起到加锁的作用，比如： 1234567891011121314class Test implements Runnable&#123; private byte[] lock = new byte[0]; // 特殊的instance变量 public void method() &#123; synchronized(lock) &#123; // todo 同步代码块 &#125; &#125; public void run() &#123; &#125;&#125; 至于是为什么，我们在原理部分会讲到。 获取类锁 不同线程访问同一个类不同实例的同步代码块 12345678910111213141516171819202122232425262728293031class SynTest implements Runnable &#123; @Override public void run() &#123; synchronized (SynTest.class) &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(Thread.currentThread().getName() + &quot; &quot; + i); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; //定义对象 SynTest synTest1 = new SynTest(); SynTest synTest2 = new SynTest(); //两个thread传入的是不同对象 Thread thread1 = new Thread(synTest1); Thread thread2 = new Thread(synTest2); thread1.start(); thread2.start(); &#125;&#125; 输出： 12345678910Thread-0 0Thread-0 1Thread-0 2Thread-0 3Thread-0 4Thread-1 0Thread-1 1Thread-1 2Thread-1 3Thread-1 4 可以看到，虽然两个线程传入的是不同的对象，但是因为我们的同步代码块修饰的是一个类而不是一个对象，所以只要是这个类定义的对象，在被线程访问时都需要获取锁。 修饰方法修饰方法和修饰代码是差不多的，仍然分为获取对象锁和获取类锁，只不过粒度薛微大了点，这里就不赘述啦。 实现给出下面一段代码， 12345678910111213public class Test &#123; public synchronized void synMethod()&#123; System.out.println(&quot;this is a sync method&quot;); &#125; public void method2()&#123; synchronized (this)&#123; System.out.println(&quot;this is a sync block&quot;); &#125; &#125;&#125; 反编译后得到如下信息： 可以看到，对于synchronized修饰的方法，JVM使用ACC_SYNCHRONIZED标记符来实现同步。顺便一提，这个方法的标记符是作为符号引用放在常量池中的，参考这篇文章。 对于synchronized修饰的代码块，则是使用monitorenter和monitorexit两个指令来实现同步。 原理好，讲完了synchronized的用法之后，我们再来考虑一下，synchronized是如何保持线程同步的，上文中一直讲到的获取锁，又是个什么操作呢。 先说两个结论： synchronized基于monitor机制实现 任何对象均可作为锁 至于原因，我们接下来解释。 要说明这个问题，首先我们要理解Monitor机制和Java的对象模型。 Monitormonitor，被翻译成监视器，或者管程。它是一种同步机制，在不同的语言里，有不同的实现。但是无论哪种语言实现，它的核心元素有以下四种： 监视者对象 (Monitor Object): 负责定义公共的接口方法，这些公共的接口方法会在多线程的环境下被调用执行。 同步方法：这些方法是监视者对象所定义。为了防止竞争条件，无论是否同时有多个线程并发调用同步方法，还是监视者对象含有多个同步方法，在任一时间内只有监视者对象的一个同步方法能够被执行。 监视锁 (Monitor Lock): 每一个监视者对象都会拥有一把监视锁。 监视条件 (Monitor Condition): 同步方法使用监视锁和监视条件来决定方法是否需要阻塞或重新执行。 从上面synchronized关键字的用法中可以看到，其实synchronized往往需要指定一个对象与之关联，即使它修饰非静态方法，关联的其实是this。这里关联的对象就是监视器对象monitor object, 并且我们在这个对象中定义了很多管理和唤醒线程的方法，比如wait, notify. 你是不是发现了什么，是的没错，在java实现的monitor机制中（我们上面讲了不同的语言对moitor有不同的实现），monitor object其实就是我们的java.lang.Object类定义的对象。 继续讲，这个监视器对象拥有一把锁，所以对于下面这个代码 123synchronized(obj)&#123; do something&#125; 任何线程想要访问这段临界区，都要先获取obj对象的锁。 我们上面讲的这些，在jvm内部都有具体的实现，是基于一种叫做ObjectMonitor的模式实现的。我们来看下它的大概原理： 当一个线程需要获取 Object 的锁时，会被放入 EntrySet 中进行等待，如果该线程获取到了锁，成为当前锁的 owner。如果根据程序逻辑，一个已经获得了锁的线程缺少某些外部条件，而无法继续进行下去（例如生产者发现队列已满或者消费者发现队列为空），那么该线程可以通过调用 wait 方法将锁释放，进入 wait set 中阻塞进行等待，其它线程在这个时候有机会获得锁，去干其它的事情，从而使得之前不成立的外部条件成立，这样先前被阻塞的线程就可以重新进入 EntrySet 去竞争锁。这个外部条件在 monitor 机制中称为条件变量。 讲到这里也就大概解释了为什么我们上面说synchronized是基于monitor实现的了，要记住，monitor不是一个具体的东西，它是一种机制，或者说一种方法论，不同的语言有不同的实现，在java中，synchronized关键字就是monitor的具体实现。同时我们也可以看出，synchronized锁的不是别的，是对象，每个对象都只有一把锁，当被一个线程获取后，其他线程执行到这里也就只能等了。 那么怎么才算一个线程获取了锁呢，这些信息是存储在Java对象的对象头中的。 Java对象模型Java对象由三部分组成，对象头，实例数据，填充数据，如下图所示： 实例数据就是我们自己coding时写的那部分，填充数据主要是为了字节对齐而设置的，就像网络中数据报格式一样。而和synchronized相关的玄机，都藏在对象头里了。 对象头由两部构成：mark word和class meta data address,如果对象是数组类型，还会有一部分来描述数组长度。 长度 内容 说明 1 Word Mark Word 存储对象的hashcode,分代年龄和锁标记等信息 1 Word Class Metadata Address 存储指向对象类型数据的指针 1 Word Array length 数组长度 可以看到，和锁相关的信息的都在Mark Word中，这也是我们重点分析的对象。顺便一提，Class Metadata Address指针指向存储对象类型信息的位置，那对象类型信息放在哪里呢，熟悉JVM内存结构的朋友应该知道，是放在方法区的。 下面我们重点研究Mark Word. 上面我们说到，mark word里面存储了相关的锁信息，那具体的结构是怎样的呢。 下图描述了32位虚拟机上，对象在不同状态下mark word里面的情况： 其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的。 无锁 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁 是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 内存语义以下内容涉及到Java内存模型。 可见性可见性指的是一个线程对变量的修改能够立即被另一个线程看见。 为了保证可见性，对synchronized修饰的代码有这样一条规则：对一个变量解锁之前，必须先把此变量同步回主存中。这样解锁后，后续线程就可以访问到被修改后的值。 原子性synchronized对要访问的代码段加锁，访问结束再释放锁，在此期间只有一个线程能访问代码块，可以实现原子性。 有序性synchronized保证的有序性是多个线程之间的有序性，即被加锁的内容要按照顺序被多个线程执行。但是其内部的同步代码还是会发生重排序，只不过由于编译器和处理器都遵循as-if-serial语义，所以我们可以认为这些重排序在单线程内部可忽略。 参考探索 Java 同步机制 Java 中的 Monitor 机制 不可不说的Java“锁”事 既生synchronized，何生volatile","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"关键字","slug":"关键字","permalink":"http://example.com/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"}]},{"title":"Java中的锁","slug":"Java中的锁","date":"2019-09-13T02:08:56.000Z","updated":"2019-09-13T02:08:56.000Z","comments":true,"path":"2019/09/13/Java中的锁/","link":"","permalink":"http://example.com/2019/09/13/Java%E4%B8%AD%E7%9A%84%E9%94%81/","excerpt":"","text":"本文转自：不可不说的Java“锁”事 前言Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 Java中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录： 1. 乐观锁 VS 悲观锁乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。 先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 根据从上面的概念描述我们可以发现： 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例： 12345678910111213141516// ------------------------- 悲观锁的调用方式 -------------------------// synchronizedpublic synchronized void testMethod() &#123; // 操作同步资源&#125;// ReentrantLockprivate ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁public void modifyPublicResources() &#123; lock.lock(); // 操作同步资源 lock.unlock();&#125;// ------------------------- 乐观锁的调用方式 -------------------------private AtomicInteger atomicInteger = new AtomicInteger(); // 需要保证多个线程使用的是同一个AtomicIntegeratomicInteger.incrementAndGet(); //执行自增1 通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？我们通过介绍乐观锁的主要实现方式 “CAS” 的技术原理来为大家解惑。 CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。 CAS算法涉及到三个操作数： 需要读写的内存值 V。 进行比较的值 A。 要写入的新值 B。 当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。 之前提到java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义： 根据定义我们可以看出各属性的作用： unsafe： 获取并操作内存的数据。 valueOffset： 存储value在AtomicInteger中的偏移量。 value： 存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。 接下来，我们查看AtomicInteger的自增函数incrementAndGet()的源码时，发现自增函数底层调用的是unsafe.getAndAddInt()。但是由于JDK本身只有Unsafe.class，只通过class文件中的参数名，并不能很好的了解方法的作用，所以我们通过OpenJDK 8 来查看Unsafe的源码： 123456789101112131415161718192021222324// ------------------------- JDK 8 -------------------------// AtomicInteger 自增方法public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;// Unsafe.classpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;// ------------------------- OpenJDK 8 -------------------------// Unsafe.javapublic final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v;&#125; 根据OpenJDK 8的源码我们可以看出，getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。 后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。 CAS虽然很高效，但是它也存在三大问题，这里也简单说一下： ABA问题 。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。 JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作 。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。 Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 2. 自旋锁 VS 适应性自旋锁在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。 而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock，本文中仅做名词介绍，不做深入讲解，感兴趣的同学可以自行查阅相关资料。 3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。 首先为什么Synchronized能实现线程同步？ 在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。 Java对象头synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？ 我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 MonitorMonitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 锁状态 存储内容 存储内容 无锁 对象的hashCode、对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 无锁 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁 是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 4. 公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。 如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。 但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示： 接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。 根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 下面我们来看一下公平锁与非公平锁的加锁方法的源码: 通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。 再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。 综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。 5. 可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 12345678910public class Widget &#123; public synchronized void doSomething() &#123; System.out.println(&quot;方法1执行...&quot;); doOthers(); &#125; public synchronized void doOthers() &#123; System.out.println(&quot;方法2执行...&quot;); &#125;&#125; 在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。 如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。 而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。 还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。 但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。 之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。 首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。 当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。 释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。 6. 独享锁 VS 共享锁独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。 独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 下图为ReentrantReadWriteLock的部分源码： 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。 在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 了解了概念之后我们再来看代码，先看写锁的加锁源码： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 取到当前锁的个数 int w = exclusiveCount(c); // 取写锁的个数w if (c != 0) &#123; // 如果已经有线程持有了锁(c!=0) // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。 return false; setExclusiveOwnerThread(current); // 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者 return true;&#125; 这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。 如果c=0,w=0或者c&gt;0,w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。 因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。 接着是读锁的代码： 123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码： 我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。根据源码所示，当某一个线程调用lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"}]},{"title":"谈一谈Java中的集合类之总述","slug":"谈一谈Java中的集合类","date":"2019-09-05T06:40:08.000Z","updated":"2019-09-05T06:40:08.000Z","comments":true,"path":"2019/09/05/谈一谈Java中的集合类/","link":"","permalink":"http://example.com/2019/09/05/%E8%B0%88%E4%B8%80%E8%B0%88Java%E4%B8%AD%E7%9A%84%E9%9B%86%E5%90%88%E7%B1%BB/","excerpt":"","text":"本文涉及集合类知识以及面试常问知识点 OverView集合类分为List,Map,Set. 先上张图 Map包括HashMap, LinkedHashMap, HashTable, TreeMap 和 WeakHashMap, ConcurrentHashMap HashMap 不是线程安全，最多允许一条键为null的记录 LinkedHashMap 保存了记录的插入顺序 ConcurrentHashMap 线程安全 HashTable 线程安全，键和值都不能为空 TreeMap 有排序功能 List包括ArrayList, LinkedList, Vector 和 stack Set包括HashSet , TreeSet 常见问题 HashMap 和 ConcurrentHashMap比较 HashTable实现原理，为什么线程安全 TreeMap实现原理","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"集合类","slug":"集合类","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88%E7%B1%BB/"}]},{"title":"谈一谈Java常量池之class常量池","slug":"谈一谈Java常量池之class常量池","date":"2019-09-04T06:08:30.000Z","updated":"2019-09-04T06:08:30.000Z","comments":true,"path":"2019/09/04/谈一谈Java常量池之class常量池/","link":"","permalink":"http://example.com/2019/09/04/%E8%B0%88%E4%B8%80%E8%B0%88Java%E5%B8%B8%E9%87%8F%E6%B1%A0%E4%B9%8Bclass%E5%B8%B8%E9%87%8F%E6%B1%A0/","excerpt":"","text":"Java常量池分为字符串常量池，class常量池和运行时常量池。本文主要讲class常量池。 什么是class常量池顾名思义，class常量池就是class文件中对应的常量池，那什么是class文件呢，就是将java文件编译得到的字节码文件，jvm所处理的也正是这种字节码文件。而class常量池，指的就是这个字节码文件中对应的一部分内容。 class文件结构为了进一步了解class文件，我们准备了一小段代码： 12345public class Test &#123; public static void main(String[] args) &#123; String s = &quot;hello world&quot; ; &#125;&#125; 使用javac进行编译,在十六进制下查看，得到： 这就是我们编译得到的class文件。 前四个字节是魔数（magic number）,紧接着的四个字节是版本号，然后就是class常量池的入口了。 下图展示了完整的class文件格式： 类型 名称 数量 说明 u4 magic 1 魔数 u2 minor_version 1 次版本号 u2 major_version 1 主版本号 u2 constant_pool_count 1 常量池中常量数量 cp_info constant_pool constant_pool_count-1 常量池中的常量 u2 access_flag 1 访问标志，用于标识当前的类或者接口的访问信息，如是类还是接口，访问类型等 u2 this_class 1 类索引，确定这个类的全限定名，具体存放在常量池中，根据这个索引去查找 u2 super_class 1 父类索引，作用同上 u2 interfaces_count 1 当前类所实现的接口数量 u2 interfaces interfaces_count 接口索引集合，描述当前类所实现的接口，根据索引在常量池中查找 u2 fields_count 1 field_info fields fields_count 字段表集合，用于描述类或者接口中申明的变量 u2 methods_count 1 method_info methods methods_count 方法表集合，用于描述类或者接口中申明的方法 u2 attributes_count 1 attribute_info attributes attributes_count 可以看出class文件中只有两种数据类型：无符号数和表，对于每个表，开头总会先说它的数量，然后表中的每个字段都有自己的结构。 下面这个表描述了常量池中都有哪些表 类型 标志 描述 CONSTANT_utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info ５ 长整型字面量 CONSTANT_Double_info ６ 双精度浮点型字面量 CONSTANT_Class_info ７ 类或接口的符号引用 CONSTANT_String_info ８ 字符串类型字面量 CONSTANT_Fieldref_info ９ 字段的符号引用 CONSTANT_Methodref_info １０ 类中方法的符号引用 CONSTANT_InterfaceMethodref_info １１ 接口中方法的符号引用 CONSTANT_NameAndType_info １２ 字段或方法的符号引用 CONSTANT_MothodType_info １６ 标志方法类型 CONSTANT_MethodHandle_info １５ 表示方法句柄 CONSTANT_InvokeDynamic_info １８ 表示一个动态方法调用点 要注意的是每个表结构都是不同的，那么这样就有一个问题了，既然表结构都有不同，那么jvm自己又是怎么认识这些表项的呢。这里就有一点class文件设计的技巧了：虽然每个表都不同，但是我可以给每个表设置一个开始标志或者结束标志呀。class文件使用的是前一种，每个表项，都是以一个一字节的tag位作为开始的，如上表所示，每个tag代表了不同的表结构，然后根据tag去查找对应的表结构，按照对应的表结构来解析接下来的内容。 class常量池里有啥看完class文件结构，再来细看一下class常量池，从上面的表格可以看出，常量池也是一个表，开头先说它的数量，即里面有几个常量，然后才是常量池的内容。 常量池中每一项又是一个表，且不同的详，表结构不同 我们使用javap命令来简单明了的看下class常量池： 上图展示了class常量池中的内容，常量池中主要存放两种常量：字面量（Literal）和符号引用（Symbolic References）.字面量指的就是一些字符串啊数字啊之类的东西，而符号引用包括以下三类常量： 类和接口的全限定名（这个常量在类索引或者父类索引中就会用到） 字段的名称和描述符 （这个在字段表集合中会被用到） 方法的名称和描述符（这个在方法表集合中会被用到） class常量池有啥用可以这么理解，class常量池相当于是一个资源库，在JVM运行时，它会把需要的资源从class文件中加载进内存。而这些就是类加载的内容了，我们会在后面的文章中讲到。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"class文件","slug":"class文件","permalink":"http://example.com/tags/class%E6%96%87%E4%BB%B6/"}]},{"title":"Java中的NIO","slug":"Java中的NIO","date":"2019-07-17T08:30:42.000Z","updated":"2023-05-29T14:17:37.598Z","comments":true,"path":"2019/07/17/Java中的NIO/","link":"","permalink":"http://example.com/2019/07/17/Java%E4%B8%AD%E7%9A%84NIO/","excerpt":"","text":"NIO(Non-Blocking IO，非阻塞同步IO)是Jdk 1.4后提出的新技术，为什么要提出这个技术呢？是为了解决什么问题呢？ 要回答这个问题，就要从传统的阻塞式IO说起。 何为同步异步，何为阻塞非阻塞对IO来说， 同步：API调用返回时就已经知道执行结果了 异步：API调用返回时还不知道执行结果，需要过一会儿才能知道 阻塞：当没有数据读或者写时，它就一直等啊等，等到有数据来 非阻塞：能读多少是多少，然后返回，即使没有数据读，我也不等，直接返回 总结一下就是，同步异步，强调的是返回时有没有直到执行结果。而阻塞和非阻塞，强调的是何时返回，即死等还是立即返回。 传统IO 单线程下的通信 我们举个简单例子，为了读取一个TCP连接的数据， 客户端： 123456789public class Client &#123; public static void main(String[] args) throws IOException &#123; String host = &quot;127.0.0.1&quot;; int port = 8888 ; Socket socket = new Socket(host,port) ; OutputStream outputStream = socket.getOutputStream(); outputStream.write(String.valueOf(&quot;hello server&quot;).getBytes()); &#125;&#125; 服务端 1234567891011121314public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serverSocket = new ServerSocket(8888); while (true) &#123; Socket socket = serverSocket.accept(); //do something InputStream inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int len = inputStream.read(bytes); System.out.println(new String(bytes, 0, len)); &#125; &#125;&#125; 在这里，服务端的serverSocket.accept()就是一种同步阻塞的写法，服务端的线程一直阻塞在这里，占用着内存资源，直到有请求过来，才开始执行后续代码。当有多个请求到来时，服务端就一个一个挨个处理。很显然，这是很低效的， 多线程下的通信 为了提高服务端的效率，我们多开几个线程来处理服务端的请求。每次有新的连接来了我就重新创建一个线程，而不是排队等候那唯一一个线程，这样效率得到了提高。 服务端： 12345678910111213141516171819202122232425262728293031public class MultiThreadServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serverSocket = new ServerSocket(8888); while (true) &#123; Socket socket = serverSocket.accept(); //do something new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(&quot;sub thread:&quot;+Thread.currentThread().getName()); InputStream inputStream = null; inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int len = 0; len = inputStream.read(bytes); System.out.println(new String(bytes, 0, len)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; 线程太多啦 再后来，业务庞大了，连接数多了起来，这么频繁的创建销毁线程也是很消耗系统资源的，于是，我们使用线程池进行服务端线程的创建与维护，方便统一管理和复用线程，提高资源利用率。在营业（接收并处理请求）之前我先创建好一系列线程，到时候有连接来了我就分配一个线程，用完了我再拿回来，性能薛微得到了一丝改善。 1234567891011121314151617181920212223242526272829303132333435363738394041public class ThreadPoolServer &#123; public static void main(String[] args) throws IOException &#123; ExecutorService service = new ThreadPoolExecutor(5, 10, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); ServerSocket serverSocket = new ServerSocket(8888); while (true) &#123; Socket socket = serverSocket.accept(); service.submit(new RequestHandler(socket)); &#125; &#125;&#125;class RequestHandler implements Runnable &#123; private Socket socket; public RequestHandler(Socket socket) &#123; this.socket = socket; &#125; public RequestHandler() &#123; &#125; @Override public void run() &#123; try &#123; System.out.println(&quot;sub thread:&quot; + Thread.currentThread().getName()); InputStream inputStream = null; inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int len = 0; len = inputStream.read(bytes); System.out.println(new String(bytes, 0, len)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程池也扛不住了 业务持续增长，线程池也满足不了需求了，当线程数大于cpu核数的时候，必然会存在线程切换的问题，这很耗费资源，而且，对于每个线程内部，阻塞的情况还是存在的，这也就存在一个线程状态切换的问题，这也耗费资源。 基于这个背景，我们就在考虑，有没有什么方法，能够解决这个线程频繁上下文切换的问题？也就有了我们的NIO NIO关于NIO，网络上已经有很多相关介绍了，但是我想从一个不同的角度去刨析它。 在之前的文章中我们介绍了五种IO模型，其中有一种是 IO多路复用(IO multiplexing)，NIO的设计就用到了这一思想。 首先我们来大概了解下NIO是怎么工作的。 首先，它是非阻塞的，非阻塞意味着读或者写的时候，如果没有数据，就直接返回了。为了能够拿到数据，你可能就要不停的去调用read或者write去尝试看能不能拿到数据。这也是NIO需要解决的问题之一。 NIO有三个核心模块： Buffer Channel Selector 下面我们会一一介绍。 Buffer传统的BIO是面向流（Stream）的，即我们是向Stream读取或者写入数据的，并且这个Stream是单向的，即要么是输入流，要么是输出流。 NIO是面向缓冲区的，我们要输入的数据，首先得放到Buffer，然后由Buffer送到Channel中。 ChannelChannel意思即通道，它和传统的Stream类似，很大的一点不同在于：Channel是双向的，同一个Channel既可以拿来输入，也可以拿来输出，而不像Stream是有InputStream和OutputStream之分的。 SelectorSelector叫做选择器，也被叫做多路复用器，从他的名字就可以知道，它和我们之前介绍的IO multiplexing有很大关系。 NIO中利用Selector实现了多路复用，通过在Selector上注册多个事件（在我们这里对应的就是通道了），Selector去监听这多个事件是否有发生，如果有事件发生，则进行相应处理。它这样设计一个很大的好处是可以用单线程管理多个通道，如果你仔细读这篇文章，你会发现它们十分类似。 但是也有不同，在IO multiplexing中，应用进程是被select系统调用阻塞的，但是目测在NIO中，注册监听后当前线程并没有被阻塞，所以从这个角度讲，NIO更像是IO多路复用和信号驱动式IO的结合。 总结一下，它的设计思想是这样的： 单线程实现 提出了Channel的概念，每一个对磁盘或者文件的IO操作对应一个Channel，相当于Channel提供了我们和真正的文件或者磁盘操作的一个桥梁。 我们通过Buffer和Channel交互，对于读操作，我们先把数据从Channel读到Buffer,然后再操作Buffer, 对于写操作，我们先把数据放到Buffer, 然后再写到Channel. 为了在实现非阻塞的同时避免不停的调用read()或者write(), 实现了监听机制。具体是通过选择器Selector实现的，我们把每个Channel都绑定在一个Selector上，并且告诉Selector我对什么样的事件感兴趣，通过Selector进行监听，监听的过程中程序是阻塞的，当Channel感兴趣的事件发生时，Selector通知Channel,然后Channel开始它的表演。 所以，说白了，它的非阻塞同步，主要就是 设置了监听 把多线程的客户端请求映射成了单线程的多个channel, 然后selector监听，有感兴趣的事情发生之后就开始轮询每个channel.","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"IO","slug":"IO","permalink":"http://example.com/tags/IO/"}]},{"title":"Java反射机制","slug":"Java反射机制","date":"2019-07-11T07:26:23.000Z","updated":"2019-07-11T07:26:23.000Z","comments":true,"path":"2019/07/11/Java反射机制/","link":"","permalink":"http://example.com/2019/07/11/Java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/","excerpt":"","text":"写这篇文章主要想讲两个问题： 什么是反射 反射存在的意义 反射能做哪些事 什么是反射反射，简单的来讲，是一种在程序运行时生成对象的技术。为什么说是运行时呢，相比我们平时写代码时创建对象，比如： 123public static void main()&#123; Object obj = new Object();&#125; 我们创建对象的代码是事先写好的，那么程序在编译的时候，也就是.java文件被编译成.class文件的时候，这个对象就已经在class文件中了。而反射讲的是，这个对象在编译器是不存在，在程序运行的时候，因为某种需求，它才被创建出来。 反射存在的意义学习一种技术，更重要的是要明白它存在的意义。那么为什么要有反射呢？ 反射一个最大的用途就是用在各大框架中，如Spring,Struts2 现在的各种框架都是配置型的。下面的xml是Stucts2中的一个配置文件。当后台收到这个login请求后，经过各种过滤器，最后它会和这个配置文件对应，这个配置文件里面描述了当收到这种请求后我要调用哪个类（这里就是 org.ScZyhSoft.test.action.SimpleLoginAction类），以及类中的哪个方法（这里就是execute方法）。但这个类其实配置文件只写了一个类名，也就是说等到真正这个请求到了，需要用到这个类的时候它才被创建，这里创建的技术就是反射。 123456&lt;action name=&quot;login&quot; class=&quot;org.ScZyhSoft.test.action.SimpleLoginAction&quot; method=&quot;execute&quot;&gt; &lt;result&gt;/shop/shop-index.jsp&lt;/result&gt; &lt;result name=&quot;error&quot;&gt;login.jsp&lt;/result&gt; &lt;/action&gt; 反射能做哪些事创建实例使用反射创建实例，首先要获得Class对象，你可以认为它就是我们所写的类的对象类型。这句话可能有点绕，俗话说“万事万物皆对象”（当然除了基本数据类型），所以类本身也是对象，它是Class类的对象，获取Class对象有三种方法： Class.forName() 比如Class.forName(org.ScZyhSoft.test.action.SimpleLoginAction) 直接获取某个对象的class属性 如Class&lt;?&gt; klass = obj.class 调用某个对象的getClass()方法 如Class&lt;?&gt; klass = obj.getClass() 获取Class对象之后，就可以使用Class对象来创建实例了 对于默认构造函数的对象，我们可以 12Class&lt;?&gt; c = String.class;Object str = c.newInstance(); 对于带参的构造函数，我们可以 123456//获取String所对应的Class对象Class&lt;?&gt; c = String.class;//获取String类带一个String参数的构造器Constructor constructor = c.getConstructor(String.class);//根据构造器创建实例Object obj = constructor.newInstance(&quot;23333&quot;); 获取方法和成员变量获取某个Class对象的方法集合，主要有以下几个方法： getDeclaredMethods 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 1public Method[] getDeclaredMethods() throws SecurityException getMethods 方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。 1public Method[] getMethods() throws SecurityException getMethod 方法返回一个特定的方法，public的，其中第一个参数为方法名称，后面的参数为方法的参数对应Class的对象。 1public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) getDeclaredField：所有已声明的成员变量，不问访问权限，但不能得到其父类的成员变量 getFileds：访问公有的成员变量，包括继承的公用方法 getField(String name) 获取指定的变量（public） 调用方法invoke()","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"反射","slug":"反射","permalink":"http://example.com/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"Java集合类之HashMap","slug":"谈一谈Java集合类之HashMap","date":"2019-07-09T12:44:30.000Z","updated":"2019-07-09T12:44:30.000Z","comments":true,"path":"2019/07/09/谈一谈Java集合类之HashMap/","link":"","permalink":"http://example.com/2019/07/09/%E8%B0%88%E4%B8%80%E8%B0%88Java%E9%9B%86%E5%90%88%E7%B1%BB%E4%B9%8BHashMap/","excerpt":"","text":"OverViewHashMap工作原理1. jdk 1.7数据结构： 看一下Entry的结构： 1234final K key;V value;Entry&lt;K,V&gt; next;int hash; put方法： 12345678910111213141516171819202122public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; 123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex); &#125; 12345void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; &#125; resize方法： 12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; 2. jdk 1.8在1.7的实现中，每个桶中的链表过长后会造成查询时间增长，针对此，在1.8中进行了优化，当链表超过一定长度时，使用红黑树来代替。 数据结构： 相比1.7中的成员变量，主要有以下改动: 增加了TREEIFY_THRESHOLD和UNTREEIFY_THRESHOLD:将链表转为红黑树的阈值,以及在resize时将红黑树转为链表的阈值。 将Entry改为Node Node的数据结构如下： 1234final int hash;final K key;V value;Node&lt;K,V&gt; next; put方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果表空 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果当前桶空 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果有key相同的元素 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果是tree节点 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果是链表节点 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //检查容量是否到达阈值 ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; get方法： 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 需要注意的是，HashMap和其他集合类一样，也有扩容的操作，当entries的数量超过容量阈值时，会自动扩容。所谓扩容，就是把里面的元素移植到一个更大的HashMap中，里面所有的元素都要进行以此重新hash. 即使1.8中进行了优化，但是hashmap还是存在一些不可避免的问题，比如：线程不安全。当在扩容的过程中有多个线程一起操作时，很有可能会造成链表首位相连，形成死循环。Javadoc中有这么一句话 12345678&lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt;If multiple threads access a hash map concurrently, and at least one ofthe threads modifies the map structurally, it &lt;i&gt;must&lt;/i&gt; besynchronized externally. (A structural modification is any operationthat adds or deletes one or more mappings; merely changing the valueassociated with a key that an instance already contains is not astructural modification.) This is typically accomplished bysynchronizing on some object that naturally encapsulates the map. 就是说在对HashMap做结构性修改的时候，比如put，remove，resize这种操作，不是线程安全的。其实直观想一想也是，多个线程直接访问这些内容，肯定会有问题的。下面我主要从三个方面来说明它的线程不安全性。 执行put操作的时候 以jdk 1.7为例，在put的代码中有以下方法： 1234567void createEntry(int hash, K key, V value, int bucketIndex) &#123; //先保存这个位置本来的元素 Entry&lt;K,V&gt; e = table[bucketIndex]; //将新来的元素头插 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; &#125; 这是一个简单的头插法，试想一下，假如有两个线程A和B都往同一个hashmap中写元素，恰好这两个元素算出来的索引是一样的，B线程执行到Entry&lt;K,V&gt; e = table[bucketIndex]后时间片用完，获取了桶中第一个元素后就挂起了，然后线程A进入这个方法并执行完，这时候看似A线程成功将它所操作的元素插入了进来，等到B线程的时间片来临时，B线程继续上次停止的地方执行，因为A线程和B线程获取的是相同的头元素，所以B线程的插入会覆盖之前B线程的操作。 执行resize的时候 执行resize的时候，很容易造成循环链表，使得cpu占用率飙升。上面展示了resize的代码，它有个核心方法transfer: 作用就是把原来table中的元素转移到新的table中。留意圈出来的内容，你会发现它其实就是个将当前元素e头插的链表操作. 同样假设有两个线程，假设了我们的hash算法就是简单的用key mod 一下表的大小。 ​ (1) 假设线程一刚好执行完代码1就被挂起，而线程二执行完了，那么情况如下： 线程一的e指向3，next指向7. ​ (2) 线程一被调度回来执行，执行完当前循环，将3头插，并且执行下次循环中的代码next=e.next后， ​ (3) 将7头插，并执行下一次循环中的next=e.next后 ​ (4) 它来了，它带着环型链表来了 总结一下，为什么会出现环型链表，针对这个链表而言，是因为我们把链表的最后一个元素进行了头插却没有考虑将指向这个节点的next指针置为null导致的。 执行remove的时候 ConcurrentHashMap1. jdk 1.7工作原理使用分段锁技术，定义了Segment类，该类继承自ReentryLock, ConcurrentHashMap结构大概 如下： 这相当于一种分治思想，Segment数组中的每个元素包含了一个table数组,这是一个原始意义上的HashMap，每个table数组的元素里装了HashEntry. table整体是一个数组链表的形式。 即使需要加锁，也是对每个段进行加锁。 HashEntry所包含的字段如下： 1234final int hash;final K key;volatile V value;volatile HashEntry&lt;K,V&gt; next; 可以发现，hash和key都是被final修饰的， value和next是被volatile修饰的，保证了多线程下的可见性。 put1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) //value不能为空 throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; //寻找对应的段 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); return s.put(key, hash, value, false); //在对应的段中进行put&#125; 从上述代码可以发现，ConcurrentHashMap中value不允许为空。段中的put方法如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; //如果存在相同entry则替换 oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; //如果当前桶里没东西则创建新Entry加进去 if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; 可以看到put操作还是有加锁处理的，因为volatile关键字并不能保证原子性。先尝试获取锁，如果失败，则利用scanAndLockForPut自旋获取锁。 rehash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private void rehash(HashEntry&lt;K,V&gt; node) &#123; /* * Reclassify nodes in each list to new table. Because we * are using power-of-two expansion, the elements from * each bin must either stay at same index, or move with a * power of two offset. We eliminate unnecessary node * creation by catching cases where old nodes can be * reused because their next fields won&#x27;t change. * Statistically, at the default threshold, only about * one-sixth of them need cloning when a table * doubles. The nodes they replace will be garbage * collectable as soon as they are no longer referenced by * any reader thread that may be in the midst of * concurrently traversing table. Entry accesses use plain * array indexing because they are followed by volatile * table write. */ HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; int newCapacity = oldCapacity &lt;&lt; 1; threshold = (int)(newCapacity * loadFactor); HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123; HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; if (next == null) // Single node on list newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; //1. 这里就是遍历当前链表，找到最后一个不在原桶中的元素，那么这个元素后面的所有元素也都不在原桶中。 if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; newTable[lastIdx] = lastRun; // Clone remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; int nodeIndex = node.hash &amp; sizeMask; // add the new node node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable; &#125; 这里主要要注意里面的一个优化，进行rehash时，由于扩容是二倍，所以本来桶中的那些entry要么在原处，要么在原位置+原容量的位置，也就是说桶中的entry只有两个去处：原地不动或者当前位置+容量。所以注释1处找到最后一个不在原桶中的元素后，这个元素后面的所有元素都不在原桶中且都在相同的索引处。 get1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null; &#125; 因为value都是volatile修饰的，所以get过程不需要加锁。 sizesize方法是跨段操作 2. jdk 1.8工作原理底层使用红黑树，类似hashmap的优化： 在并发控制上，抛弃了原本的分段锁，采用CAS+synchronized 来保证并发安全性。 put get size方法1.8中size方法就比较简单 123456public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); &#125; sumCount方法： 1234567891011final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125; 如果counterCells不空，则遍历元素和baseCount累加。关于baseCount和CounterCells解释如下： baseCount定义如下： 123456/** * Base counter value, used mainly when there is no contention, * but also as a fallback during table initialization * races. Updated via CAS. */private transient volatile long baseCount; 通过CAS更新，没有争用时使用它计数。它在addCount方法中被使用。 如果有争用，baseCount的CAS更新失败，那么就尝试把要更新的增量更新到CounterCell中 CounterCell结构如下： 12345678/** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */ @sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125; &#125; 1.7和1.8的区别 1.7 1.8 数据结构 链表 红黑树 并发控制 分段锁 CAS+synhcronized size 多次计算，再决定是否加锁 baseCount+CounterCell 参考Map 综述（三）：彻头彻尾理解 ConcurrentHashMap（jdk 1.6） HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！ (jdk1.7 jdk 1.8) Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术 疫苗：JAVA HASHMAP的死循环 并发编程 —— ConcurrentHashMap size 方法原理分析","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"}]},{"title":"关于synchronized关键字","slug":"关于synchronize关键字","date":"2019-07-04T06:45:10.000Z","updated":"2019-07-04T06:45:10.000Z","comments":true,"path":"2019/07/04/关于synchronize关键字/","link":"","permalink":"http://example.com/2019/07/04/%E5%85%B3%E4%BA%8Esynchronize%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"synchronized关键字可以用来修饰方法，也可以用来修饰代码块，但是底层的实现有所不同。对于同步方法，JVM采用ACC_SYNCHRONIZED标记符来实现同步。 对于同步代码块。JVM采用monitorenter、monitorexit两个指令来实现同步。 Q1: synchronized关键字如何实现原子性？ ​ 通过moniterenter和moniterexit两个指令保证代码块在同一时间内只能被同一线程访问。 Q2: synchronized关键字如何实现可见性？ ​ 对于sybchronized关键字，有一条规定是这样的，在对代码块解锁前，需要先把里面的变量同步到主存中，以此来保证可见性。","categories":[{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"}],"tags":[]},{"title":"科学上网","slug":"科学上网","date":"2019-07-04T02:58:39.000Z","updated":"2019-07-04T02:58:39.000Z","comments":true,"path":"2019/07/04/科学上网/","link":"","permalink":"http://example.com/2019/07/04/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/","excerpt":"","text":"最近买了个vultr,特此记录以下安装小飞机的过程： 123wget --no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh | tee shadowsocks.log 然后根据提示输入密码端口之类的，等安装好就可以用了 1/etc/init.d/shadowsocks status 可以查看shadowsocks是否在运行 有时候shadowsocks不好用，可以用ssr 123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log","categories":[{"name":"教程","slug":"教程","permalink":"http://example.com/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"教程","slug":"教程","permalink":"http://example.com/tags/%E6%95%99%E7%A8%8B/"}]},{"title":"类加载机制","slug":"类加载机制","date":"2019-06-05T07:41:06.000Z","updated":"2019-06-05T07:41:06.000Z","comments":true,"path":"2019/06/05/类加载机制/","link":"","permalink":"http://example.com/2019/06/05/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"深入理解Java类加载器(ClassLoader)2017年06月26日 09:34:08 zejian_ 阅读数：115126 版权声明：本文为博主原创文章，请尊重原创，未经博主允许禁止转载，保留追究权 https://blog.csdn.net/javazejian/article/details/73413292 【版权申明】未经博主同意，谢绝转载！（请尊重原创，博主保留追究权）http://blog.csdn.net/javazejian/article/details/73413292出自【zejian的博客】 关联文章： 深入理解Java类型信息(Class对象)与反射机制 深入理解Java枚举类型(enum) 深入理解Java注解类型(@Annotation) 深入理解Java类加载器(ClassLoader) 深入理解Java并发之synchronized实现原理 Java并发编程-无锁CAS与Unsafe类及其并发包Atomic 深入理解Java内存模型(JMM)及volatile关键字 剖析基于并发AQS的重入锁(ReetrantLock)及其Condition实现原理 剖析基于并发AQS的共享锁的实现(基于信号量Semaphore) 并发之阻塞队列LinkedBlockingQueue与ArrayBlockingQueue 本篇博文主要是探讨类加载器，同时在本篇中列举的源码都基于Java8版本，不同的版本可能有些许差异。主要内容如下 类加载的机制的层次结构 启动Bootstrap类加载器 扩展Extension类加载器 系统System类加载器 理解双亲委派模式 双亲委派模式工作原理 双亲委派模式优势 类加载器间的关系 类与类加载器 类与类加载器 了解class文件的显示加载与隐式加载的概念 编写自己的类加载器 自定义File类加载器 自定义网络类加载器 热部署类加载器 双亲委派模型的破坏者-线程上下文类加载器 类加载的机制的层次结构每个编写的”.java”拓展名类文件都存储着需要执行的程序逻辑，这些”.java”文件经过Java编译器编译成拓展名为”.class”的文件，”.class”文件中保存着Java代码经转换后的虚拟机指令，当需要使用某个类时，虚拟机将会加载它的”.class”文件，并创建对应的class对象，将class文件加载到虚拟机的内存，这个过程称为类加载，这里我们需要了解一下类加载的过程，如下： 加载：类加载过程的一个阶段：通过一个类的完全限定查找此类字节码文件，并利用字节码文件创建一个Class对象 验证：目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，不会危害虚拟机自身安全。主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证。 准备：为类变量(即static修饰的字段变量)分配内存并且设置该类变量的初始值即0(如static int i=5;这里只将i初始化为0，至于5的值将在初始化时赋值)，这里不包含用final修饰的static，因为final在编译的时候就会分配了，注意这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中。 解析：主要将常量池中的符号引用替换为直接引用的过程。符号引用就是一组符号来描述目标，可以是任何字面量，而直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。有类或接口的解析，字段解析，类方法解析，接口方法解析(这里涉及到字节码变量的引用，如需更详细了解，可参考《深入Java虚拟机》)。 初始化：类加载最后阶段，若该类具有超类，则对其进行初始化，执行静态初始化器和静态初始化成员变量(如前面只初始化了默认值的static变量将会在这个阶段赋值，成员变量也将被初始化)。 这便是类加载的5个过程，而类加载器的任务是根据一个类的全限定名来读取此类的二进制字节流到JVM中，然后转换为一个与目标类对应的java.lang.Class对象实例，在虚拟机提供了3种类加载器，引导（Bootstrap）类加载器、扩展（Extension）类加载器、系统（System）类加载器（也称应用类加载器），下面分别介绍 启动（Bootstrap）类加载器启动类加载器主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，它负责将 &lt;JAVA_HOME&gt;/lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，注意必由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类)。 扩展（Extension）类加载器扩展类加载器是指Sun公司(已被Oracle收购)实现的sun.misc.Launcher$ExtClassLoader类，由Java语言实现的，是Launcher的静态内部类，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。 12345678910111213141516171819//ExtClassLoader类中获取路径的代码private static File[] getExtDirs() &#123; //加载&lt;JAVA_HOME&gt;/lib/ext目录中的类库 String s = System.getProperty(&quot;java.ext.dirs&quot;); File[] dirs; if (s != null) &#123; StringTokenizer st = new StringTokenizer(s, File.pathSeparator); int count = st.countTokens(); dirs = new File[count]; for (int i = 0; i &lt; count; i++) &#123; dirs[i] = new File(st.nextToken()); &#125; &#125; else &#123; dirs = new File[0]; &#125; return dirs; &#125;12345678910111213141516171819 系统（System）类加载器也称应用程序加载器是指 Sun公司实现的sun.misc.Launcher$AppClassLoader。它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。 在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，需要注意的是，Java虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类时才会将它的class文件加载到内存生成class对象，而且加载某个类的class文件时，Java虚拟机采用的是双亲委派模式即把请求交由父类处理，它一种任务委派模式，下面我们进一步了解它。 理解双亲委派模式双亲委派模式工作原理双亲委派模式要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器，请注意双亲委派模式中的父子关系并非通常所说的类继承关系，而是采用组合关系来复用父类加载器的相关代码，类加载器间的关系如下： 双亲委派模式是在Java 1.2后引入的，其工作原理的是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都很懒，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己想办法去完成，这不就是传说中的实力坑爹啊？那么采用这种模式有啥用呢? 双亲委派模式优势采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。可能你会想，如果我们在classpath路径下自定义一个名为java.lang.SingleInterge类(该类是胡编的)呢？该类并不存在java.lang中，经过双亲委托模式，传递到启动类加载器中，由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过系统类加载器加载该类。但是这样做是不允许，因为java.lang是核心API包，需要访问权限，强制加载将会报出如下异常 1java.lang.SecurityException: Prohibited package name: java.lang1 所以无论如何都无法加载成功的。下面我们从代码层面了解几个Java中定义的类加载器及其双亲委派模式的实现，它们类图关系如下 从图可以看出顶层的类加载器是ClassLoader类，它是一个抽象类，其后所有的类加载器都继承自ClassLoader（不包括启动类加载器），这里我们主要介绍ClassLoader中几个比较重要的方法。 loadClass(String) 该方法加载指定名称（包括包名）的二进制类型，该方法在JDK1.2之后不再建议用户重写但用户可以直接调用该方法，loadClass()方法是ClassLoader类自己实现的，该方法中的逻辑就是双亲委派模式的实现，其源码如下，loadClass(String name, boolean resolve)是一个重载方法，resolve参数代表是否生成class对象的同时进行解析相关操作。： 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 先从缓存查找该class对象，找到就不用重新加载 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //如果找不到，则委托给父类加载器去加载 c = parent.loadClass(name, false); &#125; else &#123; //如果没有父类，则委托给启动加载器去加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // 如果都没有找到，则通过自定义实现的findClass去查找并加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123;//是否需要在加载时进行解析 resolveClass(c); &#125; return c; &#125; &#125;1234567891011121314151617181920212223242526272829303132333435363738 正如loadClass方法所展示的，当类加载请求到来时，先从缓存中查找该类对象，如果存在直接返回，如果不存在则交给该类加载去的父加载器去加载，倘若没有父加载则交给顶级启动类加载器去加载，最后倘若仍没有找到，则使用findClass()方法去加载（关于findClass()稍后会进一步介绍）。从loadClass实现也可以知道如果不想重新定义加载类的规则，也没有复杂的逻辑，只想在运行时加载自己指定的类，那么我们可以直接使用this.getClass().getClassLoder.loadClass(&quot;className&quot;)，这样就可以直接调用ClassLoader的loadClass方法获取到class对象。 findClass(String)在JDK1.2之前，在自定义类加载时，总会去继承ClassLoader类并重写loadClass方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑写在findClass()方法中，从前面的分析可知，findClass()方法是在loadClass()方法中被调用的，当loadClass()方法中父加载器加载失败后，则会调用自己的findClass()方法来完成类加载，这样就可以保证自定义的类加载器也符合双亲委托模式。需要注意的是ClassLoader类中并没有实现findClass()方法的具体代码逻辑，取而代之的是抛出ClassNotFoundException异常，同时应该知道的是findClass方法通常是和defineClass方法一起使用的(稍后会分析)，ClassLoader类中findClass()方法源码如下： 1234//直接抛出异常protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125;1234 defineClass(byte[] b, int off, int len)defineClass()方法是用来将byte字节流解析成JVM能够识别的Class对象(ClassLoader中已实现该方法逻辑)，通过这个方法不仅能够通过class文件实例化class对象，也可以通过其他方式实例化class对象，如通过网络接收一个类的字节码，然后转换为byte字节流创建对应的Class对象，defineClass()方法通常与findClass()方法一起使用，一般情况下，在自定义类加载器时，会直接覆盖ClassLoader的findClass()方法并编写加载规则，取得要加载类的字节码后转换成流，然后调用defineClass()方法生成类的Class对象，简单例子如下： 12345678910protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; // 获取类的字节数组 byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; //使用defineClass生成class对象 return defineClass(name, classData, 0, classData.length); &#125; &#125;12345678910 需要注意的是，如果直接调用defineClass()方法生成类的Class对象，这个类的Class对象并没有解析(也可以理解为链接阶段，毕竟解析是链接的最后一步)，其解析操作需要等待初始化阶段进行。 resolveClass(Class≺?≻ c)使用该方法可以使用类的Class对象创建完成也同时被解析。前面我们说链接阶段主要是对字节码进行验证，为类变量分配内存并设置初始值同时将字节码文件中的符号引用转换为直接引用。 上述4个方法是ClassLoader类中的比较重要的方法，也是我们可能会经常用到的方法。接看SercureClassLoader扩展了 ClassLoader，新增了几个与使用相关的代码源(对代码源的位置及其证书的验证)和权限定义类验证(主要指对class源码的访问权限)的方法，一般我们不会直接跟这个类打交道，更多是与它的子类URLClassLoader有所关联，前面说过，ClassLoader是一个抽象类，很多方法是空的没有实现，比如 findClass()、findResource()等。而URLClassLoader这个实现类为这些方法提供了具体的实现，并新增了URLClassPath类协助取得Class字节码流等功能，在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass()方法及其获取字节码流的方式，使自定义类加载器编写更加简洁，下面是URLClassLoader的类图(利用IDEA生成的类图) 从类图结构看出URLClassLoader中存在一个URLClassPath类，通过这个类就可以找到要加载的字节码流，也就是说URLClassPath类负责找到要加载的字节码，再读取成字节流，最后通过defineClass()方法创建类的Class对象。从URLClassLoader类的结构图可以看出其构造方法都有一个必须传递的参数URL[]，该参数的元素是代表字节码文件的路径,换句话说在创建URLClassLoader对象时必须要指定这个类加载器的到那个目录下找class文件。同时也应该注意URL[]也是URLClassPath类的必传参数，在创建URLClassPath对象时，会根据传递过来的URL数组中的路径判断是文件还是jar包，然后根据不同的路径创建FileLoader或者JarLoader或默认Loader类去加载相应路径下的class文件，而当JVM调用findClass()方法时，就由这3个加载器中的一个将class文件的字节码流加载到内存中，最后利用字节码流创建类的class对象。请记住，如果我们在定义类加载器时选择继承ClassLoader类而非URLClassLoader，必须手动编写findclass()方法的加载逻辑以及获取字节码流的逻辑。了解完URLClassLoader后接着看看剩余的两个类加载器，即拓展类加载器ExtClassLoader和系统类加载器AppClassLoader，这两个类都继承自URLClassLoader，是sun.misc.Launcher的静态内部类。sun.misc.Launcher主要被系统用于启动主应用程序，ExtClassLoader和AppClassLoader都是由sun.misc.Launcher创建的，其类主要类结构如下： 它们间的关系正如前面所阐述的那样，同时我们发现ExtClassLoader并没有重写loadClass()方法，这足矣说明其遵循双亲委派模式，而AppClassLoader重载了loadCass()方法，但最终调用的还是父类loadClass()方法，因此依然遵守双亲委派模式，重载方法源码如下： 12345678910111213141516/** * Override loadClass 方法，新增包权限检测功能 */public Class loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; int i = name.lastIndexOf(&#x27;.&#x27;); if (i != -1) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; sm.checkPackageAccess(name.substring(0, i)); &#125; &#125; //依然调用父类的方法 return (super.loadClass(name, resolve));&#125;12345678910111213141516 其实无论是ExtClassLoader还是AppClassLoader都继承URLClassLoader类，因此它们都遵守双亲委托模型，这点是毋庸置疑的。ok，到此我们对ClassLoader、URLClassLoader、ExtClassLoader、AppClassLoader以及Launcher类间的关系有了比较清晰的了解，同时对一些主要的方法也有一定的认识，这里并没有对这些类的源码进行详细的分析，毕竟没有那个必要，因为我们主要弄得类与类间的关系和常用的方法同时搞清楚双亲委托模式的实现过程，为编写自定义类加载器做铺垫就足够了。ok，前面出现了很多父类加载器的说法，但每个类加载器的父类到底是谁，一直没有阐明，下面我们就通过代码验证的方式来阐明这答案。 类加载器间的关系我们进一步了解类加载器间的关系(并非指继承关系)，主要可以分为以下4点 启动类加载器，由C++实现，没有父类。 拓展类加载器(ExtClassLoader)，由Java语言实现，父类加载器为null 系统类加载器(AppClassLoader)，由Java语言实现，父类加载器为ExtClassLoader 自定义类加载器，父类加载器肯定为AppClassLoader。 下面我们通过程序来验证上述阐述的观点 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Created by zejian on 2017/6/18. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] *///自定义ClassLoader，完整代码稍后分析class FileClassLoader extends ClassLoader&#123; private String rootDir; public FileClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; // 编写获取类的字节码并创建class对象的逻辑 @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; //...省略逻辑代码 &#125; //编写读取字节流的方法 private byte[] getClassData(String className) &#123; // 读取类文件的字节 //省略代码.... &#125;&#125;public class ClassLoaderTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; FileClassLoader loader1 = new FileClassLoader(rootDir); System.out.println(&quot;自定义类加载器的父加载器: &quot;+loader1.getParent()); System.out.println(&quot;系统默认的AppClassLoader: &quot;+ClassLoader.getSystemClassLoader()); System.out.println(&quot;AppClassLoader的父类加载器: &quot;+ClassLoader.getSystemClassLoader().getParent()); System.out.println(&quot;ExtClassLoader的父类加载器: &quot;+ClassLoader.getSystemClassLoader().getParent().getParent()); /** 输出结果: 自定义类加载器的父加载器: sun.misc.Launcher$AppClassLoader@29453f44 系统默认的AppClassLoader: sun.misc.Launcher$AppClassLoader@29453f44 AppClassLoader的父类加载器: sun.misc.Launcher$ExtClassLoader@6f94fa3e ExtClassLoader的父类加载器: null */ &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738394041424344 代码中，我们自定义了一个FileClassLoader，这里我们继承了ClassLoader而非URLClassLoader,因此需要自己编写findClass()方法逻辑以及加载字节码的逻辑，关于自定义类加载器我们稍后会分析，这里仅需要知道FileClassLoader是自定义加载器即可，接着在main方法中，通过ClassLoader.getSystemClassLoader()获取到系统默认类加载器，通过获取其父类加载器及其父父类加载器，同时还获取了自定义类加载器的父类加载器,最终输出结果正如我们所预料的，AppClassLoader的父类加载器为ExtClassLoader，而ExtClassLoader没有父类加载器。如果我们实现自己的类加载器，它的父加载器都只会是AppClassLoader。这里我们不妨看看Lancher的构造器源码 123456789101112131415161718192021222324public Launcher() &#123; // 首先创建拓展类加载器 ClassLoader extcl; try &#123; extcl = ExtClassLoader.getExtClassLoader(); &#125; catch (IOException e) &#123; throw new InternalError( &quot;Could not create extension class loader&quot;); &#125; // Now create the class loader to use to launch the application try &#123; //再创建AppClassLoader并把extcl作为父加载器传递给AppClassLoader loader = AppClassLoader.getAppClassLoader(extcl); &#125; catch (IOException e) &#123; throw new InternalError( &quot;Could not create application class loader&quot;); &#125; //设置线程上下文类加载器，稍后分析 Thread.currentThread().setContextClassLoader(loader);//省略其他没必要的代码...... &#125; &#125;123456789101112131415161718192021222324 显然Lancher初始化时首先会创建ExtClassLoader类加载器，然后再创建AppClassLoader并把ExtClassLoader传递给它作为父类加载器，这里还把AppClassLoader默认设置为线程上下文类加载器，关于线程上下文类加载器稍后会分析。那ExtClassLoader类加载器为什么是null呢？看下面的源码创建过程就明白，在创建ExtClassLoader强制设置了其父加载器为null。 1234567891011121314151617181920//Lancher中创建ExtClassLoaderextcl = ExtClassLoader.getExtClassLoader();//getExtClassLoader()方法public static ExtClassLoader getExtClassLoader() throws IOException&#123; //........省略其他代码 return new ExtClassLoader(dirs); // .........&#125;//构造方法public ExtClassLoader(File[] dirs) throws IOException &#123; //调用父类构造URLClassLoader传递null作为parent super(getExtURLs(dirs), null, factory);&#125;//URLClassLoader构造public URLClassLoader(URL[] urls, ClassLoader parent, URLStreamHandlerFactory factory) &#123;1234567891011121314151617181920 显然ExtClassLoader的父类为null，而AppClassLoader的父加载器为ExtClassLoader，所有自定义的类加载器其父加载器只会是AppClassLoader，注意这里所指的父类并不是Java继承关系中的那种父子关系。 类与类加载器类与类加载器在JVM中表示两个class对象是否为同一个类对象存在两个必要条件 类的完整类名必须一致，包括包名。 加载这个类的ClassLoader(指ClassLoader实例对象)必须相同。 也就是说，在JVM中，即使这个两个类对象(class对象)来源同一个Class文件，被同一个虚拟机所加载，但只要加载它们的ClassLoader实例对象不同，那么这两个类对象也是不相等的，这是因为不同的ClassLoader实例对象都拥有不同的独立的类名称空间，所以加载的class对象也会存在不同的类名空间中，但前提是覆写loadclass方法，从前面双亲委派模式对loadClass()方法的源码分析中可以知，在方法第一步会通过Class&lt;?&gt; c = findLoadedClass(name);从缓存查找，类名完整名称相同则不会再次被加载，因此我们必须绕过缓存查询才能重新加载class对象。当然也可直接调用findClass()方法，这样也避免从缓存查找，如下 1234567891011121314151617String rootDir=&quot;/Users/zejian/Downloads/Java8_Action/src/main/java/&quot;;//创建两个不同的自定义类加载器实例FileClassLoader loader1 = new FileClassLoader(rootDir);FileClassLoader loader2 = new FileClassLoader(rootDir);//通过findClass创建类的Class对象Class&lt;?&gt; object1=loader1.findClass(&quot;com.zejian.classloader.DemoObj&quot;);Class&lt;?&gt; object2=loader2.findClass(&quot;com.zejian.classloader.DemoObj&quot;);System.out.println(&quot;findClass-&gt;obj1:&quot;+object1.hashCode());System.out.println(&quot;findClass-&gt;obj2:&quot;+object2.hashCode());/** * 直接调用findClass方法输出结果: * findClass-&gt;obj1:723074861 findClass-&gt;obj2:895328852 生成不同的实例 */1234567891011121314151617 如果调用父类的loadClass方法，结果如下，除非重写loadClass()方法去掉缓存查找步骤，不过现在一般都不建议重写loadClass()方法。 1234567891011121314151617//直接调用父类的loadClass()方法Class&lt;?&gt; obj1 =loader1.loadClass(&quot;com.zejian.classloader.DemoObj&quot;);Class&lt;?&gt; obj2 =loader2.loadClass(&quot;com.zejian.classloader.DemoObj&quot;);//不同实例对象的自定义类加载器System.out.println(&quot;loadClass-&gt;obj1:&quot;+obj1.hashCode());System.out.println(&quot;loadClass-&gt;obj2:&quot;+obj2.hashCode());//系统类加载器System.out.println(&quot;Class-&gt;obj3:&quot;+DemoObj.class.hashCode());/*** 直接调用loadClass方法的输出结果,注意并没有重写loadClass方法* loadClass-&gt;obj1:1872034366 loadClass-&gt;obj2:1872034366 Class-&gt; obj3:1872034366 都是同一个实例*/1234567891011121314151617 所以如果不从缓存查询相同完全类名的class对象，那么只有ClassLoader的实例对象不同，同一字节码文件创建的class对象自然也不会相同。 了解class文件的显示加载与隐式加载的概念所谓class文件的显示加载与隐式加载的方式是指JVM加载class文件到内存的方式，显示加载指的是在代码中通过调用ClassLoader加载class对象，如直接使用Class.forName(name)或this.getClass().getClassLoader().loadClass()加载class对象。而隐式加载则是不直接在代码中调用ClassLoader的方法加载class对象，而是通过虚拟机自动加载到内存中，如在加载某个类的class文件时，该类的class文件中引用了另外一个类的对象，此时额外引用的类将通过JVM自动加载到内存中。在日常开发以上两种方式一般会混合使用，这里我们知道有这么回事即可。 编写自己的类加载器通过前面的分析可知，实现自定义类加载器需要继承ClassLoader或者URLClassLoader，继承ClassLoader则需要自己重写findClass()方法并编写加载逻辑，继承URLClassLoader则可以省去编写findClass()方法以及class文件加载转换成字节码流的代码。那么编写自定义类加载器的意义何在呢？ 当class文件不在ClassPath路径下，默认系统类加载器无法找到该class文件，在这种情况下我们需要实现一个自定义的ClassLoader来加载特定路径下的class文件生成class对象。 当一个class文件是通过网络传输并且可能会进行相应的加密操作时，需要先对class文件进行相应的解密后再加载到JVM内存中，这种情况下也需要编写自定义的ClassLoader并实现相应的逻辑。 当需要实现热部署功能时(一个class文件通过不同的类加载器产生不同class对象从而实现热部署功能)，需要实现自定义ClassLoader的逻辑。 自定义File类加载器这里我们继承ClassLoader实现自定义的特定路径下的文件类加载器并加载编译后DemoObj.class，源码代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class DemoObj &#123; @Override public String toString() &#123; return &quot;I am DemoObj&quot;; &#125;&#125;123456package com.zejian.classloader;import java.io.*;/** * Created by zejian on 2017/6/21. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class FileClassLoader extends ClassLoader &#123; private String rootDir; public FileClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; /** * 编写findClass方法的逻辑 * @param name * @return * @throws ClassNotFoundException */ @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; // 获取类的class文件字节数组 byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; //直接生成class对象 return defineClass(name, classData, 0, classData.length); &#125; &#125; /** * 编写获取class文件并转换为字节码流的逻辑 * @param className * @return */ private byte[] getClassData(String className) &#123; // 读取类文件的字节 String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; // 读取类文件的字节码 while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 类文件的完全路径 * @param className * @return */ private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace(&#x27;.&#x27;, File.separatorChar) + &quot;.class&quot;; &#125; public static void main(String[] args) throws ClassNotFoundException &#123; String rootDir=&quot;/Users/zejian/Downloads/Java8_Action/src/main/java/&quot;; //创建自定义文件类加载器 FileClassLoader loader = new FileClassLoader(rootDir); try &#123; //加载指定的class文件 Class&lt;?&gt; object1=loader.loadClass(&quot;com.zejian.classloader.DemoObj&quot;); System.out.println(object1.newInstance().toString()); //输出结果:I am DemoObj &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485 显然我们通过getClassData()方法找到class文件并转换为字节流，并重写findClass()方法，利用defineClass()方法创建了类的class对象。在main方法中调用了loadClass()方法加载指定路径下的class文件，由于启动类加载器、拓展类加载器以及系统类加载器都无法在其路径下找到该类，因此最终将有自定义类加载器加载，即调用findClass()方法进行加载。如果继承URLClassLoader实现，那代码就更简洁了，如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * Created by zejian on 2017/6/21. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class FileUrlClassLoader extends URLClassLoader &#123; public FileUrlClassLoader(URL[] urls, ClassLoader parent) &#123; super(urls, parent); &#125; public FileUrlClassLoader(URL[] urls) &#123; super(urls); &#125; public FileUrlClassLoader(URL[] urls, ClassLoader parent, URLStreamHandlerFactory factory) &#123; super(urls, parent, factory); &#125; public static void main(String[] args) throws ClassNotFoundException, MalformedURLException &#123; String rootDir=&quot;/Users/zejian/Downloads/Java8_Action/src/main/java/&quot;; //创建自定义文件类加载器 File file = new File(rootDir); //File to URI URI uri=file.toURI(); URL[] urls=&#123;uri.toURL()&#125;; FileUrlClassLoader loader = new FileUrlClassLoader(urls); try &#123; //加载指定的class文件 Class&lt;?&gt; object1=loader.loadClass(&quot;com.zejian.classloader.DemoObj&quot;); System.out.println(object1.newInstance().toString()); //输出结果:I am DemoObj &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940 非常简洁除了需要重写构造器外无需编写findClass()方法及其class文件的字节流转换逻辑。 自定义网络类加载器自定义网络类加载器，主要用于读取通过网络传递的class文件（在这里我们省略class文件的解密过程），并将其转换成字节流生成对应的class对象，如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Created by zejian on 2017/6/21. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class NetClassLoader extends ClassLoader &#123; private String url;//class文件的URL public NetClassLoader(String url) &#123; this.url = url; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassDataFromNet(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; /** * 从网络获取class文件 * @param className * @return */ private byte[] getClassDataFromNet(String className) &#123; String path = classNameToPath(className); try &#123; URL url = new URL(path); InputStream ins = url.openStream(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; // 读取类文件的字节 while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; //这里省略解密的过程....... return baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; // 得到类文件的URL return url + &quot;/&quot; + className.replace(&#x27;.&#x27;, &#x27;/&#x27;) + &quot;.class&quot;; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 比较简单，主要是在获取字节码流时的区别，从网络直接获取到字节流再转车字节数组然后利用defineClass方法创建class对象，如果继承URLClassLoader类则和前面文件路径的实现是类似的，无需担心路径是filePath还是Url，因为URLClassLoader内的URLClassPath对象会根据传递过来的URL数组中的路径判断是文件还是jar包，然后根据不同的路径创建FileLoader或者JarLoader或默认类Loader去读取对于的路径或者url下的class文件。 热部署类加载器所谓的热部署就是利用同一个class文件不同的类加载器在内存创建出两个不同的class对象(关于这点的原因前面已分析过，即利用不同的类加载实例)，由于JVM在加载类之前会检测请求的类是否已加载过(即在loadClass()方法中调用findLoadedClass()方法)，如果被加载过，则直接从缓存获取，不会重新加载。注意同一个类加载器的实例和同一个class文件只能被加载器一次，多次加载将报错，因此我们实现的热部署必须让同一个class文件可以根据不同的类加载器重复加载，以实现所谓的热部署。实际上前面的实现的FileClassLoader和FileUrlClassLoader已具备这个功能，但前提是直接调用findClass()方法，而不是调用loadClass()方法，因为ClassLoader中loadClass()方法体中调用findLoadedClass()方法进行了检测是否已被加载，因此我们直接调用findClass()方法就可以绕过这个问题，当然也可以重新loadClass方法，但强烈不建议这么干。利用FileClassLoader类测试代码如下： 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) throws ClassNotFoundException &#123; String rootDir=&quot;/Users/zejian/Downloads/Java8_Action/src/main/java/&quot;; //创建自定义文件类加载器 FileClassLoader loader = new FileClassLoader(rootDir); FileClassLoader loader2 = new FileClassLoader(rootDir); try &#123; //加载指定的class文件,调用loadClass() Class&lt;?&gt; object1=loader.loadClass(&quot;com.zejian.classloader.DemoObj&quot;); Class&lt;?&gt; object2=loader2.loadClass(&quot;com.zejian.classloader.DemoObj&quot;); System.out.println(&quot;loadClass-&gt;obj1:&quot;+object1.hashCode()); System.out.println(&quot;loadClass-&gt;obj2:&quot;+object2.hashCode()); //加载指定的class文件,直接调用findClass(),绕过检测机制，创建不同class对象。 Class&lt;?&gt; object3=loader.findClass(&quot;com.zejian.classloader.DemoObj&quot;); Class&lt;?&gt; object4=loader2.findClass(&quot;com.zejian.classloader.DemoObj&quot;); System.out.println(&quot;loadClass-&gt;obj3:&quot;+object3.hashCode()); System.out.println(&quot;loadClass-&gt;obj4:&quot;+object4.hashCode()); /** * 输出结果: * loadClass-&gt;obj1:644117698 loadClass-&gt;obj2:644117698 findClass-&gt;obj3:723074861 findClass-&gt;obj4:895328852 */ &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;123456789101112131415161718192021222324252627282930313233 双亲委派模型的破坏者-线程上下文类加载器​ 在Java应用中存在着很多服务提供者接口（Service Provider Interface，SPI），这些接口允许第三方为它们提供实现，如常见的 SPI 有 JDBC、JNDI等，这些 SPI 的接口属于 Java 核心库，一般存在rt.jar包中，由Bootstrap类加载器加载，而 SPI 的第三方实现代码则是作为Java应用所依赖的 jar 包被存放在classpath路径下，由于SPI接口中的代码经常需要加载具体的第三方实现类并调用其相关方法，但SPI的核心接口类是由引导类加载器来加载的，而Bootstrap类加载器无法直接加载SPI的实现类，同时由于双亲委派模式的存在，Bootstrap类加载器也无法反向委托AppClassLoader加载器SPI的实现类。在这种情况下，我们就需要一种特殊的类加载器来加载第三方的类库，而线程上下文类加载器就是很好的选择。​ 线程上下文类加载器（contextClassLoader）是从 JDK 1.2 开始引入的，我们可以通过java.lang.Thread类中的getContextClassLoader()和 setContextClassLoader(ClassLoader cl)方法来获取和设置线程的上下文类加载器。如果没有手动设置上下文类加载器，线程将继承其父线程的上下文类加载器，初始线程的上下文类加载器是系统类加载器（AppClassLoader）,在线程中运行的代码可以通过此类加载器来加载类和资源，如下图所示，以jdbc.jar加载为例 从图可知rt.jar核心包是有Bootstrap类加载器加载的，其内包含SPI核心接口类，由于SPI中的类经常需要调用外部实现类的方法，而jdbc.jar包含外部实现类(jdbc.jar存在于classpath路径)无法通过Bootstrap类加载器加载，因此只能委派线程上下文类加载器把jdbc.jar中的实现类加载到内存以便SPI相关类使用。显然这种线程上下文类加载器的加载方式破坏了“双亲委派模型”，它在执行过程中抛弃双亲委派加载链模式，使程序可以逆向使用类加载器，当然这也使得Java类加载器变得更加灵活。为了进一步证实这种场景，不妨看看DriverManager类的源码，DriverManager是Java核心rt.jar包中的类，该类用来管理不同数据库的实现驱动即Driver，它们都实现了Java核心包中的java.sql.Driver接口，如mysql驱动包中的com.mysql.jdbc.Driver，这里主要看看如何加载外部实现类，在DriverManager初始化时会执行如下代码 12345678910111213141516171819//DriverManager是Java核心包rt.jar的类public class DriverManager &#123; //省略不必要的代码 static &#123; loadInitialDrivers();//执行该方法 println(&quot;JDBC DriverManager initialized&quot;); &#125;//loadInitialDrivers方法 private static void loadInitialDrivers() &#123; sun.misc.Providers() AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; //加载外部的Driver的实现类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); //省略不必要的代码...... &#125; &#125;); &#125;12345678910111213141516171819 在DriverManager类初始化时执行了loadInitialDrivers()方法,在该方法中通过ServiceLoader.load(Driver.class);去加载外部实现的驱动类，ServiceLoader类会去读取mysql的jdbc.jar下META-INF文件的内容，如下所示 而com.mysql.jdbc.Driver继承类如下： 12345678910public class Driver extends com.mysql.cj.jdbc.Driver &#123; public Driver() throws SQLException &#123; super(); &#125; static &#123; System.err.println(&quot;Loading class `com.mysql.jdbc.Driver&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;. &quot; + &quot;The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.&quot;); &#125;&#125;12345678910 从注释可以看出平常我们使用com.mysql.jdbc.Driver已被丢弃了，取而代之的是com.mysql.cj.jdbc.Driver，也就是说官方不再建议我们使用如下代码注册mysql驱动 123456//不建议使用该方式注册驱动类Class.forName(&quot;com.mysql.jdbc.Driver&quot;);String url = &quot;jdbc:mysql://localhost:3306/cm-storylocker?characterEncoding=UTF-8&quot;;// 通过java库获取数据库连接Connection conn = java.sql.DriverManager.getConnection(url, &quot;root&quot;, &quot;root@555&quot;);123456 而是直接去掉注册步骤，如下即可 1234String url = &quot;jdbc:mysql://localhost:3306/cm-storylocker?characterEncoding=UTF-8&quot;;// 通过java库获取数据库连接Connection conn = java.sql.DriverManager.getConnection(url, &quot;root&quot;, &quot;root@555&quot;);1234 这样ServiceLoader会帮助我们处理一切，并最终通过load()方法加载，看看load()方法实现 12345public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; //通过线程上下文类加载器加载 ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125;12345 很明显了确实通过线程上下文类加载器加载的，实际上核心包的SPI类对外部实现类的加载都是基于线程上下文类加载器执行的，通过这种方式实现了Java核心代码内部去调用外部实现类。我们知道线程上下文类加载器默认情况下就是AppClassLoader，那为什么不直接通过getSystemClassLoader()获取类加载器来加载classpath路径下的类的呢？其实是可行的，但这种直接使用getSystemClassLoader()方法获取AppClassLoader加载类有一个缺点，那就是代码部署到不同服务时会出现问题，如把代码部署到Java Web应用服务或者EJB之类的服务将会出问题，因为这些服务使用的线程上下文类加载器并非AppClassLoader，而是Java Web应用服自家的类加载器，类加载器不同。，所以我们应用该少用getSystemClassLoader()。总之不同的服务使用的可能默认ClassLoader是不同的，但使用线程上下文类加载器总能获取到与当前程序执行相同的ClassLoader，从而避免不必要的问题。ok~.关于线程上下文类加载器暂且聊到这，前面阐述的DriverManager类，大家可以自行看看源码，相信会有更多的体会，另外关于ServiceLoader本篇并没有过多的阐述，毕竟我们主题是类加载器，但ServiceLoader是个很不错的解耦机制，大家可以自行查阅其相关用法。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"类加载","slug":"类加载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"}]},{"title":"数据库","slug":"数据库","date":"2019-04-08T01:23:24.000Z","updated":"2019-04-08T01:23:24.000Z","comments":true,"path":"2019/04/08/数据库/","link":"","permalink":"http://example.com/2019/04/08/%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"","text":"乐观锁和悲观锁 悲观锁 悲观锁对数据修改持有悲观态度，认为数据很容易被修改，所以在修改数据前会先给加锁，效率较低。 乐观锁 乐观锁假设一般情况下不会造成数据冲突，所它只在事务提交更新的时候，才去检测是否有冲突。如果冲突了则给用户返回一定的信息让用户自己去处理。 乐观锁并不是真正的加锁，通常，它可以通过版本号，或者时间戳等来判断是否发生了冲突。比如添加版本号，每次修改数据时都会带上版本号，如果执行更新时的版本号和我们刚刚查询出来的版本号一致，就可以执行更新，否则，就认为是过期的数据 。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"java虚拟机","slug":"java虚拟机","date":"2019-03-04T13:43:50.000Z","updated":"2023-05-29T14:17:39.387Z","comments":true,"path":"2019/03/04/java虚拟机/","link":"","permalink":"http://example.com/2019/03/04/java%E8%99%9A%E6%8B%9F%E6%9C%BA/","excerpt":"","text":"Java内存模型java运行时数据区域程序计数器线程私有的 Java虚拟机栈线程私有，存放局部变量，返回值地址等 本地方法栈线程私有，存放局部变量，返回值地址等 Java堆线程共享区域，几乎所有的对象实例都在这里分配内存。 方法区存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。 运行时常量池是方法区的一部分，用于存放编译期生成的各种字面变量和符号引用 直接内存NIO使用Native函数 库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByBuffer对象作为这块内存的引用进行操作。由于这样做避免了在Java堆和Native堆中来回复制数据，所以可以显著提高性能。 内存模型工作内存和主内存 volatile当一个变量被volitile关键字修饰时，它有两层语义： 可见性：一个线程对这个变量的更改会立即刷新到主内存中 禁止指令重排序：保证了有序性。 但是它不保证原子性，它能保证修改被立即写到主存，但是不能保证读到的值被立即修改，也就是原子性。对于非原子性的操作，比如自增操作，如果一个线程读入了变量的值，然后被阻塞，这时候这个线程其实是没有修改变量值的，那么也就不会使得其他线程缓存无效，这时候其他线程也读入这个值得时候，读入得其实是旧值。问题得根源就在于，volatile只能保证修改时立即可见，但是不能保证这个操作是原子性的，比如自增操作。如何解决这个问题呢？可以使用synchronized关键字。 使用volatile关键字，可以使得其他线程中对被修饰变量的拷贝无效，迫使它再次从主存中重新读取。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，volatile语句相当于一个屏障，它所处的位置是禁止指令重排序的，但是它前面和后面的代码块是可以分别指令重排序的。 然后推荐一篇很不错的博客： 内存模型的特征 原子性 可见性 有序性 sychronized关键字可以实现上述三种特性。 除了volatile之外，sychronized和final也可以实现可见性。 happens-before原则先行发生（happens-before）原则指的是java内存模型中定义的两个操作之间的先序关系。如果A先行发生于B，那么A操作所产生的影响就能被B观察到，这里的影响包括内存中共享变量值的修改，发送消息，调用方法等。 happens-before原则是对指令执行顺序性的保障，如果两个操作可以有下面的原则推导出来，说明这两个操作是存在顺序性的，可以在编码中直接使用。否则，虚拟机可以对他们重排序。 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。 管程锁规定：一个unlock操作先行发生于后面对同一个锁的lock操作。（后面指时间上的先后性） volatile变量规则: 对一个volitle变量的写操作先行发生于后面对这个变量的读操作。（后面指时间上的先后性） 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测。 线程中断规则: 对线程interrupt方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 对象终结操作：一个对象的初始化完成先行发生于它的finalize方法的开始。 传递性：如果A先行发生于B，B先行发生于C，那就可以得出A先行发生于C 先行发生原则和时间上的先后发生其实是没有关系的。一个操作时间上的先发生不代表这个操作是“先行发生”。反过来，一个操作是“先行发生”也不代表它是时间上先发生的，因为会有指令重排序。 GC所回收的区域指的是堆和方法区。 关于GC的灵魂拷问： 什么是垃圾 引用计数算法（Reference Couting） 添加一个引用计数器，当一个对象被引用时，计数器加一；引用失效时，计数器减一。引用为零，则是垃圾。 缺点：无法解决对象循环引用的问题。 可达性分析算法(Reachablity Analysis) 从一个叫做GC Root的对象作为起点，一直向下搜索，搜索走过的路径被称为Reference Chain, 那些不在这个引用链中的对象是不可达的，是垃圾。 那么问题来了，哪些对象被称为GC Root? 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI引用的对象 如何回收垃圾 标记-清楚算法 会产生大量的内存碎片 复制算法 我每次只用内存的一半，这一半用完后，把存活的对象挪到另一半，然后清理这一半。 缺点：只能用一半的空间，而且复制意味着修改对象的地址。 标记-整理算法 可以认为是结合了上述两种方法的优点，先标记，然后把存活对象往一段移动，清理另一端。 缺点：内存变动频繁，需要整理所有存活对象的引用地址，效率比复制算法低。 分代收集算法 集百家之长，对不同寿命的对象使用不同的算法收集。 将堆分为新生代和老年代，新生代对象朝生夕死，只有少量对象存活，所以我们采用复制算法。 回收策略Eden, from Survivor, to Survivor, Old 前三个都是新生代 对象首先都会被分配到Eden中，当Eden剩余空间不够用时，会触发一次Minor GC, 剩下的存活对象放到from Survivor, 如果from区不够，则放到Old. 继续新建对象，下一次Eden又不够用了，继续Minor GC，这次把Eden和from里面剩下的存活对象又放到to里面，如果不够放，继续放到Old. 特例除了上述所说，还有一些特殊情况： 大对象直接进入Old. 因为它比较大，你放到新生代的话，频繁的Minor GC要移动一个大块头是个很麻烦的事 长期存活对象进入Old. 有些对象一直在from区和to区来回蹦跶，我们给它一个年龄计数器，每蹦跶一次年龄加一，等到成年了就把它送到Old.这个年龄默认是15岁 动态对象年龄判定 JVM并不是严格要求说只有成年才能被送到Old. 如果Survior中相同年龄的对象占用了一半或者以上的空间，那么这些对象以及比他们年长的都会被送到Old. 因为它们太占地方了。 思考 为什么要有Survivor区而不是直接Eden和Old. 为了在进入Old之间缓冲一哈，不然Old会被很快填满，而且进入Old的对象指不定没过多久就变成垃圾了。 为什么要有两个Survivor区 这个其实是借鉴了复制算法的思想。两个Survivor来回倒腾，每次总有一个是空的，它可以很好的解决碎片化的问题。 关于引用 强引用（Strong Reference） 常见的Objec obj = new Object()就是强引用。 强引用所指的对象在任何时候都不会被系统回收。JVM宁愿抛出OOM异常，也不会回收强引用所指向的对象。 强引用可能导致内存泄漏 软引用（Soft Reference） 软引用是除了强引用之外，最强的引用类型。 在内存紧张的情况下，软引用会被回收。 弱引用（Weak Reference） 系统GC时，只要发现弱引用，就会被回收。 弱引用和软引用都适合用来保存一些可有可无的缓存数据。 虚引用（Phantom Reference） 虚引用是四个里面最弱的，如果说软引用和弱引用是弟弟，那么虚引用就是弟中弟。 一个对象持有虚引用，和没有持有几乎是一样的，因为虚引用随时可能会被GC回收，那么虚引用的作用在哪里呢？它主要用在垃圾回收过程中。虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之 关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 类加载机制类加载的生命周期加载 验证 准备 解析 初始化 各种类加载器启动类加载器 拓展类加载器（ExtClassLoader） 系统类加载器（AppClassLoader） 自定义类加载器 类初始化的时机以下五种情况下会进行类的初始化 （1） （2） （3） （4） （5） 这五种情况称之为对类的主动引用，除这五种之外，所有引用类的方式都不会触发初始化，成为被动引用。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Java虚拟机","slug":"Java虚拟机","permalink":"http://example.com/tags/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"矩阵","slug":"矩阵","date":"2019-03-03T06:01:35.000Z","updated":"2019-03-03T06:01:35.000Z","comments":true,"path":"2019/03/03/矩阵/","link":"","permalink":"http://example.com/2019/03/03/%E7%9F%A9%E9%98%B5/","excerpt":"","text":"如何理解矩阵范数在一维或者二维的世界里，我们有映射（或者函数），一个值通过一个映射关系（或函数）变成了另一个值，这时候一个函数就代表了这种映射关系。在这个情况下，我们的自变量，是一维的，是一个数。 当情况上升之后，当自变量是二维呢，比如说，自变量是一个向量。这时候，这种映射关系（或者函数关系）可以用矩阵来表示。一个向量，作用在这个矩阵上，变成了另一个向量。 而范数（norm），也就是我们说的模，其实它是带有“长度”的概念的，它是表示这个变化过程大小的一个度量，它用来表示这个矩阵的某种大小。它是一个函数，它把不能比较大小的向量（矩阵）转化成实数，这样就可以用来比较大小了。 也可以认为，矩阵是一种力，它作用在一个向量（或者矩阵）上面，会改变他们的一些属性，比如大小，方向。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"java多线程","slug":"java多线程","date":"2019-01-20T04:56:25.000Z","updated":"2023-05-29T14:17:39.390Z","comments":true,"path":"2019/01/20/java多线程/","link":"","permalink":"http://example.com/2019/01/20/java%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"ThreadlocalThreadLocal是一个支持泛型的类，它为每个线程提供局部变量，这种变量是其他线程访问不到的，实现了线程的数据隔离。 线程间隔离，方法间共享 内部方法set12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 获取当前线程，获取当前线程的ThreadLocalMap,然后存储键值对。这里需要注意Thread中是由一个类型为ThreadLocalMap的变量threadLocals,其中ThreadLocalMap就是一个定制的hashmap. get1234567891011121314151617181920212223242526272829public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; protected T initialValue() &#123; return null; &#125; remove12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 正常来讲，ThreadLocal对象会在每个线程里面 创建一个变量副本，线程间是不可互相访问这些变量的，但是在有些情况下，我们需要在子线程中也能访问父线程中的变量，这时候可以使用InheritableThreadLocals类，当父线程创建子线程时，父线程中inheritalbeThreadLocals变量里的本地变量复制一份保存到子线程的inheritableThreadLocals变量里面， 但是复制过来以后，他们也是互相独立的副本了，修改起来互不相干。 总结ThreadLocal类通过操作Thread类里面的ThreadLocalMap类型的变量，来实现线程私有变量的访问。真正私有变量是放在这个定制的hashmap里被维护的。 Java线程中断会有这种情况，由于某种需求你需要一个子线程去执行某些任务，但是这个任务可能在中途由于其他因素需要被中断或者中止，对于这种情况，就需要用到java的线程中断的方法了。 interrupt()方法准确的讲，interrupt()方法并不是真正的中断线程，它的真正作用是修改线程中的标志位，然后我们根据标志位，手动的去中断这个线程（后面会讲到可能是根据标志位也可能是根据线程抛出的异常去手中断线程）。 1234567891011121314public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0(); &#125; 这里我贴了一段源码，如果没猜错的话，这个interrupt0()方法就是用来修改标志位的。 interrupt()方法可以用来中断线程，根据所要中断的线程是阻塞的或者是非阻塞的，做法不同。 如果要中断的线程是被wait(),sleep(),join()方法阻塞，那么中断状态会被清除并且抛出一个InterruptedException异常。 什么意思呢？上文中我们讲到interrupt()方法其实修改的是线程的中断标志位，而非真正中断线程。在这里可以看到，如果要中断的线程是被这些方法阻塞的，当我们调用interrupt()方法时，虽然标志位会被修改，但是我们是察觉不到的，因为它又会被clear掉，也就是被重新置为false,所以在这种情况下，我们要去中断线程的话，就得catch这个异常，然后在catch中操作了。 如果要中断的线程是通过InterruptibleChannel被I/O操作阻塞的话，标志位会被修改为true,同时会抛出ClosedByInterruption异常。 对于这种情况我没有进行尝试，但是从字面意思来看，我们应该既可以从标志位入手去中断线程也可以从异常入手去做。 如果线程被Selector阻塞，那么通过interrupt()中断它时；线程的中断标记会被设置为true，并且它会立即从选择操作中返回 如果不属于前面所说的情况，那么通过interrupt()中断线程时，它的中断标记会被设置为“true” 上面的操作都提到了标志位，那么标志位怎么获得呢？ interrupted():静态方法，调用它时，标志位会被清除。这意味着如果你连着调用两次这个方法，那么第二次结果肯定是false. isInterrupted()：非静态方法，调用它时，标志位不会被清除。 下面是一个例子，相关说明已经写在了注释里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import static java.lang.Thread.sleep;public class ThreadTest &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new MyThread1(); Thread t2 = new MyThread2(); t1.start(); t2.start(); System.out.println(&quot;after two minutes thread one interrupt&quot;); try &#123; sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; t1.interrupt(); t2.interrupt(); Thread.sleep(3000); System.out.println(&quot;in main &quot; + t1.getName() + &quot; &quot; + t1.getState() + &quot; &quot; + t1.isInterrupted()); System.out.println(&quot;in main &quot; + t1.getName() + &quot; &quot; + t2.getState() + &quot; &quot; + t2.isInterrupted() ); &#125;&#125;/** * 非阻塞型线程，通过判断标志位来实现线程中止 */class MyThread1 extends Thread &#123; @Override public void run() &#123; for (; ; ) &#123; System.out.println(&quot;in &quot;+getName()); if (isInterrupted()) &#123; /** * 下面调用了一次interrupted()方法，标志位被清除，所以再次调用isInterrupted()方法时为false */ System.out.println(getName() + &quot; &quot; + getState() + &quot; &quot; + interrupted()+&quot; &quot;+isInterrupted() ); break; &#125; &#125; &#125;&#125;/** * 阻塞型线程，通过异常来终止 */class MyThread2 extends Thread &#123; @Override public void run() &#123; try &#123; for (; ; ) &#123; System.out.println(&quot;in &quot;+getName()); sleep(500); &#125; &#125; catch (InterruptedException e) &#123; System.out.println(getName() + &quot; &quot; + getState() + &quot; &quot; + isInterrupted()); e.printStackTrace(); &#125; &#125;&#125; Java线程池我们通常使用的一种创建线程池的方式： 1ExecuttorService executorService = new ThreadPoolExecutor(1,1,60,TimeUnit.SECONDS,new ArrayBlockingQueue&lt;&gt;(10)); 它的构造函数是这样的： 123456public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) 其中： corePoolSize: 核心线程数量 maximumPoolSize:最大线程数数量 keepAliveTime:那些超过核心线程数数量的的线程如果在这个时间内没有被执行，就会被回收。 unit:上一个参数的时间单位。 workQueue:用来存储等待执行的任务。 hander:拒绝任务处理时的策略。 看ThreadPoolExecutor的定义，可以发现它继承了AbstractExecutorService 1public class ThreadPoolExecutor extends AbstractExecutorService 再来看下AbstractExecutorService的定义: 1public abstract class AbstractExecutorService implements ExecutorService 它实现了ExecutorService接口 再来看下ExecutorService接口 1public interface ExecutorService extends Executor 它实现了Executor接口： 123public interface Executor&#123; void execute(Runnable command)&#125; 我们来画下它们的类图 可以看出，Executor是最顶层的接口。 解下来我们来看下ThreadPoolExecutor里面的一些变量和方法. 首先是ctl相关的： 123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) &#123; return c &amp; ~COUNT_MASK; &#125; private static int workerCountOf(int c) &#123; return c &amp; COUNT_MASK; &#125; private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ctl这个变量其实是个组合变量，用它来表示线程数量workerCount和线程工作状态runState。 从下面几行可以看出来，线程状态有五种，那么就需要三个比特位来表示，剩下的Integer.SIZE-3也就是29位用来表示线程数量，一共能表示$2^{29}-1$个线程。第三行则是通过位运算来计算掩码，掩码是长度为29 bit的1。 所以现在的情况是这样的，ctl一共有32位，高三位用来表示线程池运行状态，低29位用来表示线程数量。 下面看下这几个拆解ctl的方法： 1private static int runStateOf(int c) &#123; return c &amp; ~COUNT_MASK; &#125; 这个方法是为了获取运行状态。掩码是29个1，取非，29个0，与ctl与运算，得到ctl的高三位+29个0，正好和上面几行的runState的左移对应起来。 1private static int workerCountOf(int c) &#123; return c &amp; COUNT_MASK; &#125; 这个方法用来获取线程数量，与的结果就是ctl的低29位。 1private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 这个方法runState和workerCount来组合出一个ctl 再来看下execute方法： 它的代码如下： 12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 我们分批来看这块代码： 123456int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; 首先，获得当前线程数，如果小于corePoolSize，那么就添加新的线程去执行任务。如果添加线程成功了，直接return,否则，重新获得ctl的值，继续下面的判断。 1234567if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; 在执行这个代码块时我们需要注意，来到第二个代码块时，第一个代码块的判断条件可能是workerCount大于等于corePoolSize,也可能是addWorker失败。如果线程池isRunning,则尝试向workQueue中添加任务，如果添加成功，重新获得ctl值，double check 线程池是否running,如果此时线程池没有running，则remove掉当前任务，并且执行reject. 如果线程池在运行，或者remove失败，检查workerCount是否为0，如果为0则添加一个空的thread. 12else if (!addWorker(command, false)) reject(command); 如果添加核心线程失败，则直接拒绝。 这个可能看着有点迷，先看下里面的addWorker方法 //有空再写吧 这里推荐一篇讲的很仔细的博客：https://mp.weixin.qq.com/s/-89-CcDnSLBYy3THmcLEdQ Java中的锁图片来自美团技术团队博客 这些分类更多的是按照锁的特性和设计来分类的，并不是说真真正正的有这么多的锁。 下面我会介绍Java中的synchronized 、 reentrylock等锁，以及它们分别属于哪些类别。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"直面Java","slug":"直面Java","date":"2019-01-12T12:49:24.000Z","updated":"2019-01-12T12:49:24.000Z","comments":true,"path":"2019/01/12/直面Java/","link":"","permalink":"http://example.com/2019/01/12/%E7%9B%B4%E9%9D%A2Java/","excerpt":"","text":"魔数常量值 比如说用来标识文件类型 JIT​ JIT(Just in time compiler). ​ 前提： ​ 1. java文件是先被编译成字节码（也就是class文件）然后才载入JVM的​ 2. JVM中既有解释器又有编译器 ​ 及时编译技术就是说，在JVM解释（用的是解释器）执行字节码的时候，遇到一些热点代码（也就是经常被重复执行的代码，具体怎么算重复执行后面有讲到）时，会把它编译成和本地平台相关的机器码去执行。 ​ 这里你可能会有疑问： 为什么遇到热点代码时要把他们翻译成本地机器码？ 答：因为JVM执行机器码的速度要比解释执行快得多，遇见这种重复执行很多次的代码，把它翻译成机器码是明智的。 为什么不全部编译？ 答：因为编译也费时间啊，尤其当工程很大的时候。而且，如果我们在执行前把Java文件全部编译成机器码的话，那它还和C++有什么区别，它的跨平台性又体现在哪里？ ​ java文件首先被编译成字节码，也就是class文件，class文件被虚拟机装载以后，会以解释模式运行一段时间，当发觉某些代码运行比较频繁（这里有两种度量方式）时，就会对这些代码进行优化。 从上图可以看出，JVM中有解释器和编译器，解释器将字节码解释执行，比较慢。尤其当有一部分代码运行的特别频繁，如循环，这时候使用解释器来解释执行就更慢了。而JIT的作用也就体现在这里。代码解释执行的时候，它先暗中观察一段时间，从而发现热点代码“Hot Spot Code”，把它编译成和本地平台相关的机器码（编译由后台线程去执行），并进行各个层次的优化。这里的热点代码有两类： 多次调用的方法 多次调用的循环体 那么如何发现热点代码呢，这就需要用到热点探测“Hotpot Detection”,目测的探测方法有两种： 基于采样的热点探测：周期性的检查每个线程的栈顶，那些经常出现在栈顶的方法就是热点代码。 优点：容易获得方法调用关系 缺点：不精确 基于计数器的热点探测：更为严谨，它为每个方法或者代码块建立计数器，如果计数超过某个阈值，那么这个方法（代码块）就是热点代码。 优点：精确 缺点：比较麻烦，需要为每个方法或代码块建立计数器 HotSpot中使用第二种，它为方法和循环体分别设定了方法计数器和回边计数器。 那么问题来了，编译后的本地机器码放在了哪里？ JIT编译器分client模式和server模式。server模式启动慢，但是启动后性能高，适合于大型的服务器后台程序；client启动快，但性能不如server模式，适合于桌面程序等。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Python学习笔记","slug":"python学习笔记","date":"2018-10-13T07:33:11.000Z","updated":"2020-05-31T04:35:04.000Z","comments":true,"path":"2018/10/13/python学习笔记/","link":"","permalink":"http://example.com/2018/10/13/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"语句 while循环，for循环，if语句 不需要括号，后面需要加冒号 定义函数语句 ： def fun(a,b): ​ 注：参数可以设置为默认值 定义全局变量： 定义在函数外部或者用内部global修饰","text":"语句 while循环，for循环，if语句 不需要括号，后面需要加冒号 定义函数语句 ： def fun(a,b): ​ 注：参数可以设置为默认值 定义全局变量： 定义在函数外部或者用内部global修饰 模块安装 sd 函数 默认参数 函数可以有默认参数，但是默认参数必须指向不变对象 可变参数 意味着可以传入任意多个参数，在调用时自动组装成一个tuple,在参数前面加个*号，在一个list或者tuple前面加个 *号，意味着将list或tuple元素拆解成多个可变参数传入 关键字参数 关键字参数允许传入任意个含参数名的参数，这些关键字参数在函数内部自动组装成一个dict 1234def person(name,age,**kw): print(&#x27;name&#x27;,name,&#x27;age&#x27;,age,&#x27;other&#x27;,kw)person(&#x27;Jack&#x27;,24,**&#123;&#x27;city&#x27;:&#x27;Beijing&#x27;,&#x27;job&#x27;:&#x27;Engineer&#x27;&#125;)&gt;&gt;&gt; name Jack age 24 other &#123;&#x27;job&#x27;: &#x27;Engineer&#x27;, &#x27;city&#x27;: &#x27;Beijing&#x27;&#125; 命名关键字参数 顾名思义，限制关键字参数的名字，比如说我只允许传入city和job关键字，那么 1person(name,age,*,city,job) 果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了 1person(name,age,*args,city,job) 高级特性 切片 12345l=list(range(0,100,1))L[0:3]表示取出索引0到索引2的所有元素l[:10] //取出前十个元素l[-10:] //取出后十个元素l[:10:2] //前十个数每两个取一个 列表生成式 123[x*x for x in range(1,11)]d = &#123;&#x27;x&#x27;:&#x27;A&#x27;,&#x27;y&#x27;:&#x27;B&#x27;,&#x27;z&#x27;:&#x27;C&#x27;&#125;[k+&#x27;=&#x27;+v for k,v in d.items()] 生成器 一边循环一遍计算的机制 定义方法一 123456&gt;&gt;&gt; l = [x*x for x in range(1,11)]&gt;&gt;&gt; l[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&gt;&gt;&gt; g = (x*x for x in range(1,11))&gt;&gt;&gt; g&lt;generator object &lt;genexpr&gt; at 0x000001EF9005A5C8&gt; 相比于列表生成器，唯一的不同就是() 定义方法二 yield关键字，以斐波那契数列为例 1234567891011121314151617&gt;&gt;&gt; def fib(max): n,a,b = 0,0,1 while n&lt;max: yield b a,b = b,a+b n=n+1 return &#x27;done&#x27;&gt;&gt;&gt; for i in fib(6): print(i) 112358 如果把这里的yield换成print，那fib()就是个函数，这里yield关键字的作用是，生成器每次执行到这里返回，下次执行时接着这里执行 Interable Interator 可以作用于for循环的成为Interable 可以被next()函数调用并不断返回下一个值的叫做Interator 可以用isInstance()判断一个对象是否是Interator对象 Interator的计算是惰性的，只有需要下一个值时它才会计算 函数式编程允许将函数作为一个参数传给函数 高阶函数 map/reduce map map(function,Interator),map将function作用于Interator的每个元素，生成一个新的Interator 1234567&gt;&gt;&gt; map(abs,[-1,-2,-3,-4])&lt;map object at 0x000001EF9006C518&gt;&gt;&gt;&gt; r = map(abs,[-1,-2,-3,-4])&gt;&gt;&gt; r&lt;map object at 0x000001EF9006C278&gt;&gt;&gt;&gt; list(r)[1, 2, 3, 4] 也就是一种映射 reduce reduce(function,Interator)，reduce可以认为是一种归纳或者迭代 123&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; reduce(add,[1,2,3,4])10 filter 同样接收两个参数 sorted sorted([...],key=function)先按照key所指的函数对list处理，对处理后的结果排序，然后把排序好的结果映射到原来的list并返回 文件读写 写文件： 123file = open(&quot;filename&quot;,&quot;openMethod&quot;)file.write()file.close() 读文件： 1234file = open()context = file.read()//其他形式file.readline()或file.readlines()file.close() class 类 定义： 123456class Calculator : name = &#x27;Good Calculator&#x27; price = 18 def __init__(self,name,price) def add(self,x,y): return x+y 声明： calcu = Calculator(); 注： 与java不同的是python定义方法时必然有一个self参数，相当于java中的this,且在方法中使用属性时需要用 self.name 函数init()相当于构造函数，用于初始化属性，也是最先执行的方法，比较奇怪的是它这里并没有像java中那样和类名同名 属性必须初始值，不然会报错 元组，列表，字典，集合 元组 tuple = (…) 圆括号,相比于列表，元组一旦初始化就不可改变 列表 list= […] 方括号123456789list.append(element) #追加list.insert(index,element) #插入list.remove(element) #删除第一次出现的该元素list[-1] #表示最后一个元素list[0:3] #从第0个元素到第三个元素（不包括第三个）list.index(element) #返回第一次出现该元素的索引list.count(element) #返回list中该元素的个数list.sort() #对list进行升序排序并覆盖原来的listlist.sort(reverse=True) #对list降序排序 多维列表123multi_dim_list = [[1,2,3],[4,5,6],[7,8,9]]print(multi_dim_list[0])print(multi_dim_list[0][2]) 字典 无序的容器，可存储任意类型对象，每个元素分别又由键：值构成，键必须唯一，值可不唯一，且类型可多样，键类型也可多样。无论是添加还是删除元素，都是通过键来索引值 123456789101112d = &#123;1:&#x27;a&#x27;,2:&#x27;b&#x27;&#125;print(d)print(d[1])del d[1]print(d)d[3]=&#x27;c&#x27;print(d)d[4] = &#123;1:3,2:4&#125;d[5] = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]print(d)d[&#x27;a&#x27;]= 1print(d) 集合 set可以看成数学意义上的无序和无重复元素的集合，set里存放的是不可重复的键 模块1. import模块 + import time + import time as t 自己重新定义模块名 + from time import time,localtime 只import自己想要的功能 + from time import * import该模块所有功能 try语句123456try: .....except Exception as e: ....else: .... map zip lambda zip 将两个list用于纵向的合并,如： 12a=[1,2,3] , b=[4,5,6]print(list(zip(a,b))) 输出：[(1, 4), (2, 5), (3, 6)] lambda lambda用于定义一个简单的函数，简化代码,如： 12res = lambda x,y : x+yprint(res(2,5)) 输出：7 map 用于绑定函数与参数，如：list(map(fun,1,2))注：参数须为列表形式 copy &amp; deepcopy a = list[1,2,3] , 如果 b = a , 则a和b指向的是同一内存空间，这时候如果用 b = copy.copy(a) (因为copy是一个模块，所以需要先引入这个模块import copy), 则会开辟新的内存空间，如果输出 id(a) == id(b) ,则是false.但是需要注意这里的copy是浅复制(shallow copy),也就是说只会复制list中的一层到新的内存空间，如果list是这种形式：a = list[1,2,[3,4]],那么执行copy后前两个元素 会被复制到新的内存空间，而第三个元素则被共享，这时候就需要deepcopy发挥作用了，使用它则是完完全全的复制 冒号的用法把冒号放在数组中，主要起到分片的作用， 1234567891011121314&gt;&gt;&gt; a = &#x27;hello&#x27;&gt;&gt;&gt; a[1:3]&#x27;el&#x27;&gt;&gt;&gt; a[::]&#x27;hello&#x27;&gt;&gt;&gt; a[:]&#x27;hello&#x27;&gt;&gt;&gt; a[:1]&#x27;h&#x27;&gt;&gt;&gt; a[1:]&#x27;ello&#x27;&gt;&gt;&gt; a[-1]&#x27;o&#x27;&gt;&gt;&gt;","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"论文总结","slug":"论文总结","date":"2018-07-16T02:40:04.000Z","updated":"2023-05-29T14:17:39.392Z","comments":true,"path":"2018/07/16/论文总结/","link":"","permalink":"http://example.com/2018/07/16/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/","excerpt":"","text":"CROWDSOURCE-BASED SIGNAL STRENGTH FIELD ESTIMATION BYGAUSSIAN PROCESSES the authors apply a Gaussian Process (GP) to model the RSS(received signal strength), and for estimation they use measurements from known locations，which based on a log-normal path loss model and perfectly knowledge of the user locations. In this paper, the author proposed an extended GP implementation and took into account the inaccuracy of user locations and unknown of path loss exponent. The parameters of the path loss Gaussian are estimated according to the empirical Bayesian approach. Steering Crowdsourced Signal Map Construction via Bayesian Compressive Sensing incentive mechanism is essential challenges: missing value inference crowdsourcing quality estimation incentive mechanism (incentive distribution map) cost and reward ? how to construct projection matrix (using correlations) mentioned: auction-based incentive designs RMapCS: Radio Map Construction From Crowdsourced Samples for Indoor LocalizationUse site survey to construct a radio map offline radio map construction, Online fingerprinting localization Challenges: Inaccurate sample annotation Measurement device diversity Nonuniform spatial distribution Quality-Aware Sparse Data Collection in MEC Enhanced Mobile Crowdsensing Systems将边缘计算和群智感知结合起来： 边缘节点进行一部分的计算，推断出未采样格子的状态，降低冗余和向服务器传输的数据量。 边缘节点能够实时感知用户移动模式，从而判断当前区域的参与者密度并进行调节。 在云端： 通过压缩感知恢复数据","categories":[{"name":"学术","slug":"学术","permalink":"http://example.com/categories/%E5%AD%A6%E6%9C%AF/"}],"tags":[]},{"title":"设计模式","slug":"设计模式","date":"2018-07-15T08:07:59.000Z","updated":"2023-05-29T14:17:37.594Z","comments":true,"path":"2018/07/15/设计模式/","link":"","permalink":"http://example.com/2018/07/15/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"单例模式 使用场景：有些情况下，我们只需要一个实例，比如说：点击按钮之后的弹框，应该是点击多次也只弹一次，而不是点击一次弹一次。这种情况就需要用到单例模式，从功能上讲，单例模式用于那些只需要一个实例的场景；从资源上讲，单例模式可以避免对象频繁的创建和销毁。 如何实现：构造方法私有，通过getInstance()方法来获得实例。 实现代码 懒汉式，线程不安全 所谓懒汉式，就是说并没有在定义intance的时候就给它初始化，因为懒，只有到第一次用到这个实例的时候才去初始化。懒汉模式是一种lazy-loading，只有到用的时候才会创建，从而也就会有个问题，第一次使用的时候创建可能会比较耗时。如果我们知道这个对象肯定是要被用到的，可以用饿汉模式，下面会说到。 但是很显然在多线程环境下是会出问题的，如果两个线程同时执行到了if(instance==null)，然后发现都成立，就会new出两个实例来。 12345678910public class SingleObject&#123; private static SingleObject instance ; private SingleObject()&#123;&#125;; private static SingleObject getInstance()&#123; if(instance == null)&#123; instance = new SingleObject() ; &#125; return instance ; &#125;&#125; 懒汉式，线程安全 这种方法在第一次调用时才初始化，避免浪费内存。但是需要加锁才能保证单例，会影响效率。因为只有new的时候，也就是第一次初始化的时候才需要并发控制，其他情况下是不需要并发控制的，但是给这个getInstance()方法加上synchronized关键字，会导致每次需要获得单例的时候都会被加锁。 12345678910public class SingleObject&#123; private static SingleObject instance ; private SingleObject()&#123;&#125;; private static synchronized SingleObject getInstance()&#123; if(instance == null)&#123; instance = new SingleObject() ; &#125; return instance ; &#125;&#125; 可以看出这种方式一个问题就是，锁的粒度太大了，其实只需要在new对象的时候加锁就可以了，这就引出了下面双重校验锁。 饿汉式，线程安全 所谓饿汉，就是说在类加载的时候就初始化。它这里其实是利用了类加载机制，类加载的时候是会用synchronized关键字给加锁的。未实现lazy-loading. 1234567public classs SingleObject&#123; private static SingleObject instance = new SingleObject() ; private SingleObject()&#123;&#125;; private static SingleObject getInstance()&#123; return instance ; &#125;&#125; 饿汉变种 123456789public class Singleton&#123; private static class SingletonHolder&#123; private static final Singleton instance = new Singleton() ; &#125; private Singleton()&#123;&#125; public static final Singleton getInstance()&#123; return SingletonHolder.instance ; &#125;&#125; 同样是利用类加载机制，同样是饿汉，但是它实现了lazy-loading。类加载的时候Singleton被装载，但是instance不一定被初始化，只有调用getIntance()方法的时候，才会显式装载SingletonHolder类，从而实例化instance 双重校验锁 123456789101112131415public static SingleObject&#123; private volatile static SingleObject instance ; private SingleObject()&#123;&#125;; private static SingleObject getInstance()&#123; if(instance == null)&#123; synchronized(Singleton.class)&#123; if(instance==null)&#123; instance = new SingleObject() ; &#125; &#125; &#125; return instance ; &#125;&#125; double check在代码中已经体现的很明显了，这里主要解释一下volatile关键字。在jvm的文章中，我们已经提到volatile关键字可以保证可见性、禁止指令重排序。它用在这里的的主要作用也是为了保证禁止指令重排序，在初始化一个实例的时候，要经过一下几个步骤 （1）申请内存空间 （2）初始化默认值（注意不是构造方法的初始化） （3）执行构造方法 （4）连接引用和实例 其中步骤（3）对应new SingleObject()，步骤四对应instance=new SingleObject()，这四个步骤可能会进行指令重排序，变成（1）（2）（4）（3），这种情况下，上述代码执行完后可能会return一个还没有初始化完的实例，另一个线程获取时，就会获取到一个未初始化完的对象。而使用了volatile关键字后，可以禁止指令重排序，那么执行的顺序就是(1)(2)(3)(4)，就不会存在上述问题。 静态内部类 123456789public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 枚举 CAS IteratorIterator本身是个Interface,被很多集合类所实现，我们也可以自己实现。 使用Iterator的一个好处就是我们可以不用去关注序列本身具体的结构，只用操作Iterator就可以实现序列的遍历。 如何实现在集合类内部实现一个Iterator接口，在这个实现的接口里面对集合类进行访问。而外部类想要访问集合中的元素时，只需要给它返回一个Iterator对象，然后通过Iterator的next()和hasNext()方法来访问集合元素。 这样做的一个好处：可以不对外部类暴露集合内部情况。 这里是代码部分 其实感觉设计模式的核心就是实现功能的解耦，让每个部分各司其职，而不是一锅大杂烩。 Visitor当对象结构对应的类很少改变，但经常需要在此结构上定义很多不同且不相关的操作，为了不让这些操作污染这些对象的类，我们将这些操作封装在另一个类中，而在被访问的类中只提供一个接待访问者的接口accept(Visitor),在Visitor()中传入被访问类的引用供访问。 类似于有人来你家做客，你只负责给他开个门（被访问的类提供一个accept()接口让visitor进来），他来到了你家，对你家的结构很清楚了（visit方法有一个被访问对象作为参数），至于客人具体要做什么，完全自便（具体的visit()方法的内容由Visitor定）。 这种设计的好处： 很好的解耦了访问者和被访问者 给被访问者提供了很大的自主操作的空间。 ComputerPart 接口 12345package Visitor;public interface ComputerPart &#123; void accept(ComputerPartVisitor visitor) ;&#125; ComputerPart实现类 12345678910111213141516171819202122232425262728package Visitor;public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor visitor) &#123; visitor.visit(this); &#125;&#125;package Visitor;public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor visitor) &#123; visitor.visit(this); &#125;&#125;package Visitor;public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor visitor) &#123; visitor.visit(this); &#125;&#125; Visitor接口 123456package Visitor;public interface ComputerPartVisitor &#123; void visit(ComputerPart computerPart) ;&#125; Visitor接口实现类 1234567891011package Visitor;public class ComputerPartVisitorImp implements ComputerPartVisitor &#123; @Override public void visit(ComputerPart computerPart) &#123; System.out.println(&quot;visit &quot;+computerPart.getClass()); &#125;&#125; 当我们需要访问更多对象时，可以在Visitor中多重载几个visitor函数即可。 Composite也叫做部分-整体模式，把对象组合成树形结构，将个体对象（叶子）和组合对象（树枝）统一对待。 它是一种嵌套的关系，就像目录树一样，一个文件夹套一个文件夹，直到最后的叶子节点——文件；或者像一句话一样，从句子到单词再到最后的字母；还有HTML标签，等等。 当我们想忽略组合对象与个体对象的不同，统一使用组合结构中的所有对象时，可以考虑这种设计模式。 Implementing the composite pattern lets clients treat individual objects and compositions uniformly. 如何解决：树枝和叶子实现统一接口，树枝内部组合该接口。 关键代码：树枝内部组合该接口，并且含有内部属性 List，里面放 Component 一般来讲，组合模式的Composite里面会有一个Arraylist，add方法既可以向其中添加Leaf，也可以添加composite,这里就体现了个体和组合对象的统一对待。 这里是相关代码实现，代码中除了add方法能体现该思想外，printList方法也能体现，对于File的print,只是简单的打印，对于Directory的print则是通过迭代器，去打印其每一个item，这里其实是个递归调用，如果item是file,那么就调用了File的·printList方法，如果item是directory,则递归调用。 Adapter适配器模式，顾名思义，就像电源适配器一样，你需要对已有的东西进行一定的改装，使他适配于新的需求。 比如说我原本就有一个现成的类，现在有一个新项目，也能用到这个类，但是需要稍作修改（旧类的接口不符合新系统的需要）。 再具体一点，新类A想用旧类B中的一些方法，但是得需要修改一下，因为这些方法不能完全满足现在的需求。有这么几种想法： 直接修改旧类B （这个方法很暴力） 新类A继承旧类B （Java中类只能单继承，而且这两个类逻辑上也不是继承关系，如果继承并覆盖的话还不如重新实现） 适配器模式 （通过一个中间件把类A的东西转化成类B的） 适配器模式就像生活中的电源适配器一样，能够连接两头并且进行转换。举个栗子，比如说有个Chinese类，他能speak和write，但是都是中文，后来，需求改变，又需要再写一个American,他也能speak和write,但是是英文。那么问题来了，如果重新写一个类的话，其实很多代码都是和Chinese相同的，这时候就需要适配器模式了。适配器模式有两种实现方法 继承已有类，实现目标接口 依赖已有类（将已有类作为自己的元素），实现目标接口 这里实例一个依赖的实现 Chinese类 12345678910Public class Chinese&#123; public String write()&#123; System.out.println(&quot;我正在写汉字&quot;); return &quot;我正在写汉字&quot; ; &#125; public String speak()&#123; System.out.println(&quot;我正在说汉语&quot;); return &quot;我正在说汉语&quot; ; &#125;&#125; American接口 1234Public interface American&#123; public void writeEnglish(); public void speakEnglish();&#125; 适配器 1234567891011121314151617181920212223Public class TranslatorAdapter implement American&#123; Chinese chi ; public TranslatorAdapter(Chinese chi)&#123; this.chi = chi ; &#125; @Override public void writeEnglish()&#123; System.out.println(translate(chi.write())); &#125; public void speakEnglish()&#123; System.out.println(translate(chi.speak())) ; &#125; public String tranlate(String sentence)&#123; if(sentence.equal(&quot;我正在写汉字&quot;)) return &quot;I am speak English&quot; ; return &quot;I am writing English&quot; ; &#125; &#125; 测试类 12345Pulic class Test&#123; public static void main(String[] args)&#123; TranslatorAdapter adapter = new TranslatorAdapter(new Chinese()) &#125;&#125; Template Method PatternTemplate Method模式用到了抽象类，用一句话总结它的特点就是：父类中定义处理流程的框架，子类中实现具体的处理。模板顾名思义，就是提供了一个模板，最后的模具和它的形状相同（子类继承父类），但是但是不同的模具用的材料可能不同（继承自抽象父类的子类的实现方法不尽相同） 这里是一个简单的demo,需要注意两个问题 模板使用final关键字修饰，不可改变 具体方法延迟到子类中去实现 Simple Factory Pattern模式动机假设这样一种场景：有一个父类按钮Button, 这个父类按钮底下继承了很多不同形状的子类按钮，圆形的，正方形的，三角形的。。。现在客户端程序想要用这些按钮，一种方法是你说明要哪种按钮，然后在客户端中new出来，但是显然这样耦合度比较高，因为在客户端中我们想用就完事了，而不想多余的先判断，再new. 另一种可行的办法是，我们再重新建一个类，叫做工厂类，当客户端中想要什么类型的按钮时，就跟工厂类讲，比如客户端需要一个圆形按钮，它不需要知道这个按钮的类名叫什么，它只需要告诉工厂类，我需要一个圆形按钮，工厂类造好给它就可以了。 这就是简单工厂模式，就是说有一个专门的工厂类用来生产一堆大差不差的子类，外部只需要告诉它要什么类，它生产好了再交给外部。 UML再偷一张菜鸟教程的图嘿嘿嘿 这个很容易理解，就不写代码了 要说简单工厂模式和策略模式的区别，工厂模式生产的是类，而策略模式注重的是策略，也就是方法， 工厂类根据不同的需求返回不同的类，策略模式根据外部传入的不同的类，给出（执行）不同的方法（策略） 工厂方法模式上述简单工厂模式中，有一个工厂类，客户端告诉工厂需求，它根据需求创建好对应的类并返回。这就存在一个问题，你需要在工厂类中判断当前是哪种需求，这就意味着以后要扩展时，你肯定要在工厂类中做修改，增加新的需求判断条件，这就违背了开闭原则，因为，我们提出了工厂方法模式。 简单工厂模式只有一个工厂类，根据不同需求产生不同的product, 工厂方法模式有多个工厂类，不同的需求对应不同的工厂类，这些工厂类实现了共同的接口。当日后要扩展时，只需要添加product类，添加对应工厂类就可以了。这种修改同时意味着我们将需求的判断交给了客户端，也就是说，客户端需要告诉工厂类它想要什么具体产品，而不是像简单工厂模式那样这个判断是在工厂类中进行的。 抽象工厂模式工厂方法模式中，一个工厂生产一种特定的产品，工厂方法也具有唯一性。但是也有一种情况，一个工厂要生产多种产品，如一个海尔公司要生产海尔电视，海尔冰箱，海尔洗衣机；又如一个SqlServer工厂要生产user表，部门表等，一个Access工厂也要生产user表，部门表等。对于这种一个工厂要生产多种不同产品的情况，我们采用抽象工厂模式。 Decorator​ 装饰器模式，在不违背开闭原则的基础上，给一个类动态的添加功能。也就是说在不修改这个类且不影响其他类的基础上，给这个类添加功能。 ​ 对于一个设计模式，理解它的原理是很简单的，但是要理解它为什么是这样的，应该在哪些场景中使用它，却是不容易的。下面我将试着从一个开发者的角度去思考这个问题。 ​ 假如有一个类 A，现在需求升级，要给A添加新的功能，该怎么做？ 直接修改A，简单粗暴，但同时也有很多隐患。 写一个子类继承A，在子类中添加新的功能。可以是可以，不够优雅，有新功能的A和原来的A原则上讲并没有继承关系，只是我们为了实现需求给强行继承了。 使用装饰器模式。 装饰器模式，听名字就知道，它装饰了原来的类。就像明月装饰了你的窗户，你装饰了别人的梦。抛去这些花里胡哨的名词，我们来看他的本质。 既然是装饰，其实可以理解为一种“包裹”，我在原来的类的基础上再包裹一些东西。那么问题来了，怎么包裹呢？首先，为了让外人看不出我的装饰器类和原来的A类的差别，我让装饰器类和A类继承自同一父类； 然后，为了实现包裹，我把原来的A类作为装饰器类的一个构造函数参数传给装饰器类，这样装饰器类既能够使用A类，又能够在A类的基础上进行一些操作了。（这个包裹说的专业点就叫做聚合） 以上。 ​ 从UML图可以看出，其实Decorator和ConcretComponent继承自同一父类，Decorotor它聚会了Component类，然后在复写的operation方法中对聚合而来的component类进行操作，这就是所谓的装饰。​​ 其实装饰器模式的本质就是，在一个装饰器类中引入了原本要修改的类，然后对这个类进行装饰。要被修改的类的代码没有发生改变，只是它自己被放在另一个类中被操作了一波。​​ 它的核心思想：1. 继承自相同的父类（这样就可以复写要修改的类中的方法） 2. 聚合了要修改的类（这样就可以在原来类的基础上进行一定的装饰，而这个装饰代码是在原来的类之外的。） Proxy Pattern代理模式，故名思意。加入我们想访问对象A，代理模式就是在我们和对象A之间建立一个中间层，也就是代理，从而让代理替我们去访问这个对象。 它的核心思想就是让代理和被访问对象实现同一接口，然后在代理中调用被访问对象中的方法来实现访问。 原型模式Java中原型模式通过实现`Cloneable`接口来实现。所谓原型模式就是说，这个接口有个clone方法，当我们需要这个对象时，通过clone方法来获得对象，而不是通过类的构造函数来构造类，这两者的代价是很不同的。 所使用的场景：当直接创建对象的代价比较大时，则采用这种模式。 ​ 所以这里就会存在一个浅复制和深复制的问题。 外观模式假如你接手祖传代码后，使用起来肯定不容易，这时候你可以在祖传代码之上再加一个中间层，外部代码通过访问中间层来实现对祖传代码的访问，这样就避免了外部代码直接去访问祖传代码。 外观模式隐藏系统的复杂性。它向现有的系统提供一个接口，来隐藏系统的复杂性。客户端不需要知道系统内部的复杂联系，整个系统只需要提供一个接待员即可。 关键代码：在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 建造者模式将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。（感觉有点像模板模式） 建造者模式更加关注零件装配的顺序。就是说组件不变，而这些组件之间的组合会发生变化。 如何实现：首先有个builder类，用来有构建各个组件的方法，其次有个Director类，用来描述各个组件之间的组合关系。 观察者模式一个对象的状态发生变化，给所有依赖它的对象发送通知，进行更新。 策略模式设计模式的终极目的在于解耦。 加入完成一个任务，有多种方法，我们希望根据不同的环境或者不同的条件这多种方法可以随时替换。 比如说现在有个计算器，有时候我们要它做加法，有时候又要它做减法，那么怎么实现呢？ 最直观的方法就是硬编码了，直接把这些加减乘除写成一个计算器Calculator的方法，如果这样的话后期修改也就比较麻烦。 策略模式的思想就在于把这些不同的算法封装成不同的策略类，然后聚合到Calculator类中，然后再给Calculator类一个set方法，以此实现可插拔。 再盗一张菜鸟教程的图。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Android学习笔记","slug":"Android学习笔记","date":"2018-07-04T07:46:41.000Z","updated":"2023-05-29T14:17:37.582Z","comments":true,"path":"2018/07/04/Android学习笔记/","link":"","permalink":"http://example.com/2018/07/04/Android%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"此文章谨用来记录我在做安卓过程中遇到的相关问题和知识点 Handlerhandler在创建之初，会和某个线程绑定，可以认为它是这个线程的代言人，其一个用途就是多线程通信，尤其是非线程安全情况下的线程通信 Fragment为什么会出现fragment这个东西呢，举个最简单的例子，就是想把一个安卓页面划分成多个部分，每个部分显示不同的内容，而这几个部分又属于同一个activity,比如我们使用qq或者微信的时候，地下有个导航栏，无论我们是选择哪一个，只有上面的部分在变，而导航栏却一直都在，这就是fragment的应用。 fragment英文叫做片段，顾名思义其实它就是activity的一个片段，一个子集，让一个activity占据整个页面很庞大，那我们就把activity分成好几个部分，让它们共享这个页面。 这里我拿一张google官方的示例图，就很能说明问题了。 生命周期再甩一张官方图 上图表示在fragment所在的activity运行时fragment的生命周期 添加Fragment 有动态添加和静态添加两种方式，后面会讲到 onAttach() 该fragment被添加到activity中时被调用（两者建立关联时），且只会被调用一次 onCreate() fragment被创建时调用 onCreateView() 绘制该fragment的view时被调用，且讲绘制的view返回 onActivityCreate() fragment所在的activity启动完成后回调 onStart() 启动fragment时被回调 onResume() 恢复fragment时被调用，onStart()方法后一定回调onResume() 经过上述步骤，fragment就被激活了 onPause() fragment被暂停时调用 onStop() fragment停止时调用，停止并不意味着这个fragment被销毁，比如我们按下home键 onDestroyView() 销毁Fragment所包含的view onDestroy() 销毁fragment onDetach() fragment被从activity中remove时调用 其实它的生命周期和activity很相似，理解它们的生命周期，这样就能更好的知道应该在它们的哪个阶段进行哪些操作。 静/动态添加上面提到，fragment是activity的片段，所以就有个这个片段何时被添加的问题。 无论动态添加还是静态添加，在此之前我们都要先定义好这个fragment的内部布局xml文件并且定义一个继承了Fragment的类和这个xml文件关联起来，有点类似于我们要定义好listview的每个item然后通过adapter将它们适配。 下面我们定义一个chart_fragment文件 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot;&gt; &lt;TextView android:id=&quot;@+id/textView&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;match_parent&quot; android:layout_weight=&quot;1&quot; android:text=&quot;this is chart fragment&quot; android:textSize=&quot;20dp&quot;/&gt;&lt;/LinearLayout&gt; 然后用一个继承自Fragment的类将这个xml添加进来 123public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) &#123; return inflater.inflate(R.layout.chart_fragment,container,false); &#125; 这样ChartFragment类就和我们的布局文件关联起来了，以后用ChartFragment就指的是这个fragment了 静态添加 直观讲就是在activity的布局文件中加入fragment标签 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:orientation=&quot;horizontal&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot;&gt; &lt;fragment android:name=&quot;com.example.news.ArticleListFragment&quot; android:id=&quot;@+id/list&quot; android:layout_weight=&quot;1&quot; android:layout_width=&quot;0dp&quot; android:layout_height=&quot;match_parent&quot; /&gt; &lt;/LinearLayout&gt; 像这样，可以发现上述fragment的name是一个类名，也就是我们上面关联的类名，这也是静态添加fragment的一个特点 动态添加 所谓动态添加就是我们不直接把fragment标签写死在activity的布局文件中，而是在activity布局文件中给fragment留一个container,比如各种layout,然后在代码中通过FragmentSupportManager来进行添加。我们获得Transaction对象，用它来操作fragment,比如add,remove,hide,show,replace等。 1getSupportFragmentManager().beginTransaction().replace(R.id.frame2,new MapFragment()).commit(); Fragment Activity交互这里用菜鸟教程的一张图来说明问题 这里面比较难理解的是Fragment向Activity传递数据，我个人是这样理解的：假设有这样一个场景，点击Fragment A中的某个选项需要切换到Fragment B,那么Fragment必须把这个讯息传给它所在的Activity,因为Fragment A是没有切换的能力的，这种大事必须A和B的爸爸来完成。那如何做呢？我们可以定义一个接口I，然后让Activity实现这个接口，这个接口里函数的参数就是Fragment A要向Activity传递的数据，然后我们在Fragment中获得Activity对象，调用这个接口函数，是不是就很巧妙的把Fragment A的信息（作为参数）传递给了Activity（Activity实现了这个接口，所以调用的时候自然能获得接口的参数，而这个参数来自于Fragment A）呢？ 遇到的问题 我用的是两个fragment,一个静态添加一个动态添加，一个fragment中受到点击事件去动态添加另一个fragment时，总是失败，看完了网上的各种方法，如包的版本问题，support.v4还是app包,以及fragment的name问题，都没有找到原因，后来发现，原来是这个constraintlayout搞得我没有把fragment画出来，所以以后开发还是给布局加点颜色为好。 我想在Activity中先模拟一次一个fragment中的点击事件，这样一进来屏幕就不会感觉很空洞，于是我在onCreate方法中添加了button的performclick方法，但是，没反应，又经过一阵搜寻，原来在onCreate中，其实fragment布局还没有加载完，这时候贸然performclick是没有作用的，应该讲方法加到onStart中，看来学好他们的生命周期还是很有用的鸭。 信号强度 有两种信号单位，dbm和asu asu(alone signal unit)：独立信号单元，是一种模拟信号。asu代表手机将它的位置传递给附近的信号塔的速率，它和dbm测量的是一样的东西，但是是以一种更加线性的方式来表示。 dBm：是一个表示功率绝对值的值（也可以认为是以1mW功率为基准的一个比值），计算公式为：10log（功率值/1mw）。 网络类型 电信 2G CDMA3G CDMA20004G TD-LTE，FDD-LTE 移动 2G GSM3G TD-SCDMA4G TD-LTE，FDD-LTE 联通 2G GSM3G WCDMA4G TD-LTE，FDD-LTE 安卓api提供的类型 权限管理安卓的权限分正常权限和危险权限，正常权限在Manifest中添加一哈就可以了，但是危险权限自己添加后还需要一个手动申请并覆盖原来方法的过程。 通过ActivityCompat.requestPermissions来申请我们所需的权限，它会回调onRequestPermissionsResult方法，所以我们还需要复写这个方法来达到我们的目的，复写方式很简单，让MainActivity实现ActivityCompat.OnRequestPermissionsResultCallback接口（因为onRequestPermissionsResult方法就是i这个接口中的），然后再MainActivity中复写该方法即可 Context 和 Activity 的关系用一张图就很能说明问题了 关于findViewById刚刚在做一个popupwindow里面显示动态图表的东西,在找图表的id时总是返回空指针，后来发现，之前写的类里面总以为findViewById是Context的方法，所以此前在用这个方法的时候一直传递Context来调用，其实这是一个View的方法，虽然在同一个Context下，但已经是不同的视图了，所以总返回空指针。 setOnclickedListener在重写该接口的onClicked方法时，该方法的参数是被点击的那个视图，比如按钮等。 PopupWindow1234void showAtLocation (View parent, // 该属性只要是屏幕上任意控件对象即可 int gravity, // 屏幕位置 int x, // 偏移坐标 int y) 这里需要注意第一个参数是屏幕上的组件，但不能是popupwindow中的组建，否则会报错。 Problems AS视图编辑器里不能显示控件，最后解决办法，在style.xml中的parent=后面加Base.","categories":[{"name":"移动开发","slug":"移动开发","permalink":"http://example.com/categories/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"数据结构","slug":"数据结构","date":"2018-06-29T10:32:31.000Z","updated":"2023-05-29T14:17:39.320Z","comments":true,"path":"2018/06/29/数据结构/","link":"","permalink":"http://example.com/2018/06/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"树树的表示方法通过在连续的存储空间中标注每个节点的父节点，兄弟节点，子节点等，来达到索引的目的 双亲表示法 在每个节点后面指明父节点所在位置（结构体就可以表示） 孩子表示法 在每个节点后面链接上子节点的下表（数组+链表来表示） 双亲孩子表示法 以上两种方式的结合，每个节点后面既指明父节点的位置，也同时链接上各个子节点 12345678910111213141516#define MAX_TREE_SIZE 50typedef CTNode&#123; int index; CTNode *next ;&#125;NodePtr;typedef struct&#123; ElementType elem ; int parent_index ; NodePtr *firstChild ;&#125;CTBox;typedef struct&#123; CTBox nodes[MAX_TREE_SIZE]&#125;CTree; 二叉树二叉树，顾名思义，最多有两个子节点。在递归定义的情况下，它有五种形态：空二叉树，只有根节点，只有左子树，只有右子树，左右子树都有。 比如说，对于一棵二叉树，有三个节点，那它有几种情况呢？答案是五种！ 特殊二叉树 斜二叉树（斜成一条线），满二叉树（最圆满的情况），完全二叉树（最后一层最右边的节点从右往左缺失） 二叉树性质 二叉树的第i层最多有2^(i-1)个节点 （化作等比数列，二叉树的第i层相当于数列的第i-1项） 深度为k的二叉树至多有2^k-1个节点 任何一棵二叉树，如果其叶子节点数为n0，度为二的节点数为n2,则n0 = n2 + 1 推导：设总结点数为n,度为1的节点数为n1,n=n0+n1+n2,树枝数目为n-1=n1+2*n2,结合这两个公式有n0=n2+1 具有n个节点的完全二叉树的深度是$$ \\lfloor \\log n \\rfloor+1$$ 推导：设该二叉树深度为k,则它的节点数量位于深度为k-1和深度为k的满二叉树中间，即有 $ 2^{k-1} -1 &lt; n \\leq2^{k}-1$ 化简得 $k-1\\leq \\log n&lt;k$ 所以有$k=\\lfloor \\log n\\rfloor+1$ 如果一棵有n个节点的完全二叉树其节点按层序编号，对任一节点i(1&lt;=i&lt;=n)有如下性质 如果i=1,则i是根节点 如果2i&gt;n,则i没有左孩子，否则其左孩子是2i 如果2i+1&gt;n,则i没有右孩子，否则其右孩子是2i+1 二叉树存储结构 数组或者链表，用数组存储的话遇到极端情况（如斜树）比较浪费空间，所以一般用链表来存储 12345typedef BiNode&#123; ElemType elem; BiNode *lchild ; Binode *rchild ;&#125;BiTree 二叉树的遍历 前序遍历 根，左，右 中序遍历 左，根，右 后序遍历 左，右，根 层序遍历 12345678910111213141516171819202122232425262728293031323334353637//define bitreetypedef struct BiTree&#123; char data ; struct BiTree * lchild ; struct BiTree * rchild ;&#125;BiTree;//create bitreevoid createBiTree(BiTree* &amp;T)&#123; char c ; //cin &gt;&gt; c ; if(&#x27; &#x27;==(c=getchar())) T = NULL; else&#123; T = new BiTree ; T -&gt; data = c ; createBiTree(T-&gt;lchild) ; createBiTree(T-&gt;rchild) ; &#125; &#125;void visit(BiTree* T,int level)&#123; cout &lt;&lt; &quot;node &quot; &lt;&lt; T-&gt; data &lt;&lt; &quot; in level &quot; &lt;&lt; level &lt;&lt; endl ;&#125;//traverse bitreevoid preOrderTraverse(BiTree* T,int level)&#123; if(T)&#123; visit(T,level) ; preOrderTraverse(T-&gt;lchild,level+1) ; preOrderTraverse(T -&gt; rchild,level+1) ; &#125; &#125; Huffman Tree 背景 有n个带权重的叶子节点，我们想构造一棵二叉树，使得带权路径长度最小 方法 不断的将两棵权值最小的树合并成一棵更大的树，新树的根节点权值为之前两棵树的根节点权值之和。 Huffman Code 综合考虑，我们认为Huffman Tree中每一个节点都有权值（其中非叶子节点权值为0），左右孩子。且哈夫曼树的节点要么为0要么为2，没有度为1的节点，则有n个叶子节点的哈夫曼树共有2n-1个节点（这点可由二叉树性质推出），我们考虑将其存储在长度为2n的一维数组中（选择长度为2n而不是2n-1是为了下边从1开始计算） 存储结构 1234typedef struct&#123; unsigned int weight ; unsigned int parent,lchild,rchild ; //这里我们存储的都是下标&#125;HTNode,*HuffmanCode 哈夫曼编码主要分为一下几个步骤： 初始化 初始化时给叶子节点权重，非叶子节点权重为0（也就是第一行和第二行for循环的意思） 构建哈夫曼树 构建时我们就从前面n个叶子节点找到权值最小的两个，将他俩合并成一个新的节点，放在n+1的位置，以此类推（对应第三个for循环） 求哈夫曼编码 求哈夫曼编码就是从根节点到叶子节点游走下去，如果是左孩子则编码为0，如果是右孩子，则编码为1，然后将编码以此存入相应数组里。但是，如果从根节点开始寻找，那么我们必须遍历这棵树，这是很麻烦的，我们可以考虑从叶子节点回溯到根节点，对于每个节点，从结构体我们可以知道它是有指向父节点的指针的，那我们就从叶子节点开始回溯，如果当前节点是父节点的左孩子，则当前编码为0，如果是右孩子，则编码为1，同时我们设置一个数组cd[…]来存储编码，因为是从叶子到根节点这样回溯的，所以我们得到的编码肯定是反着的，所以如果我们把这个编码从数组cd的的屁股开始放，就可以解决这个问题了。 图关键路径 在AOE网（Activity On Edge）中，弧表示活动，顶点表示事件，权值表示活动持续时间，它是一个有向无环图。通常情况下，AOE网可以用来估算工程的完成时间。它的两个主要问题是： 1. 完成整项工程需要多长时间 2. 哪些活动是影响工程进度的关键 ​ 对于第一个问题，完成整项工程的需要多长时间，我们只需要考虑完成它所需要的最短时间即可。对于一个有向无环图所表示的工程来说，完成工程的最短时间是从开始点到结束点的最长路径的长度，我们把这个最长路径叫做关键路径（这里有人可能会疑问为什么不是最短路径的长度，你想，如果是在最短路径长度所表示的时间内就能完成工程，那么那些耗时较长的工序咋整，假设最长长度是8，最短是5，如果有个工序需要在时间为6时进行，如果选择5作为完成工程的最短时间，那这个工序岂不是没有时间进行了） ​ 对于第二个问题，哪些活动是影响工程进度的关键，我们引入下图来说明问题，因为途中有些活动是并行进行的，所以有些顶点事件的开始时间其实是不唯一的，拿v5来说，v1 -&gt; v2 -&gt; v5 这条路径执行的话，v5要到7这个时间点才能执行，按照v1 -&gt; v3 -&gt; v5 这条路径执行的话，到5这个时间点就可以执行了，那么问题来了，v5处的事件真的能在时间为5时执行么，答案是不能！如果此时执行的话，时间为5时v2还没有被执行，v5的先决条件还不满足呢，这也是我们上述中最短时间为什么选的是最长路径的原因。这里我们提出事件的最早开始时间ei这一概念 事件Vi的最早开始时间就是从V1到Vi的最长距离。最早开始时间，顾名思义就是这个事件最早能被执行的时间，上述的V5的最早开始时间就是7，也就是说V7不能比时间7更早执行了，不然它的先决事件没有被执行完。也即V5的执行时间应该大于等于7，那是不是可以无限大呢？显然是不能的，因为无限延迟肯定会延误工期啊，所以V5的执行时间再怎么延迟，也要在工期（也就是我们说的项目的最短时间即关键路径）结束前走到V9啊。因此我们又提出了最迟开始时间li，顾名思义也就是这个开始时间的选择很精准，刚好到工期结束，它也刚好走到V9. ​ 拿上图来分析，这里我们以知从v1到v9的最长路径是（v1,v2,v5,v8,v9）,路径长度18，即v9的最早发生时间是18.我们来看活动a6(注意这里看的是活动不是事件哦),它的最早开始时间是5（从v1到v4）,最晚开始时间是8，怎么算的呢，总长是18，它如果要赶在刚好工期结束的时候赶到v9,那它应该从时间 18-a11-a9-a6 = 8 处开始，这样工期结束时就刚好赶到v9。 ​ 上述我们计算了时间的最早开始时间和最迟开始时间，你会发现，在l-e之间有个差值，这个差值表示我们工期可以延迟的一个幅度，那么就一种特殊情况，差值为零，它表示这个活动一秒钟都延期不得，不然会影响整个工期进度，我们把这种活动叫做关键活动。 ​ ​ 排序插入排序插入排序的核心思想：认为最初的一个元素是有序的， ​ 然后从第二个元素往后，开始和已经有序的元素进行逆向比较， ​ 如果比有序的倒数第一个元素大是最好的，这种情况下不用移动有序元素可以直接插入末尾 ​ 否则就是把有序部分向后移动，直到遇见某个元素，它刚好小于我们的待比较元素， 查找二叉排序树左孩子比父亲小，右孩子比父亲大。正常情况，用n个节点随机构造的二叉排序树，高度为log(n),所以查找的时间复杂度也是log(n)，没问题。但怕就怕在这个二叉排序树走极端，万一它只有左孩子或者只有右孩子，那么它就会变成个链表，这时候查找的时间复杂度就变成了n了。 所以，为了避免上述情况的发生，我们需要薛微制裁一下二叉排序树，使它不要偏科严重，于是就有了平衡二叉树。 平衡二叉树（AVL树）因为二叉排序树偏科严重，所以我们教会了AVL树雨露均沾，在保证二叉排序树的特点上，我们又要求AVL树左右子树高度差不能超过1，这样一来，整棵树就显得很均衡了。每当插入或者删除节点使得树失衡的时候，我们都要通过旋转去调节。 但是！虽然它很严格的平衡了，但是每次这种调节确实很费时的，这对于频繁的删除和插入的场景来说，并不是个好消息。所以人们又想，能不能弱化一下它的平衡，让它可以偏科，但是不要太严重就行，于是，就有了红黑树。 红黑树红黑树的定义是这样的： 每个节点要么红要么黑 根节点是黑色的 每个叶节点都是空节点，是黑的 如果一个节点是红的，那么它的两个儿子是黑的 对于每个节点，到叶子节点的任意一条路径上，黑色节点数目都一样多 它的查找，插入，删除时间复杂度为O(log n),它的统计性能比AVL数更好。 插入插入只能是插入红色节点，因为插入黑节点，违背性质五，需要大规模调整。 插入的节点是根节点 直接涂黑 插入的节点的父亲是黑节点 没毛病，直接插 父亲是红节点 现象说明 处理策略 Case 1 当前节点的父节点是红色，且当前节点的祖父节点的另一个子节点（叔叔节点）也是红色。 (01) 将“父节点”设为黑色。 (02) 将“叔叔节点”设为黑色。 (03) 将“祖父节点”设为“红色”。 (04) 将“祖父节点”设为“当前节点”(红色节点)；即，之后继续对“当前节点”进行操作。 Case 2 当前节点的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的右孩子 (01) 将“父节点”作为“新的当前节点”。 (02) 以“新的当前节点”为支点进行左旋。 Case 3 当前节点的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的左孩子 (01) 将“父节点”设为“黑色”。 (02) 将“祖父节点”设为“红色”。 (03) 以“祖父节点”为支点进行右旋。 叔叔是红色 叔叔是黑色，当前是右孩子 处理策略： 将“父节点”作为“新的当前节点”； 以“新的当前节点”为支点进行左旋。 叔叔是黑色，当前是左孩子 处理策略(01) 将“父节点”设为“黑色”。(02) 将“祖父节点”设为“红色”。(03) 以“祖父节点”为支点进行右旋。 删除普通二叉树的删除规则： 1、如果删除的是叶节点，可以直接删除； 2、如果被删除的元素有一个子节点，可以将子节点直接移到被删除元素的位置； 3、如果有两个子节点，这时候就可以把被删除元素的右支的最小节点（被删除元素右支的最左边的节点）和被删除元素互换，我们把被删除元素右支的最左边的节点称之为后继节点（后继元素），然后在根据情况1或者情况2进行操作。 对于红黑树的删除，首先要满足普通二叉树的删除规则，其次，删除还不能影响到上述的红黑树的五条特性。 大意就是：红色的，直接删；根节点，直接删； 这个我已经写不动了，有时间再写吧， 总结总之，无论是插入还是删除，在满足普通二叉排序数的规则之上，还需要考虑配色问题，要使得颜色满足红黑树的定义。 感悟为什么今天突然看这个呢，因为在看源码的时候渐渐发现除了HashMap, TreeMap也用到了红黑树去达到一个有序的Map的效果的，所以就看了下，虽然挺复杂的，我也没看完，但是大概懂它的工作原理以及设计哲学了，也是不错的收获啦，起码以后再看源码的时候碰到它就不会很陌生了。 参考文献： 红黑树(一)之 原理和算法详细介绍","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"windows下tensorflow anoconda安装","slug":"windows下tensorflow anoconda安装","date":"2018-05-31T04:00:00.000Z","updated":"2018-05-31T04:00:00.000Z","comments":true,"path":"2018/05/31/windows下tensorflow anoconda安装/","link":"","permalink":"http://example.com/2018/05/31/windows%E4%B8%8Btensorflow%20anoconda%E5%AE%89%E8%A3%85/","excerpt":"","text":"之前已经装好anoconda，这里安装tensorflow 准备工作：Python3.5 或者Python3.6 很多操作指令官方文档已经给出 打开cmd，输入 conda create -n tensorflow python=3.5 创建一个名为tensorflow的环境，（这里我第一次尝试并没有成功，将目录切换到Python底下才成功，估计是环境变量的问题），可能会显示要安装新的文件，点y即可。 激活环境 activate tensorflow 这时你会发现命令行最开始会有(tensorflow)，说明已经激活 安装tensorflow, 因为我安装的是cpu版本，所以命令如下： pip install --ignore-installed --upgrade tensorflow 至此安装已经完成，如需检验是否安装成功，输入python,如果import tensorflow不报错，基本说明安装成功 至此tensorflow的安装工作已经完成，那如何在anconda navigator中导入呢？ 方法一 UI界面中导入 ​ 个人觉得这种方法很容易卡死，推荐第二种 方法二 命令行下载 首先activate 某环境，然后conda install xxx (如spyder) 如果之前安装了别的python版本，因为anaconda里面自己带了python,如何给指定版本安装numpy?这里有两种方式： 1. activate conda环境，然后conda install numpy,这样会安装许多其他的包，很麻烦,不推荐 2. py -3 -m pip install python","categories":[{"name":"教程","slug":"教程","permalink":"http://example.com/categories/%E6%95%99%E7%A8%8B/"}],"tags":[]},{"title":"leetcode题解","slug":"LeetCode题解","date":"2018-05-03T03:13:20.000Z","updated":"2023-05-29T14:17:39.379Z","comments":true,"path":"2018/05/03/LeetCode题解/","link":"","permalink":"http://example.com/2018/05/03/LeetCode%E9%A2%98%E8%A7%A3/","excerpt":"","text":"###542.01 矩阵 题目描述 给定一个由 0 和 1 组成的矩阵，找出每个元素到最近的 0 的距离。 两个相邻元素间的距离为 1 。 题目分析 可用动态规划来求解，每个元素距离0最近的距离 = 该元素邻居距离0最近的距离 + 1 为了从分利用内存空间，我们仍然用这个矩阵来表示距离 为零的元素不用处理，如果某个元素的邻居有0，那么将该元素置为1（说明它到0的距离为1） 将剩下的元素（也就是周围全是1的元素）置为无穷大，这个初始化意味着他们到零的距离为无穷大，需要在后面的动态规划中求解 通过上述的处理，我们可以得到，这些无穷大的值其实都被数字1或者边界所包含，通过边界值可以更新无穷大的值 对矩阵进行遍历，第一顺序横向遍历，当遇见值为无穷大的元素时，更新它的值为 邻居到0最近距离+1 和无穷大 本身值的较小者 matrix[i][j]=min(matrix[i-1][j]+1,matrix[i][j]) //如果该元素不是第一列 第一次遍历将会和该元素的左边元素和上边元素比较 第二次遍历从最后一行最后一列开始遍历，将会和该元素的右边和下边元素进行比较 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import static java.lang.Math.min;public class Matrix2&#123; public static void main(String[] args) &#123; int[][] matrix = //&#123;&#123;0,0,0&#125;, &#123;0,1,0&#125;, &#123;1,1,1&#125;&#125; ; &#123; &#123;0, 0, 1, 0, 1, 1, 1, 0, 1, 1&#125;, &#123;1, 1, 1, 1, 0, 1, 1, 1, 1, 1&#125;, &#123;1, 1, 1, 1, 1, 0, 0, 0, 1, 1&#125;, &#123;1, 0, 1, 0, 1, 1, 1, 0, 1, 1&#125;, &#123;0, 0, 1, 1, 1, 0, 1, 1, 1, 1&#125;, &#123;1, 0, 1, 1, 1, 1, 1, 1, 1, 1&#125;, &#123;1, 1, 1, 1, 0, 1, 0, 1, 0, 1&#125;, &#123;0, 1, 0, 0, 0, 1, 0, 0, 1, 1&#125;, &#123;1, 1, 1, 0, 1, 1, 0, 1, 0, 1&#125;, &#123;1, 0, 1, 1, 1, 0, 1, 1, 1, 0&#125;&#125;; int [][] matrix2 ; matrix2 = updateMatrix(matrix) ; System.out.println(&quot;last&quot;); for(int i=0 ; i&lt;matrix2.length; i++)&#123; for(int j=0; j&lt;matrix2[0].length;j++)&#123; System.out.print(matrix2[i][j]+&quot; &quot;); &#125; System.out.println(); &#125; &#125; public static int[][] updateMatrix(int[][] matrix)&#123; // for(int i=0; i&lt;matrix.length;i++)&#123; for(int j=0; j&lt;matrix[0].length;j++)&#123; if(matrix[i][j]==1)&#123; if(i&gt;0 &amp;&amp; matrix[i-1][j]==0) &#123; matrix[i][j]=1; continue; &#125; if(i&lt;matrix.length-1 &amp;&amp; matrix[i+1][j]==0)&#123; matrix[i][j]=1 ; continue; &#125; if(j&gt;0 &amp;&amp; matrix[i][j-1]==0)&#123; matrix[i][j]=1 ; continue; &#125; if(j&lt;matrix[0].length-1 &amp;&amp; matrix[i][j+1]==0)&#123; matrix[i][j]=1; continue; &#125; matrix[i][j]=65535 ; &#125; &#125; &#125; System.out.println(&quot;first &quot;); for(int i=0 ; i&lt;matrix.length; i++)&#123; for(int j=0; j&lt;matrix[0].length;j++)&#123; System.out.printf(&quot;%-8d&quot;,matrix[i][j]); &#125; System.out.println(); &#125; for(int i=0; i&lt;matrix.length;i++)&#123; for(int j=0; j&lt;matrix[0].length;j++)&#123; if(matrix[i][j]==65535)&#123; if(i&gt;0)&#123; matrix[i][j] = min(matrix[i-1][j]+1,matrix[i][j]); &#125; if(j&gt;0)&#123; matrix[i][j] = min(matrix[i][j-1]+1,matrix[i][j]); &#125; &#125; &#125; &#125; System.out.println(&quot;second &quot;); for(int i=0 ; i&lt;matrix.length; i++)&#123; for(int j=0; j&lt;matrix[0].length;j++)&#123; System.out.printf(matrix[i][j]+&quot;\\t&quot;); &#125; System.out.println(); &#125; for(int i=matrix.length-1; i&gt;=0;i--)&#123; for(int j=matrix[0].length-1;j&gt;=0;j--)&#123; if(i&lt;matrix.length-1) matrix[i][j]=min(matrix[i+1][j]+1,matrix[i][j]); if(j&lt;matrix[0].length-1) matrix[i][j]=min(matrix[i][j+1]+1,matrix[i][j]); &#125; &#125; return matrix; &#125;&#125; 关于疑问 可能有人会想，为什么要遍历两遍，而不是在第一次遍历时就直接和前后左右邻居相比较，继续看这张图，按照我们的思路处理后是这样的 请看第一行倒数第二个元素m[0][8]，如果只进行一次顺序遍历，由于它底下的值m[1][8]没有更新，它将会认为从左边得到的4(m[0][7]+1)这个值是最小值，但是事实是，当它底下这个无穷大值如果经过更新成2，那么它的4也应该更新为3。如果按照我们只遍历一次的思想，它是等不到m[1][8]更新的，但是如果我们先正向遍历比较左边和上边元素，得到下图 第二次反向遍历时，当m[0][8]和它下面的m[1][8]比较时，因为m[1][8]已经更新，所以它也会被更新。 所以说，第一波遍历时本来就是从左到右从上到下的顺序，即使强行和当前元素的右边和下边比较，因为这两边还没有更新，所以并没有什么效果，所以才需要两次遍历，且方向相反 1 456. 132模式 题目描述 给定一个整数序列：a1, a2, …, an，一个132模式的子序列 ai, aj, ak 被定义为：当 i &lt; j &lt; k 时，ai &lt; ak &lt; aj。设计一个算法，当给定有 n 个数字的序列时，验证这个序列中是否含有132模式的子序列。 注意：n 的值小于15000。 分析 最暴力的方法就是通过三重循环直接判断，但是运行时会超时，这里对三重循环进行优化，通过观察可知，假设三个数依次是x,y,z.如果y&lt;=x,这时可以直接用y来替代x，因为用一个更小的值来做x肯定是不会错的。同理，如果z&gt;=y，我们就用z的值来更新y。需要注意的是下标的移动。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445public boolean find132pattern(int[] nums) &#123; int x,y,z ; int min,max ; if(nums.length==0) return false; min=max=nums[0] ; for(int i=1; i&lt;nums.length;i++)&#123; min = nums[i]&lt;min ? nums[i] : min ; max = nums[i]&gt;max ? nums[i]:max ; &#125; if(max-min&lt;2) return false ; for(int i=0; i&lt;nums.length;)&#123; x= nums[i]; for(int j=i+1; j&lt;nums.length;)&#123; y=nums[j]; //如果遇见比x还小的值，就更新x,同时更新下标 if(y&lt;=x)&#123; x=y; i=j; j++; continue ; &#125; for(int k=j+1; k&lt;nums.length;k++)&#123; z=nums[k]; //如果遇见比y还大的值，就更新y,同时更新下标 if(z&gt;=y)&#123; y=z ; j=k; continue; &#125; if( x&gt;=z)&#123; continue; &#125; else return true ; &#125; j++; &#125; i++; &#125; return false ; &#125; 反思 看了下里面大神解答，时间复杂度控制在O(n)也是可以解决这个问题的。先找到当前元素nums[i]前面所有元素中最小的元素min[i]，然后反向遍历，并在遍历时将元素加入集合，然后判断集合中是否存在大于当前元素nums[i]前面的最小元素min[i]的元素，如果存在且这个元素小于当前元素，则返回true.否则直到遍历结束并返回false. 650.2 Keys Keyboard 题目描述 Initially on a notepad only one character ‘A’ is present. You can perform two operations on this notepad for each step: Copy All: You can copy all the characters present on the notepad (partial copy is not allowed). Paste: You can paste the characters which are copied last time. Given a number n. You have to get exactly n ‘A’ on the notepad by performing the minimum number of steps permitted. Output the minimum number of steps to get n ‘A’. 题目分析 题目最终化简为n的素数分解，然后将质因数求和 代码 12345678910111213141516public int minSteps(int n) &#123; int sum=0; if(n==1) return 0 ; if(n==2) return 2; for(int i=2; i*i&lt;=n;i++)&#123; while(n%i==0)&#123; sum+=i ; n/=i; &#125; &#125; if(n!=1) sum+=n; return sum ; &#125;","categories":[{"name":"题解","slug":"题解","permalink":"http://example.com/categories/%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"http://example.com/tags/Leetcode/"}]},{"title":"Spring","slug":"Spring","date":"2018-04-15T08:27:20.000Z","updated":"2023-05-29T14:17:37.589Z","comments":true,"path":"2018/04/15/Spring/","link":"","permalink":"http://example.com/2018/04/15/Spring/","excerpt":"","text":"初探Spring类似于Struts2, Spring也是通过xml配置文件来对类进行操作的 在Struts2中，对于表单的提交，通过将表单中标签的name属性设置为Bean中对应的属性，通过配置struts.xml可以让框架自己去调用对应的setter，这里也是类似，只不过设置的是applicationContext.xml,这个配置文件将会告诉容器如何操作具体的类。 看一段代码： bean包中 接口IPerson及其实现类 123456package com.bean;public interface IPerson &#123; public void say();&#125; 123456789101112131415161718192021222324252627package com.bean;public class ChineseImp implements IPerson &#123; private String name ; private int age ; @Override public void say() &#123; System.out.println(&quot;I&#x27;m Chinese,my name is&quot;+this.name+&quot; my age is &quot;+this.age); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 1234567891011121314151617181920212223242526272829package com.bean;import java.sql.SQLOutput;public class AmericanImp implements IPerson &#123; private String name ; private int age ; @Override public void say() &#123; System.out.println(&quot;I&#x27;m American,my name is &quot;+this.name+&quot; my age is&quot;+this.age); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; applicationContext.xml 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;chinese&quot; class=&quot;com.bean.ChineseImp&quot;&gt; &lt;property name=&quot;name&quot;&gt; &lt;value&gt;taochaoquan&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;age&quot;&gt; &lt;value&gt;23&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;american&quot; class=&quot;com.bean.AmericanImp&quot;&gt; &lt;property name=&quot;name&quot;&gt; &lt;value&gt;Arrow&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;age&quot;&gt; &lt;value&gt;12&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; emmmm内容浅显易懂，就不详述了 测试类 1234567891011121314151617package com.spring;import com.bean.IPerson;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Test &#123; public static void main(String[] args) &#123; //创建Spring容器 ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); IPerson p1 = (IPerson) context.getBean(&quot;chinese&quot;); p1.say(); IPerson p2 = (IPerson) context.getBean(&quot;american&quot;); p2.say(); &#125;&#125; 输出 12I&#x27;m Chinese,my name istaochaoquan my age is 23I&#x27;m American,my name is Arrow my age is12 控制反转和依赖注入 ​ 传统的设计模式：假如调用者A需要调用被调用者B，那么它就需要new出一个B，这样的话，A,B之间的耦合度就会比较高，假如说后期需求发生了变化，需要往B中添加属性，那么就得修改项目中调用了B处的相关代码。 ​ 使用依赖注入：假如说A需要调用B，Spring容器会自动将B的实例注入到A中，相当于此时A拥有了B，当项目需求变更时，我们只需要修改Spring的配置文件而无需修改代码 下面用一个例子来说明6 有一个User类 1234567891011121314151617181920212223package bean;public class User &#123; private String username ; private String password ; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; 用接口UserDao来模拟持久层 12345678package dao;import bean.User;public interface UserDao &#123; public void save(User user);&#125; 1234567891011package dao;import bean.User;public class UserDaoImp implements UserDao &#123; @Override public void save(User user) &#123; System.out.println(&quot;user has been saved in database&quot;); &#125;&#125; 服务层 123456789package service;import bean.User;public interface UserService &#123; public void add( User user);&#125; 12345678910111213141516171819202122package service;import bean.User;import dao.UserDao;public class UserServiceImp implements UserService &#123; private UserDao userDao ; public UserDao getUserDao() &#123; return userDao; &#125; public void setUserDao(UserDao userDao) &#123; this.userDao = userDao; &#125; @Override public void add(User user) &#123; userDao.save(user); &#125;&#125; 测试类 123456789101112131415161718package main;import bean.User;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import service.UserServiceImp;public class Test &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserServiceImp usi = (UserServiceImp) context.getBean(&quot;userService&quot;) ; User user = new User(); user.setUsername(&quot;tao&quot;); user.setPassword(&quot;123&quot;); usi.add(user); &#125;&#125; 大概业务逻辑如下：有一个新的用户user，我们想把它加到用户列表中，UserServiceImp类中提供了add()方法，我们可以看到，add方法内部其实是调用了UserDao的save方法，那么问题来了，当Test类中的usi.add()传入user后，应当需要一个UserDao的实例来执行save方法，而在我们的代码中并没有看到new出的实例。其实这个操作就是Spring容器帮我们做的，请看下面的配置文件 beans.xml 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;udi&quot; class=&quot;dao.UserDaoImp&quot;&gt;&lt;/bean&gt; &lt;bean id=&quot;userService&quot; class=&quot;service.UserServiceImp&quot;&gt; &lt;property name=&quot;userDao&quot;&gt; &lt;ref bean=&quot;udi&quot;/&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 这里其实就是把被依赖的UserDao的实例注入了UserServiceImp的实例中，也就是我们所说的依赖注入。 对于上面的业务逻辑，如果 我们不使用依赖注入，应该是这样的，1.创建UserServiceImp实例，2.创建UserDao实例，3.通过UserServiceImp的setter方法，建立两者依赖， 可以看出，依赖注入帮我们完成了第二步和第三步，很好的解耦了他们的依赖性 Spring MVC配置DispatcherServlet 大概完成了一个简单demo,我只想说，最后部署的时候并不用加项目名称来访问，直接localhost:8008/welcome就可以了。 注解 @PathVariable 当使用@RequestMapping URI tempalte样式映射时，即someUrl/{paramId},这时的paramId可通过@PathVariable注解将其绑定到方法参数上 123456789@Controller @RequestMapping(&quot;/owners/&#123;ownerId&#125;&quot;) public class RelativePathUriTemplateController &#123; @RequestMapping(&quot;/pets/&#123;petId&#125;&quot;) public void findPet(@PathVariable String ownerId, @PathVariable String petId, Model model) &#123; // implementation omitted &#125; &#125; 假如使用@PathVariable注解时参数名和URI template中的不一致，可以这样@PathVarible(&quot;name&quot;)其中name为URI template中的变量名 @RequestHeader 把request header中的某些字段绑定到参数上 @CookieValue 把Request header中关于cookie的值绑定到参数上 @RequestParam和@RequestBody @SessionAttribute和@ModelAttribute 绑定HttpSession中的attribute对象的值, @ModelAttribute注解有两个用法，一个是用于方法上，一个是用于参数上。用于方法上时，被其注释的方法会在Controller每个方法执行前被执行，因此通常用来在处理@RequestMapping之前为请求绑定需要从后台查询的model；用于参数上时，用来通过名称对应把相应名称的值绑定到注解的参数bean上 总的来说，注解就是实现了请求的相关值与方法参数的绑定。 请求参数名和java类的属性相匹配 测试SpringMVC HttpRequest –&gt; DispatcherServlet –&gt; Handler Mapping –&gt; Controller –&gt; Model and View –&gt; DispatherServlet –&gt; View Resolver –&gt; Model","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://example.com/categories/JavaWeb/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Intellij快捷键","slug":"Intellij快捷键","date":"2018-03-29T07:31:04.000Z","updated":"2023-05-29T14:17:39.325Z","comments":true,"path":"2018/03/29/Intellij快捷键/","link":"","permalink":"http://example.com/2018/03/29/Intellij%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"alt+Enter 纠错提示 ctrl+q 显示函数注释 ctrl+h 显示类继承结构","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://example.com/tags/%E6%95%99%E7%A8%8B/"}]},{"title":"java学习笔记","slug":"java学习笔记","date":"2018-03-14T06:57:25.000Z","updated":"2023-05-29T14:17:39.378Z","comments":true,"path":"2018/03/14/java学习笔记/","link":"","permalink":"http://example.com/2018/03/14/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"继承与覆盖 当通过一个父类的引用指向一个子类的对象后，将只能通过这个父类的引用访问那些父类中定义了的属性和方法。Java平台的执行规则是： 在编译的时候，可以调用哪些方法，访问哪些属性，是引用类型决定的；在程序运行的时候，具体访问哪个属性，执行哪个方法，是对象的类型决定的。 也就是说，如果子类中有这个方法f1而父类中没有，那么指向子类的父类引用是不能调用子类的这个方法f1的,只有当子类和父类拥有一样的方法（继承或者覆盖得到）时，指向子类的父类引用才可以调用这个方法，并且调用的是子类的方法。 使用覆盖的几条规则 子类必须把这个方法从父类中继承过来，这个与方法的访问控制符有关系； 子类方法的访问控制符的访问权限应比父类中的更宽松或者相同 子类方法返回值类型必须能赋值给父类方法返回值类型 当继承被引入到重载的参数中时，决定函数重载的哪个方法被调用的是实参。这里的实参指的是引用的类型，而不是引用指向的对象的类型 对于静态方法，Java会根据引用的类型而非引用指向的对象的类型来决定调用哪个静态方法 变量的覆盖，变量的值取决于引用类型而不是引用指向的对象类型 多态所谓多态，指的是同一行为在不同环境下有不同表现。 为什么会有多态呢？主要由三个原因造成： 继承 覆盖 父类引用指向子类对象 接口什么是接口如何定义接口 程序使用接口可以很好的避免对外部类的依赖性，因为对外只需要一个接口，任何实现了该接口的对象都可以作为参数传递过去。 保存接口的文件名也要和接口名相同 ```public abstract insterface 接口名{ public static final int r =1; public abstract 返回值 方法名(); } 12也可以简单写为 interface 接口名{ int r =1 ; 返回值 方法名() } 123456789101112#### 怎么使用接口#### 为什么要用接口### 抽象类+ 接口是抽象的，必须通过类实现它才能用，除了抽象的接口之外，还有抽象的类，其声明方法类似 public abstract class Person{ private String name ; public Person(String name)&#123; this.name = name ; &#125; ... public abstract void introduceSelf(); } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 + 抽象类首先是一个类 + 抽象类中可以没有抽象方法 + 一个类如果继承了抽象类，要么自己实现父类中的抽象方法，要么将自己也声明为抽象类 + 类也可以通过接口来获得抽象方法+ 为什么要有抽象类 + 从语法上讲，是为了让子类强制覆盖父类中的某些类（有点像c++中的虚函数？） + 从业务上讲，如果有一个父类的方法不应该被调用（因为调用它没有实际意义的情况），此时应该用抽象类。### 内部类#### 成员内部类定义在类中的类，与类中其他成员是同一重量级+ 内部类可以访问外部类的所有属性和方法，因为它们本来就是同一级别的+ 内部类中定义了一个指向外部类的引用+ 外部类的代码要想访问内部类的对象中的变量，需要先创建要给内部成员类的对象#### 局部内部类定义在类中一个方法或者一个作用域中的类，与方法中的局部变量是同一级别的。可以使用其所在方法中的final变量不能包含静态成员+ 静态方法中的局部内部类 + 受静态方法限制，只能访问静态变量和方法中的`final`变量+ 非静态方法中的局部内部类 + 隐含有指向外部类的引用#### 匿名内部类+ 没有名字+ 不能添加构造方法+ 没有修饰符+ 通过接口来使用匿名类+ 通过抽象类来使用匿名类#### 静态内部类+ 是类范畴中的元素，其中不含指向外部类对象的元素，所以不能在静态成员内部类中使用外部类中的非静态 成员+ 静态成员只能访问静态成员### Java异常+ 异常抛出+ 异常传递 + 从某个方法中的某个`throw`语句传递到调用这个方法的地方，一直到`main`方法 + 异常必须被传递出去或者处理掉 + 抛出异常位置后面的代码不会被执行+ 异常处理 try{ //可能会抛出异常的代码 }catch(异常类型1 异常引用1){ //如果抛出的异常与此处的异常类型匹配，用异常引用指向try中的异常实例 //处理异常 }catch(异常类型2 异常引用2){ }finally{ /*`finally`语句中的代码无论如何都会被执行，无论上面的catch过程是匹配到异常处理掉了还是将异常 抛出，都会执行finally块，如果异常被处理掉了，那么接下来执行finally,如果异常没有被匹配，那么 先执行finally,再抛出异常 */ /*finally语句通常不被遇到，一种典型使用情况是用来释放资源*/ } 1 try{}finally{ } 1234567 关于异常的捕获，我们可以做的不仅仅是将其打印输出，也可以在`catch`语句里对异常进行修改### Java多线程+ 多线程 public class UseRunnable { public static void main(String args[]) throws InterruptedException &#123; //显示主线程的名字 System.out.println(&quot;current thread name is: &quot;+Thread.currentThread().getName()); System.out.println(&quot;program will be executed after 5000 ms&quot;); //这里的Thread方法和currentThread方法一样，都是静态方法 Thread.sleep(5000); MyRunnable runnable = new MyRunnable(); Thread thread = new Thread(runnable); //这里也可以通过匿名类的方式实现Runnable /* * Thread thread = new Thread(new Runnable()&#123; * public void run()&#123; * System.out.println(&quot;this is my runnable in anther way&quot;) * &#125; * &#125;) * */ thread.start(); MyThread mythread = new MyThread(); mythread.start(); &#125; } /methond 1/class MyRunnable implements Runnable{ //通过继承接口的方式来实现线程 @Override public void run() &#123; System.out.println(&quot;this is my runnable&quot;); &#125; } /*其实我们也可以通过继承Thread类来实现*这样做有个显著的不好，java中类是单继承的，如果为了使用线程而去继承Thread类， 那将不能继承其他类，所以还是实现接口的方式好一些*/ /method 2/class MyThread extends Thread{ //Thread类有一个参数为空的构造方法 public void run()&#123; System.out.println(&quot;this is my thread&quot;); &#125; 123456789101112131415161718192021 + synchronized关键字 当某个方法只允许同一时间只被一个线程访问时，可以用synchronized关键字来修饰这个方法 + `public synchronized static void func()` 当synchronized修饰静态方法时，是类范畴内的同步。也就是说，加入某类有多个静态同步方法，那么当其中一个方法被第一个线程访问时，当第二个线程试图访问这个类中的任意一个静态同步方法时，它都会被挂起。但是不同类中的静态方法互不影响。 + `public synchronized void func()` 对象范畴的同步。也就是说，当某个线程访问该对象中的非静态同步方法时，如果另一线程试图访问同一个对象中的任意非静态同步方法时，它将被挂起 + + wait()和notify() package top.iamnewbie; public class UseWaitAndNotify { public static void main(String[] args) &#123; Object obj = new Object(); Waiting waiting = new Waiting(obj); Notifier notifier = new Notifier(obj); //注意,这里使用同一对象初始化Waiting和Notifier //因为Waiting和Notifier都实现了Runnable接口，所以可以用他们来初始化Thread类 Thread thread1 = new Thread(waiting,&quot;线程1&quot;); Thread thread2 = new Thread(notifier,&quot;线程2&quot;); //通过start函数来触发Runnable的run函数 thread1.start(); thread2.start(); &#125; } //它实现了Runnable接口，在Thread中将这个类的实例作为参数就可以创建线程class Waiting implements Runnable{ private Object waitObj ; public Waiting(Object obj) &#123; this.waitObj = obj; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;将被挂起&quot;); synchronized (waitObj)&#123; try &#123; waitObj.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName()+&quot;被唤醒&quot;); &#125; } class Notifier implements Runnable{ private Object notifyObj ; public Notifier(Object notifyObj) &#123; this.notifyObj = notifyObj; &#125; @Override public void run() &#123; System.out.println(&quot;开始notify线程&quot;); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (notifyObj)&#123; notifyObj.notify(); &#125; System.out.println(&quot;notify线程结束&quot;); &#125; } 123同步代码块，语法如下 synchronized(对象引用){ 同步代码 } 12345678910111213141516171819202122232425262728293031323334353637 如果有多个线程同时访问同步代码块，而且同步代码块中对象的引用指向的是同一对象，那么就只有一个线程能进入代码块执行。上面的例子中，两个类中都写了同步代码块，在执行的时候，可以发现，用的是同一个对象实例来初始化`Waiting`和`Notifier`,也就是说虽然同步代码块是在两个对象中，但是同步代码块中对象的引用指向的是同一个实例（这也是将两个线程联系起来的关键）。进入代码块时，给对象加锁，执行wait()方法时，去掉锁，此时线程1被挂起，同时`obj`对象也没有被加锁，这时候线程2就可以访问这个代码块了，使用过synchronized先加锁，执行notify后解锁 通篇来看，正是因为初始化两个对象用了同一对象，这才让两个线程建立了关联。### IO来一张输入流和输出流的类层次图![](https://ws1.sinaimg.cn/large/005UcYzagy1ftkxcjom5ij30n50nd45y.jpg)+ 关于几个类 + File类 文件和文件夹都用File类来表示 + `InputStream`和`OutputStream` Java中的输入流和输出流 + `Writer` Abstract class for writing to character streams. The only methods that a subclass must implement are write(char[], int, int), flush(), and close(). Most subclasses, however, will override some of the methods defined here in order to provide higher efficiency, additional functionality, or both. + `PrintWriter` `Writer`的子类，将对象格式化打印到文件中 + + 读写数据 + 向文件中写数据（假设文件已存在） + `PrintWriter` PrintWriter printWriter = new PrintWriter(new FileOutputStream(filename)); printWriter.write(“write something”); printWriter.close(); 123456789 `PrintWriter()`接受的参数类型主要有![](https://ws1.sinaimg.cn/large/005UcYzagy1fpvrurtcrcj30qf0gg0ts.jpg)这里看上去不关输出流什么事，但其实它已经蕴含在`PrintWriter`类里面了.+ `BufferdWriter` BufferedWriter out=new BufferedWriter(new FileWriter(fileName)); out.write(&quot;Hello BufferWriter&quot;); out.close(); 1234567 `BufferdWriter()`接受的参数类型 ![](https://ws1.sinaimg.cn/large/005UcYzagy1fpvrwofyqzj30nr054t8t.jpg)+ `FileWriter` FileWriter writer=new FileWriter(fileName,true); writer.write(&quot;write something&quot;); writer.close(); 12345678910111213 `FileWriter()`接受的参数类型 ![](https://ws1.sinaimg.cn/large/005UcYzagy1fpvryi3ajmj30un0a8gm4.jpg) 总结一下，写文件的话一般用的就是Writer的子类，+ 读文件 fileReader = new FileReader(file1); bufferedReader1 = new BufferedReader(fileReader); while((content1=bufferedReader1.readLine()) != null){ System.out.println(content1); } fileReader.close(); 1234567891011121314151617181920212223242526272829 ### Swing+ 基本流程 创建一个窗口`JFrame`,进行基础设置，获得Container对象，向里面添加其他组件·### Java Collection Framework![](https://ws1.sinaimg.cn/large/005UcYzagy1fv5utslrw5j30lr0ijjui.jpg)#### 相互区别`ArrayList`底层实现是数组，可以存储null, 没有进行同步措施，不是线程安全的，当数组容量不够时，需要扩容。`LinkedList`同时实现了List和Deque接口，所以它既可以看作一个顺序容器，又可以看作队列，又可以看作栈。（我对Deque的理解就是双端队列Double end queue）,它的底层实现是一个双向链表。为了效率`LinkedList`同样没有实现同步，如果多个线程并发访问，可以用`Collection.synchronizedList()`方法对其进行包装。Stack 类继承自Vector, Java已不推荐使用Stack, 而是推荐使用`ArrayDeque`（继承自Deque）,`ArrayDeque`不是线程安全的，需要手动同步，其中不允许放入null. `ArrayDeque`底层也是数组实现，作为双端队列，肯定需要判断队列是否满了，如果满了要进行扩容操作，虽然这个工作API内部就完成了，但是在看它的实现时，我的表情是这样的，![](https://ws1.sinaimg.cn/large/005UcYzagy1fv5x4qelgdj305n064dfs.jpg)数据结构书上讲的判断队列满的方法是取模，这里它是这么实现的 public void addFirst(E e) { if (e == null)//不允许放入null throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界 if (head == tail)//1.空间是否够用 doubleCapacity();//扩容 } 12345678910111213141516171819202122232425262728293031323334353637383940414243通过位运算来实现的，因为Array每次扩容都是按倍数增长，所以它的容量是2的次幂，那么用head-1来和length-1进行与运算，就可以求模了，想想通过位运算来求模肯定会节省很多时间啊。真的是![](https://ws1.sinaimg.cn/large/005UcYzagy1fv5x90s09xj308o08c3yk.jpg)##### Vector 和 `ArrayList`1. vector 是线程同步的，所以它也是线程安全的，而 `ArrayList` 是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用 `ArrayList` 效率比较高。2. 如果集合中的元素的数目大于目前集合数组的长度时，vector 增长率为目前数组长度的100%,而 arraylist 增长率为目前数组长度的50%.如过在集合中使用数据量比较大的数据，用 vector 有一定的优势。3. 如果查找一个指定位置的数据，vector 和 arraylist 使用的时间是相同的，都是0(1),这个时候使用 vector 和 arraylist 都可以。而如果移动一个指定位置的数据花费的时间为 0(n-i)n 为总长度，这个时候就应该考虑到使用 linklist,因为它移动一个指定位置的数据所花费的时间为 0(1),而查询一个指定位置的数据时花费的时间为 0(i)。ArrayList 和 Vector 是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要设计到数组元素移动 等内存操作，所以索引数据快插入数据慢，Vector 由于使用了 synchronized 方法（线程安全）所以性能上比ArrayList 要差，LinkedList 使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快！##### arraylist 和 linkedlist1. ArrayList 是实现了基于动态数组的数据结构，LinkedList 基于链表的数据结构。 2.对于随机访问 get 和 set，ArrayList 觉得优于 LinkedList，因为 LinkedList 要移动指针。 3.对于新增和删除操作 add 和 remove，LinedList 比较占优势，因为 ArrayList 要移动数据。 这一点要看实际情况的。若只对单条数据插入或删除，ArrayList 的速度反而优于 LinkedList。但若是批量随机的插入删除数据，LinkedList 的速度大大优于 ArrayList. 因为 ArrayList 每插入一条数据，要移动插入点及之后的所有数据。#### HashMap### Java自动拆装箱==比较的是对象应用，equals比较的是值在Java 5中，在Integer的操作上引入了一个新功能来节省内存和提高性能。整型对象通过使用相同的对象引用实现了缓存和重用。&gt; 适用于整数值区间-128 至 +127。&gt;&gt;&gt;&gt; 只适用于自动装箱。使用构造函数创建对象不适用。### Java中的String#### 关于字符串常量池考虑以下代码 String s1 = “taochq” ; （1）String s2 = new String(“taochq”) ; （2）String s3 = new String(“taochq”).intern() ; （3） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化，字符串类维护了一个字符串常量池。执行代码（1）的时候，jvm会检查常量池中有没有“taochq”这个字符串，没有则创建并返回引用（注意这个引用是指向字符串常量池的），有的话则直接返回它的引用。执行（2）的时候，s2是在栈上，堆上会创建一个String对象，它指向字符串常量池中的&quot;taochq&quot;,所以s2指向的是堆上的一个地址。执行（3）的时候，因为调用了intern()方法，JVM会检查常量池中是否有相同的的字符串，如果有则直接返回引用（注意这里的引用也是指向字符串常量池的），如果没有则将字符串放入常量池并返回它的引用。看到这里，你可能会觉得，代码（1）和代码（3）实现的效果差不多啊，为什么还要有`intern()`这个方法呢，其实是有区别的。要知道，常量池保存的是**已确定**的字符串，什么意思呢？就是说很多时候我们在程序中用到的字符串都是在编译器无法确定的，只有在运行时才知道这个字符串确切是啥，对于这种情况，使用intern进行定义，每次程序执行到这里的时候直接返回常量池中的字符串，可以减少堆上对象的创建。而对于那种在编译器就能确定的常量，我们当然可以使用双引号字符串进行定义。#### + 号拼接字符串在java中，`+`并不是运算符重载，java是不支持运算符重载的，这只是java的一个语法糖，它的底层仍然是`stringbuilder`的`apend`操作。#### concat借助字符数组，最终还是new了一个新的String对象##### `String` `StringBuffer` `StringBuilder`它们内部都是通过数组来实现的，不同的是，String的内部数组是final修饰的，是不可改变的，`StringBuffer`和`StringBuilder`内部数组是可修改的。它俩有一个变量来指示数组中已经被占用的元素个数。它们的append方法是通过数组来实现的。`StringBuffer`和`StringBuilder`最大的区别是`StringBuffer`是线程安全的。#### 总结如果在循环体内，使用`+`进行字符串拼接的话，会频繁的创建`StringBuilder`对象，不如直接用`StringBuilder`拼接来的快。#### String的比较`==`比较的事两个对象的引用是否相同，即两个对象是否是同一个对象而只是引用不同而已。`equals()`方法比较的是字符串的值。### `foreach`循环中的remove/add操作最近在项目中使用`foreach`并且在里面对元素进行remove时常常发生并发修改异常,特此记录。 java.util.ConcurrentModificationException 123#### 问题场景 List list = new ArrayList(); list.add(“this is”); list.add(“a foreach”); list.add(“example”); for(String str: list){ if(str.equals(“a foreach)){ list.remove(str); }} 123执行以上代码时，就会产生上述异常。 Exception in thread “main” java.util.ConcurrentModificationException at java.base/java.util.ArrayList$Itr.checkForComodification(ArrayList.java:937) at java.base/java.util.ArrayList$Itr.next(ArrayList.java:891) at Test.main(Test.java:12) 12345678910111213#### 问题分析`foreach`循环其实是java提供给我们的语法糖，其本质还是借助while循环和iterator来实现的（iterator使用迭代器模式实现）。之所以出现上述异常，是因为触发了java的fail-fast机制。fail-fast即快速失败机制，当多线程访问集合类并对其进行修改时，可能触发。其实单线程也是可以触发的，比如本例。其实产生并发修改异常的原因很简单,`checkForComdification`的代码如下： final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); } 可以看出，抛出异常的原因是因为`modCount`和`expectedModCount`的值不一样，那这两个值代表着什么呢？ + `modCount`是`AbstractList`中的成员变量，代表list被修改的次数 + `expectedModCount` 是 `ArrayList`中的一个内部类——`Itr`中的成员变量。`expectedModCount`表示这个迭代器期望该集合被修改的次数。其值是在`ArrayList.iterator`方法被调用的时候初始化的。**只有通过迭代器对集合进行操作，该值才会改变**。 看到这里，其实问题已经明了了，`foreach`是用while+iterator实现的，但是上述代码中remove操作却用的是集合类自己的remove方法而不是iterator的remove,这样造成的结果就是`modCount`得到了修改但是`expectedModCount`却没有被修改，从而抛出异常。 ### Java中的日志 阿里巴巴开发手册中有一条：【强制】应用中不可直接使用日志系统（Log4j、`Logback`）中的API，而应依赖使用日志框架SLF4J中的API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。 来看下Java中一些好的日志门面： **SLF4J**(Simple Logging Facade for Java) ### Java中的引用 在JVM的文章中有写到。 + #### 弱引用","categories":[{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"http://example.com/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"mongodb学习笔记","slug":"mongodb学习笔记","date":"2018-01-02T01:41:25.000Z","updated":"2023-05-29T14:17:37.587Z","comments":true,"path":"2018/01/02/mongodb学习笔记/","link":"","permalink":"http://example.com/2018/01/02/mongodb%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"关系型数据库与MongoDB术语对比 关系型数据库 MongoDB 表 集合 行 文档 列 字段 表join 内嵌 主键 主键（由MongoDB提供默认的key_id） 创建数据库 use DATABASE_NAME 得到 记一次在mapreduce里填的坑 mapreduce最初是由谷歌提出的框架，但已在多种平台上实现。分为map和reduce两个阶段。 map阶段通过emit函数对同一个key所对应的值进行映射，reduce阶段对每组映射结果进行化简。用官方文档的一张图来说明： ​ ​ 问题合集 在连接MongoDB的过程中，实际上应该用两次cmd,第一次是开启Mongo服务，第二次才是连接到数据库。先到安装目录下的bin文件夹下执行mongod --dbpath &quot;F:\\mongodb\\data\\db&quot;启动服务器，然后重新打开命令行，输入mongo连接数据库 在node.js操作mongodb时遇到如下错误 MongoNetworkError: connection destroyed, not possible to instantiate cursor 最后发现应该把db.close()写到回掉函数里面 ​mongodb的在线调试端口默认28017 mongodb的访问控制问题： admin对于非系统集合其实是没有读权限的","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"MySQL学习笔记","slug":"MySQL学习笔记","date":"2017-12-13T10:54:49.000Z","updated":"2023-05-29T14:17:39.314Z","comments":true,"path":"2017/12/13/MySQL学习笔记/","link":"","permalink":"http://example.com/2017/12/13/MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"###MySQL逻辑架构 redo log &amp; bin logMySQL的每次数据更改都不会立即写入磁盘的，因为这是一个大量IO的过程，耗时耗力，一个可取的操作时我先把当前的操作记录在日志里，等到夜深人静操作系统空闲的时候，在通过日志把相关的修改持久化。 所以，机智的MySQL设计者们就提出了一个叫做WAL(write ahead logging)的技术。 每当对数据库进行修改操作时，会先在redo log中添加一行记录“需要在哪个数据页上做什么修改”，并且把这行记录的状态设置为prepare状态，等到事务提交后，再把redo log中的这行记录的状态设置为commit. redo log记录方式redo log是InnoDB所有的，它的大小是固定的，可以通过特定参数来配置日志文件的数量和每个日志文件的大小。 它采用循环写的方式，如下图： 其中write pos表示当前打算写的位置，write pos和check point之间的空间表示空闲空间，因为是循环写，所以必然存在一个写满的问题，写满了，就要擦除，然后继续写，所以它是不能保存过去的所有时刻的状态。 有了这个redo log,就可以保证数据库异常重启后，我们仍然可以根据redo log里面的记录进行恢复，我们把这个能力叫做crash-safe. 那么问题来了，既然都有了redo log，为什么还要bin log呢？ 根据上述分析，我们知道： redo log是InnoDB引擎特有的，其他引擎没有 redo log容量有限，所以不会保存太多的历史记录。 基于上述两条，我们又有了bin log, 那它们有什么区别呢？ bin log是属于server层的，所以它对于所有存储引擎都能用 bin log是通过追加方式写入的，所以旧的记录不会被擦除 redo log记录的是物理修改，比如某个页面的某个值修改为啥，而bin log记录的逻辑操作，你可以认为它记录了一条SQL语句 有了这两个日志后，这两份日志需要保证逻辑一致（我也不知道为啥，先记着吧），而这个保证是通过一个叫做两阶段提交的方式来实现的： 它的大意是这样的，当有一个数据库的修改时，先将修改后的值放到内存，然后在redo log里面记录一哈，此时的状态是prepare, 然后在bin log里面再记录一哈，最后提交事务，将redo log里面的状态设置为commit. 等到夜深人静的时候，就可以通过redo里面这些状态为commit的字段来修改数据库了。 change buffer今天学习了change buffer, 简单来说，change buffer是用给普通索引的，对于频繁的更新或者插入操作，唯一索引需要把对应数据页读入内存检查唯一性，这势必会增加IO开销。而对普通索引来说，则没有必要检查唯一性，所以遇到更新或者插入操作，不着急把数据页读入内存进行更新，而是可以先把要进行的操作读入一个change buffer中，等后面啥时候机缘巧合了把对应数据页读进来和change buffer merge一下。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"tensorflow学习笔记","slug":"tensorflow学习笔记","date":"2017-11-20T07:28:37.000Z","updated":"2023-05-29T14:17:39.328Z","comments":true,"path":"2017/11/20/tensorflow学习笔记/","link":"","permalink":"http://example.com/2017/11/20/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Session会话(Session)Session是tensorflow为了控制和输出文件所执行的语句，也就是说，如果使用了tensorflow,而你又想正常输出，那就需要创建一个会话，在会话中执行sess.run()来完成你的需求。 12345678910111213import tensorflow as tfmatrix1 = tf.constant([[1,3]])matrix2 = tf.constant([[2],[4]])result = tf.matmul(matrix1,matrix2)#method1sess = tf.Session()print(sess.run(result))#method2with tf.Session() as sess : print(sess.run(result)) 注意：对于张量的写法，无论是几维，最外面总是有个中括号，然后每一维一个中括号 变量tensorflow中变量必须用tf.Variable()函数来定义，而且应以完了之后必须用tf.initialize_all_varialbles()来初始化，其实这里的初始化也只是静态的初始化，最后还要在session中run一下，run()完之后变量算是真正得到了初始化，但是如果要输出某个变量的值，仍需要sess.run()将Session指针移过去 123456789import tensorflow as tfa = tf.Variable(tf.random_uniform([1,1],1,5))init = tf.initialize_all_variables()with tf.Session() as sess: sess.run(init) print(sess.run(a)) 占位符（placeholder）顾名思义，占位符在声明的时候并没有值给它初始化，这也就是它为什么叫占位符的原因，仅仅起到一个占位置的作用，那它什么时候有值呢？它会在session中被赋值，也就是说，如果程序中不算一开始就给值的话，可以用占位符的方式。 12345678910import tensorflow as tfinput1 = tf.placeholder(tf.float32,shape=[1,1])input2 = tf.placeholder(tf.float32,shape=[1,1])output = tf.add(input1,input2)with tf.Session() as sess: result = sess.run(output,feed_dict=&#123;input1:[[1]],input2:[[1]]&#125;) print(result) placeholder最终在sess.run()中用feed_dict{}进行输入，需要注意的是，即便这里shape是[1,1],后面输入时仍是[[1]]的形式 Tensorboard关于tensorboard的使用，大概分为一下几步： tf.summary.histogram()或者tf.summary.scalar()来绘制图层，从名字上讲，histogram绘制的是柱状图，scalar绘制的是折线图，但其实我并不认识histogram绘制的是什么东西 merged = tf.summary.merge_all将所有的summary汇总在一起 writer = tf.summary.FileWriter()将event文件写到指定目录下 result = sess.run(merged,feed_dict=&#123;...&#125;) writer.add_summary(result,i) 然后在命令行中tensorboard --logdir event文件目录 Regression代码分析这里是一个回归分析的例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Sat Jan 6 16:20:17 2018@author: Terry&quot;&quot;&quot;import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt#这里定义了隐含层def add_layer(inputs, in_size, out_size, activation_function=None): #参数包括输入值，输入值大小，输出值大小，以及激励函数 Weights = tf.Variable(tf.random_normal([in_size, out_size])) #这个隐藏层做的事情就是计算：输入*权重+偏置 biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) #如果有激励函数则把结果放到激励函数里再计算一次 Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs# Make up some real data#在这里输入数据x_data = np.linspace(-1, 1, 300, dtype=np.float32)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape).astype(np.float32)y_data = np.square(x_data) - 0.5 + noise##plt.scatter(x_data, y_data)##plt.show()# define placeholder for inputs to network#这里是输入层，xs,ys都是需要输入的数据，只不过是在后面输入，所以这里使用了占位符xs = tf.placeholder(tf.float32, [None, 1])ys = tf.placeholder(tf.float32, [None, 1])# add hidden layer#这里是隐藏层l1 = add_layer(xs , 1, 10, activation_function=tf.nn.relu)# add output layerprediction = add_layer(l1, 10, 1, activation_function=None)# the error between prediction and real dataloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)# important stepsess = tf.Session()# tf.initialize_all_variables() no long valid from# 2017-03-02 if using tensorflow &gt;= 0.12if int((tf.__version__).split(&#x27;.&#x27;)[1]) &lt; 12 and int((tf.__version__).split(&#x27;.&#x27;)[0]) &lt; 1: init = tf.initialize_all_variables()else: init = tf.global_variables_initializer()sess.run(init)for i in range(1000): # training sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: # to see the step improvement print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;)) 它的学习过程是这样的，对于两个初始值xs，ys,xs会经过某种变换到达ys，这里我们通过隐含层，会计算出来一个Output,通过训练不断减小ys（理想值）和output（实际值）的误差，来达到学习的效果 Classification代码分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Mon Jun 25 11:04:49 2018@author: Arrow&quot;&quot;&quot;import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&#x27;MNIST_data&#x27;,one_hot=True) #one-hot vector表示除了某一位的数字是一其他的都是0def add_layer(inputs,in_size,out_size,activation_function=None): Weights = tf.Variable(tf.random_normal([in_size,out_size])) biases = tf.Variable(tf.zeros([1,out_size])+0.1) Wx_plus_b = tf.matmul(inputs,Weights)+biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputsdef compute_accuracy(v_xs,v_ys): global prediction y_pre = sess.run(prediction,feed_dict=&#123;xs:v_xs&#125;) correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.arg_max(v_ys,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) result = sess.run(accuracy,feed_dict=&#123;xs:v_xs,ys:v_ys&#125;) return result#define placeholder for inputs to network xs = tf.placeholder(tf.float32,[None,784])ys = tf.placeholder(tf.float32,[None,10])# add output layerprediction = add_layer(xs,784,10,activation_function=tf.nn.softmax)#the error between prediction and real data #这里使用交叉熵来计算误差，对数里面的是预测值，外面的是实际值cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),reduction_indices=[1])) #使用梯度下降，学习速率为0.5进行训练train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)sess = tf.Session()#important stepsess.run(tf.global_variables_initializer())for i in range(1000): #每次随机抓取100个数据点进行训练 batch_xs,batch_ys = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;xs:batch_xs,ys:batch_ys&#125;) #每训练50步打印一下精度，这里有一个很精妙的做法，打印精度输入的是test中的image和label, #训练用的数据集是train,那么训练结果是如何用到test数据集中的呢，这主要得益于compute_accuracy中 #的全局变量prediction,prediction会调用add_layer方法，用已经经过训练的Weights和biases同test数据集中 #的输入进行计算，这样就会得到test数据集中的预测值 if i % 50 ==0: print(compute_accuracy(mnist.test.images,mnist.test.labels)) dropout fix overfitting123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Thu Jun 28 15:10:29 2018@author: Arrow&quot;&quot;&quot;import tensorflow as tffrom sklearn.datasets import load_digitsfrom sklearn.cross_validation import train_test_splitfrom sklearn.preprocessing import LabelBinarizerdigits = load_digits()X = digits.datay = digits.targety = LabelBinarizer().fit_transform(y)X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3)tf.reset_default_graph()def add_layer(inputs,in_size,out_size,layer_name,activation_function=None): Weights = tf.Variable(tf.random_normal([in_size,out_size])) biases = tf.Variable(tf.zeros([1,out_size]))+0.1 Wx_plus_b = tf.matmul(inputs,Weights)+biases Wx_plus_b = tf.nn.dropout(Wx_plus_b,keep_prob) if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) tf.summary.histogram(layer_name+&#x27;/outputs&#x27;,outputs) return outputs#define placeholder for inputs to networkkeep_prob = tf.placeholder(tf.float32)xs = tf.placeholder(tf.float32,[None,64])ys = tf.placeholder(tf.float32,[None,10])# add output layerl1 = add_layer(xs,64,50,&#x27;l1&#x27;,activation_function=tf.nn.tanh)prediction = add_layer(l1,50,10,&#x27;l2&#x27;,activation_function=tf.nn.softmax)# the loss between prediction and real datacross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))tf.summary.scalar(&#x27;loss&#x27;,cross_entropy)train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)sess = tf.Session()merged = tf.summary.merge_all()train_writer = tf.summary.FileWriter(&quot;logs/train&quot;,sess.graph)test_writer = tf.summary.FileWriter(&quot;logs/test&quot;,sess.graph)init = tf.global_variables_initializer()sess.run(init)for i in range(500): sess.run(train_step,feed_dict=&#123;xs:X_train,ys:y_train,keep_prob:0.5&#125;) if i % 50 == 0: train_result = sess.run(merged,feed_dict=&#123;xs:X_train,ys:y_train,keep_prob:1&#125;) test_result = sess.run(merged,feed_dict=&#123;xs:X_test,ys:y_test,keep_prob:1&#125;) train_writer.add_summary(train_result,i) test_writer.add_summary(test_result,i) 有点不太明白的是，loss生成的是两个event文件，为什么最后显示在一张图里，难道说是tensorflow自己把logdir下的两个文件夹下的两个文件合并了么 遇到的问题 InvalidArgumentError: You must feed a value for placeholder tensor &#39;Placeholder&#39; with dtype float 一直以为是占位符的问题，后来发现是tensorboard的问题，因为上述代码中其实是要绘制两份图表，大概是因为tensorflow的tf.merge_all_summaries()使用一个默认的图来收集我们的所有操作，包括此前进行的一些错误操作，所以我在所有的tf操作之前加了代码tf.reset_default_graph()就好了，更多请参考 一些小问题 在引入matplotlib时，有错误显示spyder No module named &#39;PyQt4&#39;，几经折腾，最后发现系统中有新版本PyQt5而默认设置还是4，所以打开Tools -&gt; Preferences -&gt; IPython console -&gt; Graphics -&gt; Backened 修改为QT5 Convolution Neural NetworkCNN常用在图片识别，计算机视觉等领域，它大概操作如下： 对于一张图片，它有长宽高，这里的高指的是它是黑白还是彩色的 然后有个过滤器，在图片上进行扫描，每次会扫描图片上的一小部分区域，经过一次扫描，会把这个图片压缩成，长和宽更小，高度更厚的一个图片，这个过程就叫做卷积。每次扫描多大一块区域呢，我们把这个叫做patch,有时候也叫它Kernel,还有一个术语叫stride,表示扫描时移动的步幅。这个过程其实就是对特征的多次提取，其中的高度就表特征，这样的过程重复几次后，会得到一个长宽很小，高度很厚的图片， 然后把它放到全连接神经网络中进行分类。 如果每次扫描时stride过大，可能会造成信息的损失，这时候就需要pooling 池化来减少 这个效果。 根据扫描中如何处理边界，有valid padding和same padding，valid padding表示只处理图片边缘内容，不会涉及边缘以外的东西，same padding表示将图片边缘以外的东西用0来填充 代码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Fri Jun 29 13:54:21 2018@author: Arrow&quot;&quot;&quot;import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# number 1 to 10 datamnist = input_data.read_data_sets(&#x27;MNIST_data&#x27;, one_hot=True)def add_layer(inputs, in_size, out_size, activation_function=None,): # add one more layer and return the output of this layer Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b,) return outputsdef compute_accuracy(v_xs, v_ys): global prediction y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prob: 1&#125;) correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prob: 1&#125;) return result#输入形状，返回权重def weight_variable(shape): #产生正太分布，stddev是标准差 initial = tf.truncated_normal(shape,stddev=0.1) return tf.Variable(initial)#输入形状，返回偏置def biase_variable(shape): initial = tf.constant(0.1,shape=shape) return tf.Variable(initial)#定义一个二维的卷积神经网络def conv2d(x,W): # strides=[1,x_movesize,y_movesize,1] return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#x27;SAME&#x27;)def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#x27;SAME&#x27;)# define placeholder for inputs to networkxs = tf.placeholder(tf.float32, [None, 784]) # 28x28ys = tf.placeholder(tf.float32, [None, 10])keep_prob = tf.placeholder(tf.float32) # -1 表示暂时不考虑图片输入数量多少这个维度，1表示channel的数量x_image = tf.reshape(xs,[-1,28,28,1])##conv1 layer # 卷积和patch 5X5,channel 1,output height 32W_conv1 = weight_variable([5,5,1,32])b_conv1 = biase_variable([32]) #output size 28x28x32 (SAME padding不改变长宽)h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #output size 14x14x32 (pooling的步长是2) h_pool1 = max_pool_2x2(h_conv1)##conv2 layerW_conv2 = weight_variable([5,5,32,64])b_conv2 = biase_variable([64]) #output size 14x14x64 (SAME padding不改变长宽)h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) #output size 7x7x64 (pooling的步长是2) h_pool2 = max_pool_2x2(h_conv2)##func1 layerW_fc1 = weight_variable([7*7*64,1024])b_fc1 = biase_variable([1024]) #[n_samples,7,7,64] &gt;&gt; [n_samples,7*7*64]h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)## func2 layerW_fc2 = weight_variable([1024,10])b_fc2 = biase_variable([10])prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)# the error between prediction and real datacross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1])) # losstrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)sess = tf.Session()# important stepinit = tf.global_variables_initializer()sess.run(init)for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict=&#123;xs: batch_xs, ys: batch_ys,keep_prob:0.5&#125;) if i % 50 == 0: print(compute_accuracy(mnist.test.images, mnist.test.labels)) RNN 用来做classification的例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Mon Jul 2 15:04:48 2018@author: Arrow&quot;&quot;&quot;import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# set random seed for comparing the two result calculationstf.set_random_seed(1)# this is datamnist = input_data.read_data_sets(&#x27;MNIST_data&#x27;, one_hot=True)# hyperparameterslr = 0.001training_iters = 100000batch_size = 128n_inputs = 28 # MNIST data input (img shape: 28*28)n_steps = 28 # time stepsn_hidden_units = 128 # neurons in hidden layern_classes = 10 # MNIST classes (0-9 digits)# tf Graph inputx = tf.placeholder(tf.float32, [None, n_steps, n_inputs])y = tf.placeholder(tf.float32, [None, n_classes])# Define weightsweights = &#123; # (28, 128) &#x27;in&#x27;: tf.Variable(tf.random_normal([n_inputs, n_hidden_units])), # (128, 10) &#x27;out&#x27;: tf.Variable(tf.random_normal([n_hidden_units, n_classes]))&#125;biases = &#123; # (128, ) &#x27;in&#x27;: tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])), # (10, ) &#x27;out&#x27;: tf.Variable(tf.constant(0.1, shape=[n_classes, ]))&#125;def RNN(X, weights, biases): # hidden layer for input to cell ######################################## # transpose the inputs shape from # X ==&gt; (128 batch * 28 steps, 28 inputs) X = tf.reshape(X, [-1, n_inputs]) # into hidden # X_in = (128 batch * 28 steps, 128 hidden) X_in = tf.matmul(X, weights[&#x27;in&#x27;]) + biases[&#x27;in&#x27;] # X_in ==&gt; (128 batch, 28 steps, 128 hidden) X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units]) # cell ########################################## # basic LSTM Cell. if int((tf.__version__).split(&#x27;.&#x27;)[1]) &lt; 12 and int((tf.__version__).split(&#x27;.&#x27;)[0]) &lt; 1: cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True) else: cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units) # lstm cell is divided into two parts (c_state, h_state) init_state = cell.zero_state(batch_size, dtype=tf.float32) # You have 2 options for following step. # 1: tf.nn.rnn(cell, inputs); # 2: tf.nn.dynamic_rnn(cell, inputs). # If use option 1, you have to modified the shape of X_in, go and check out this: # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py # In here, we go for option 2. # dynamic_rnn receive Tensor (batch, steps, inputs) or (steps, batch, inputs) as X_in. # Make sure the time_major is changed accordingly. outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False) # hidden layer for output as the final results ############################################# # results = tf.matmul(final_state[1], weights[&#x27;out&#x27;]) + biases[&#x27;out&#x27;] # # or # unpack to list [(batch, outputs)..] * steps if int((tf.__version__).split(&#x27;.&#x27;)[1]) &lt; 12 and int((tf.__version__).split(&#x27;.&#x27;)[0]) &lt; 1: outputs = tf.unpack(tf.transpose(outputs, [1, 0, 2])) # states is the last outputs else: outputs = tf.unstack(tf.transpose(outputs, [1,0,2])) results = tf.matmul(outputs[-1], weights[&#x27;out&#x27;]) + biases[&#x27;out&#x27;] # shape = (128, 10) return resultspred = RNN(x, weights, biases)cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))train_op = tf.train.AdamOptimizer(lr).minimize(cost)# tf.argmax()用来返回当前向量最大值的索引，第二个参数是1表示按行，是0表示按列correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))with tf.Session() as sess: # tf.initialize_all_variables() no long valid from # 2017-03-02 if using tensorflow &gt;= 0.12 if int((tf.__version__).split(&#x27;.&#x27;)[1]) &lt; 12 and int((tf.__version__).split(&#x27;.&#x27;)[0]) &lt; 1: init = tf.initialize_all_variables() else: init = tf.global_variables_initializer() sess.run(init) step = 0 while step * batch_size &lt; training_iters: batch_xs, batch_ys = mnist.train.next_batch(batch_size) batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs]) sess.run([train_op], feed_dict=&#123; x: batch_xs, y: batch_ys, &#125;) if step % 20 == 0: print(sess.run(accuracy, feed_dict=&#123; x: batch_xs, y: batch_ys, &#125;)) step += 1 CNN做regression的例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&quot;&quot;&quot;Know more, visit my Python tutorial page: https://morvanzhou.github.io/tutorials/My Youtube Channel: https://www.youtube.com/user/MorvanZhouDependencies:tensorflow: 1.1.0matplotlibnumpy&quot;&quot;&quot;import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt# Hyper ParametersTIME_STEP = 10 # rnn time stepINPUT_SIZE = 1 # rnn input sizeCELL_SIZE = 32 # rnn cell sizeLR = 0.02 # learning rate# show datasteps = np.linspace(0, np.pi*2, 100, dtype=np.float32)x_np = np.sin(steps); y_np = np.cos(steps) # float32 for converting torch FloatTensorplt.plot(steps, y_np, &#x27;r-&#x27;, label=&#x27;target (cos)&#x27;); plt.plot(steps, x_np, &#x27;b-&#x27;, label=&#x27;input (sin)&#x27;)plt.legend(loc=&#x27;best&#x27;); plt.show()# tensorflow placeholderstf_x = tf.placeholder(tf.float32, [None, TIME_STEP, INPUT_SIZE]) # shape(batch, 5, 1)tf_y = tf.placeholder(tf.float32, [None, TIME_STEP, INPUT_SIZE]) # input y# RNNrnn_cell = tf.contrib.rnn.BasicRNNCell(num_units=CELL_SIZE)init_s = rnn_cell.zero_state(batch_size=1, dtype=tf.float32) # very first hidden stateoutputs, final_s = tf.nn.dynamic_rnn( rnn_cell, # cell you have chosen tf_x, # input initial_state=init_s, # the initial hidden state time_major=False, # False: (batch, time step, input); True: (time step, batch, input))outs2D = tf.reshape(outputs, [-1, CELL_SIZE]) # reshape 3D output to 2D for fully connected layernet_outs2D = tf.layers.dense(outs2D, INPUT_SIZE)outs = tf.reshape(net_outs2D, [-1, TIME_STEP, INPUT_SIZE]) # reshape back to 3Dloss = tf.losses.mean_squared_error(labels=tf_y, predictions=outs) # compute costtrain_op = tf.train.AdamOptimizer(LR).minimize(loss)sess = tf.Session()sess.run(tf.global_variables_initializer()) # initialize var in graphplt.figure(1, figsize=(12, 5)); plt.ion() # continuously plotfor step in range(60): start, end = step * np.pi, (step+1)*np.pi # time range # use sin predicts cos steps = np.linspace(start, end, TIME_STEP) x = np.sin(steps)[np.newaxis, :, np.newaxis] # shape (batch, time_step, input_size) y = np.cos(steps)[np.newaxis, :, np.newaxis] if &#x27;final_s_&#x27; not in globals(): # first state, no any hidden state feed_dict = &#123;tf_x: x, tf_y: y&#125; else: # has hidden state, so pass it to rnn feed_dict = &#123;tf_x: x, tf_y: y, init_s: final_s_&#125; _, pred_, final_s_ = sess.run([train_op, outs, final_s], feed_dict) # train # plotting plt.plot(steps, y.flatten(), &#x27;r-&#x27;); plt.plot(steps, pred_.flatten(), &#x27;b-&#x27;) plt.ylim((-1.2, 1.2)); plt.draw(); plt.pause(0.05)plt.ioff(); plt.show() 上述例子中，shape的变化很烦人呐 综合上述两个例子，LSTMRNN的核心过程，input_layer,cell,output_layer,对此tensorflow已经为我们做了很大的集成工作，需要注意的是，input_layer阶段需要进行reshape,不过用心的tf api似乎没有这个问题，然后就是output_layer部分也要reshape,cell阶段主要是构建cell, init state,并执行RNN，框架大概就是i这样了。 损失函数对损失函数求导，从而知道如何调节参数能够使损失函数超降低的方向发展。 上图就是一个用于训练模型的迭代的方法。 梯度下降法梯度，是由偏导数组成的矢量，而偏导数，指的是多元函数对某一个自变量的导数（保持其他变量不变），偏导数在几何上反应出来的就是这个函数沿着该自变量维度的一个增减情况，所以由偏导数组成的梯度，就可以描述函数在整个定义域上的一个起伏情况。 通过梯度下降的方法，我们能够更快的找到损失最小的点。 学习速率这里会有一个学习速率的概念，其表示每次训练的一个步长，学习速率并非越大越好，因为有时学习速率交大时，可能直接跳过损失函数最小的点。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[]}],"categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"},{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Netty","slug":"Netty","permalink":"http://example.com/categories/Netty/"},{"name":"容器","slug":"容器","permalink":"http://example.com/categories/%E5%AE%B9%E5%99%A8/"},{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"OS","slug":"OS","permalink":"http://example.com/categories/OS/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://example.com/categories/JavaWeb/"},{"name":"后端","slug":"后端","permalink":"http://example.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"教程","slug":"教程","permalink":"http://example.com/categories/%E6%95%99%E7%A8%8B/"},{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"},{"name":"学术","slug":"学术","permalink":"http://example.com/categories/%E5%AD%A6%E6%9C%AF/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"移动开发","slug":"移动开发","permalink":"http://example.com/categories/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/"},{"name":"题解","slug":"题解","permalink":"http://example.com/categories/%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"中断","slug":"中断","permalink":"http://example.com/tags/%E4%B8%AD%E6%96%AD/"},{"name":"异常","slug":"异常","permalink":"http://example.com/tags/%E5%BC%82%E5%B8%B8/"},{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"泛型","slug":"泛型","permalink":"http://example.com/tags/%E6%B3%9B%E5%9E%8B/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Netty","slug":"Netty","permalink":"http://example.com/tags/Netty/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"async","slug":"async","permalink":"http://example.com/tags/async/"},{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"},{"name":"类卸载","slug":"类卸载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8D%B8%E8%BD%BD/"},{"name":"Instrument","slug":"Instrument","permalink":"http://example.com/tags/Instrument/"},{"name":"ASM","slug":"ASM","permalink":"http://example.com/tags/ASM/"},{"name":"跨域","slug":"跨域","permalink":"http://example.com/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"同源策略","slug":"同源策略","permalink":"http://example.com/tags/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"动态代理","slug":"动态代理","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"面经","slug":"面经","permalink":"http://example.com/tags/%E9%9D%A2%E7%BB%8F/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"TCP","slug":"TCP","permalink":"http://example.com/tags/TCP/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://example.com/tags/TCP-IP/"},{"name":"IO模型","slug":"IO模型","permalink":"http://example.com/tags/IO%E6%A8%A1%E5%9E%8B/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Lock","slug":"Lock","permalink":"http://example.com/tags/Lock/"},{"name":"线程池","slug":"线程池","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"排序","slug":"排序","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F/"},{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"finalize","slug":"finalize","permalink":"http://example.com/tags/finalize/"},{"name":"内部类","slug":"内部类","permalink":"http://example.com/tags/%E5%86%85%E9%83%A8%E7%B1%BB/"},{"name":"https","slug":"https","permalink":"http://example.com/tags/https/"},{"name":"强化学习","slug":"强化学习","permalink":"http://example.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"关键字","slug":"关键字","permalink":"http://example.com/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"},{"name":"继承","slug":"继承","permalink":"http://example.com/tags/%E7%BB%A7%E6%89%BF/"},{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"},{"name":"RequestBody","slug":"RequestBody","permalink":"http://example.com/tags/RequestBody/"},{"name":"fail fast","slug":"fail-fast","permalink":"http://example.com/tags/fail-fast/"},{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/tags/Nginx/"},{"name":"类加载","slug":"类加载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"name":"volatile","slug":"volatile","permalink":"http://example.com/tags/volatile/"},{"name":"剑指offer","slug":"剑指offer","permalink":"http://example.com/tags/%E5%89%91%E6%8C%87offer/"},{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"},{"name":"集合类","slug":"集合类","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88%E7%B1%BB/"},{"name":"class文件","slug":"class文件","permalink":"http://example.com/tags/class%E6%96%87%E4%BB%B6/"},{"name":"IO","slug":"IO","permalink":"http://example.com/tags/IO/"},{"name":"反射","slug":"反射","permalink":"http://example.com/tags/%E5%8F%8D%E5%B0%84/"},{"name":"教程","slug":"教程","permalink":"http://example.com/tags/%E6%95%99%E7%A8%8B/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Java虚拟机","slug":"Java虚拟机","permalink":"http://example.com/tags/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Leetcode","slug":"Leetcode","permalink":"http://example.com/tags/Leetcode/"},{"name":"java基础","slug":"java基础","permalink":"http://example.com/tags/java%E5%9F%BA%E7%A1%80/"}]}